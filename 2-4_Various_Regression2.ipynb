{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 소프트맥스 회귀 구현하기 (Keras)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_JECEyCcU5n6"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import load_iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "z9SyV5KwU6yF",
    "outputId": "84920f07-5cf0-4d7a-8fed-feedff004dfd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['data', 'target', 'target_names', 'DESCR', 'feature_names', 'filename'])"
      ]
     },
     "execution_count": 2,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = load_iris()\n",
    "df.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "U2u5EJLJU9T_",
    "outputId": "fc29357a-7ecd-46d8-be82-ae3d39868688"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_data: (150, 4)\n",
      "y_data: (150,)\n",
      "nb_features: 4\n",
      "nb_classes: 3\n"
     ]
    }
   ],
   "source": [
    "x_data = np.array(df.data, dtype=np.float32)\n",
    "y_data = np.array(df.target, dtype=np.int32)\n",
    "\n",
    "nb_features = x_data.shape[1]\n",
    "nb_classes = len(set(y_data))\n",
    "\n",
    "print(\"x_data:\", x_data.shape)\n",
    "print(\"y_data:\", y_data.shape)\n",
    "\n",
    "print(\"nb_features:\", nb_features)\n",
    "print(\"nb_classes:\", nb_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jnQLnAa83xth",
    "outputId": "f911d1bf-ff6e-4680-e89d-6b6fb0abb8db"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.1, 3.5, 1.4, 0.2],\n",
       "       [4.9, 3. , 1.4, 0.2],\n",
       "       [4.7, 3.2, 1.3, 0.2],\n",
       "       [4.6, 3.1, 1.5, 0.2],\n",
       "       [5. , 3.6, 1.4, 0.2]], dtype=float32)"
      ]
     },
     "execution_count": 5,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_data[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ozVPQlT3U-ng"
   },
   "outputs": [],
   "source": [
    "# One-Hot Encoding\n",
    "y_one_hot = tf.one_hot(indices=list(y_data), depth=nb_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XZDxNW5V3u3u",
    "outputId": "abf1718d-2c75-4789-a6f7-bf39754a189c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(5, 3), dtype=float32, numpy=\n",
       "array([[1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.]], dtype=float32)>"
      ]
     },
     "execution_count": 6,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_one_hot[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "tKo-W9dBVHAR",
    "outputId": "6dfd9474-d25f-4836-c2e7-753478540fc3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 4.2372 - accuracy: 0.3333\n",
      "Epoch 2/200\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 2.9042 - accuracy: 0.3333\n",
      "Epoch 3/200\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 2.0162 - accuracy: 0.3333\n",
      "Epoch 4/200\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 1.4551 - accuracy: 0.3333\n",
      "Epoch 5/200\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 1.2249 - accuracy: 0.3533\n",
      "Epoch 6/200\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 1.1208 - accuracy: 0.3533\n",
      "Epoch 7/200\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 1.0446 - accuracy: 0.3867\n",
      "Epoch 8/200\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.9790 - accuracy: 0.4133\n",
      "Epoch 9/200\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.9187 - accuracy: 0.5733\n",
      "Epoch 10/200\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.8658 - accuracy: 0.7133\n",
      "Epoch 11/200\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.8175 - accuracy: 0.7467\n",
      "Epoch 12/200\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.7760 - accuracy: 0.7467\n",
      "Epoch 13/200\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.7378 - accuracy: 0.7867\n",
      "Epoch 14/200\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.7104 - accuracy: 0.7467\n",
      "Epoch 15/200\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.6793 - accuracy: 0.7600\n",
      "Epoch 16/200\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.6543 - accuracy: 0.7867\n",
      "Epoch 17/200\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.6350 - accuracy: 0.8000\n",
      "Epoch 18/200\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.6122 - accuracy: 0.7933\n",
      "Epoch 19/200\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.5936 - accuracy: 0.7867\n",
      "Epoch 20/200\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.5792 - accuracy: 0.7733\n",
      "Epoch 21/200\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.5621 - accuracy: 0.7867\n",
      "Epoch 22/200\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.5518 - accuracy: 0.8000\n",
      "Epoch 23/200\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.5363 - accuracy: 0.8133\n",
      "Epoch 24/200\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.5275 - accuracy: 0.8333\n",
      "Epoch 25/200\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.5134 - accuracy: 0.8267\n",
      "Epoch 26/200\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.5034 - accuracy: 0.8267\n",
      "Epoch 27/200\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.4936 - accuracy: 0.8533\n",
      "Epoch 28/200\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.4846 - accuracy: 0.8400\n",
      "Epoch 29/200\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.4731 - accuracy: 0.8533\n",
      "Epoch 30/200\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.4719 - accuracy: 0.8533\n",
      "Epoch 31/200\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.4607 - accuracy: 0.8667\n",
      "Epoch 32/200\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.4545 - accuracy: 0.8667\n",
      "Epoch 33/200\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.4476 - accuracy: 0.8733\n",
      "Epoch 34/200\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.4420 - accuracy: 0.8467\n",
      "Epoch 35/200\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.4350 - accuracy: 0.8733\n",
      "Epoch 36/200\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.4292 - accuracy: 0.8667\n",
      "Epoch 37/200\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.4218 - accuracy: 0.8867\n",
      "Epoch 38/200\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.4184 - accuracy: 0.9000\n",
      "Epoch 39/200\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.4121 - accuracy: 0.8867\n",
      "Epoch 40/200\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.4106 - accuracy: 0.8867\n",
      "Epoch 41/200\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.4016 - accuracy: 0.9200\n",
      "Epoch 42/200\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.3978 - accuracy: 0.8933\n",
      "Epoch 43/200\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.3943 - accuracy: 0.8867\n",
      "Epoch 44/200\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.3891 - accuracy: 0.9067\n",
      "Epoch 45/200\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.3875 - accuracy: 0.9133\n",
      "Epoch 46/200\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.3817 - accuracy: 0.8800\n",
      "Epoch 47/200\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.3764 - accuracy: 0.9000\n",
      "Epoch 48/200\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.3730 - accuracy: 0.9400\n",
      "Epoch 49/200\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.3687 - accuracy: 0.9200\n",
      "Epoch 50/200\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.3631 - accuracy: 0.9267\n",
      "Epoch 51/200\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.3607 - accuracy: 0.9200\n",
      "Epoch 52/200\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.3582 - accuracy: 0.9333\n",
      "Epoch 53/200\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.3543 - accuracy: 0.9400\n",
      "Epoch 54/200\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.3527 - accuracy: 0.9267\n",
      "Epoch 55/200\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.3475 - accuracy: 0.9333\n",
      "Epoch 56/200\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.3440 - accuracy: 0.9267\n",
      "Epoch 57/200\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.3415 - accuracy: 0.9333\n",
      "Epoch 58/200\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.3393 - accuracy: 0.9333\n",
      "Epoch 59/200\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.3343 - accuracy: 0.9400\n",
      "Epoch 60/200\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.3320 - accuracy: 0.9400\n",
      "Epoch 61/200\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.3287 - accuracy: 0.9400\n",
      "Epoch 62/200\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.3270 - accuracy: 0.9333\n",
      "Epoch 63/200\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.3207 - accuracy: 0.9467\n",
      "Epoch 64/200\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.3223 - accuracy: 0.9467\n",
      "Epoch 65/200\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.3162 - accuracy: 0.9400\n",
      "Epoch 66/200\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.3139 - accuracy: 0.9400\n",
      "Epoch 67/200\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.3097 - accuracy: 0.9333\n",
      "Epoch 68/200\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.3086 - accuracy: 0.9333\n",
      "Epoch 69/200\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.3059 - accuracy: 0.9600\n",
      "Epoch 70/200\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.3025 - accuracy: 0.9667\n",
      "Epoch 71/200\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.3008 - accuracy: 0.9533\n",
      "Epoch 72/200\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.2971 - accuracy: 0.9467\n",
      "Epoch 73/200\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.2943 - accuracy: 0.9600\n",
      "Epoch 74/200\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.2935 - accuracy: 0.9600\n",
      "Epoch 75/200\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.2919 - accuracy: 0.9467\n",
      "Epoch 76/200\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.2905 - accuracy: 0.9467\n",
      "Epoch 77/200\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.2849 - accuracy: 0.9600\n",
      "Epoch 78/200\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.2863 - accuracy: 0.9533\n",
      "Epoch 79/200\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.2825 - accuracy: 0.9467\n",
      "Epoch 80/200\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.2811 - accuracy: 0.9667\n",
      "Epoch 81/200\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.2803 - accuracy: 0.9600\n",
      "Epoch 82/200\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.2776 - accuracy: 0.9400\n",
      "Epoch 83/200\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.2745 - accuracy: 0.9600\n",
      "Epoch 84/200\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.2719 - accuracy: 0.9600\n",
      "Epoch 85/200\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.2692 - accuracy: 0.9600\n",
      "Epoch 86/200\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.2675 - accuracy: 0.9467\n",
      "Epoch 87/200\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.2665 - accuracy: 0.9533\n",
      "Epoch 88/200\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.2652 - accuracy: 0.9467\n",
      "Epoch 89/200\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.2633 - accuracy: 0.9600\n",
      "Epoch 90/200\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.2594 - accuracy: 0.9533\n",
      "Epoch 91/200\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.2578 - accuracy: 0.9667\n",
      "Epoch 92/200\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.2556 - accuracy: 0.9600\n",
      "Epoch 93/200\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.2547 - accuracy: 0.9600\n",
      "Epoch 94/200\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.2532 - accuracy: 0.9667\n",
      "Epoch 95/200\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.2510 - accuracy: 0.9667\n",
      "Epoch 96/200\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.2496 - accuracy: 0.9667\n",
      "Epoch 97/200\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.2470 - accuracy: 0.9467\n",
      "Epoch 98/200\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.2476 - accuracy: 0.9467\n",
      "Epoch 99/200\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.2436 - accuracy: 0.9667\n",
      "Epoch 100/200\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.2426 - accuracy: 0.9600\n",
      "Epoch 101/200\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.2427 - accuracy: 0.9667\n",
      "Epoch 102/200\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.2382 - accuracy: 0.9600\n",
      "Epoch 103/200\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.2375 - accuracy: 0.9667\n",
      "Epoch 104/200\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.2356 - accuracy: 0.9600\n",
      "Epoch 105/200\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.2363 - accuracy: 0.9600\n",
      "Epoch 106/200\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.2322 - accuracy: 0.9667\n",
      "Epoch 107/200\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.2325 - accuracy: 0.9533\n",
      "Epoch 108/200\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.2295 - accuracy: 0.9667\n",
      "Epoch 109/200\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.2274 - accuracy: 0.9600\n",
      "Epoch 110/200\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.2259 - accuracy: 0.9667\n",
      "Epoch 111/200\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.2251 - accuracy: 0.9667\n",
      "Epoch 112/200\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.2231 - accuracy: 0.9667\n",
      "Epoch 113/200\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.2231 - accuracy: 0.9667\n",
      "Epoch 114/200\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.2204 - accuracy: 0.9600\n",
      "Epoch 115/200\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.2210 - accuracy: 0.9600\n",
      "Epoch 116/200\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.2179 - accuracy: 0.9600\n",
      "Epoch 117/200\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.2182 - accuracy: 0.9667\n",
      "Epoch 118/200\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.2165 - accuracy: 0.9733\n",
      "Epoch 119/200\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.2147 - accuracy: 0.9600\n",
      "Epoch 120/200\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.2142 - accuracy: 0.9667\n",
      "Epoch 121/200\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.2116 - accuracy: 0.9667\n",
      "Epoch 122/200\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.2106 - accuracy: 0.9600\n",
      "Epoch 123/200\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.2092 - accuracy: 0.9733\n",
      "Epoch 124/200\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.2093 - accuracy: 0.9667\n",
      "Epoch 125/200\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.2083 - accuracy: 0.9667\n",
      "Epoch 126/200\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.2056 - accuracy: 0.9600\n",
      "Epoch 127/200\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.2041 - accuracy: 0.9733\n",
      "Epoch 128/200\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.2033 - accuracy: 0.9667\n",
      "Epoch 129/200\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.2001 - accuracy: 0.9733\n",
      "Epoch 130/200\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.2028 - accuracy: 0.9667\n",
      "Epoch 131/200\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.1999 - accuracy: 0.9733\n",
      "Epoch 132/200\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.1984 - accuracy: 0.9667\n",
      "Epoch 133/200\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.1971 - accuracy: 0.9667\n",
      "Epoch 134/200\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.1967 - accuracy: 0.9667\n",
      "Epoch 135/200\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.1952 - accuracy: 0.9667\n",
      "Epoch 136/200\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.1944 - accuracy: 0.9667\n",
      "Epoch 137/200\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.1938 - accuracy: 0.9667\n",
      "Epoch 138/200\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.1921 - accuracy: 0.9667\n",
      "Epoch 139/200\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.1905 - accuracy: 0.9733\n",
      "Epoch 140/200\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.1893 - accuracy: 0.9667\n",
      "Epoch 141/200\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.1921 - accuracy: 0.9667\n",
      "Epoch 142/200\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.1886 - accuracy: 0.9667\n",
      "Epoch 143/200\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.1859 - accuracy: 0.9733\n",
      "Epoch 144/200\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.1875 - accuracy: 0.9667\n",
      "Epoch 145/200\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.1855 - accuracy: 0.9667\n",
      "Epoch 146/200\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.1841 - accuracy: 0.9667\n",
      "Epoch 147/200\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.1834 - accuracy: 0.9667\n",
      "Epoch 148/200\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.1833 - accuracy: 0.9667\n",
      "Epoch 149/200\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.1803 - accuracy: 0.9667\n",
      "Epoch 150/200\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.1841 - accuracy: 0.9667\n",
      "Epoch 151/200\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.1810 - accuracy: 0.9733\n",
      "Epoch 152/200\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.1788 - accuracy: 0.9733\n",
      "Epoch 153/200\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.1803 - accuracy: 0.9667\n",
      "Epoch 154/200\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.1772 - accuracy: 0.9733\n",
      "Epoch 155/200\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.1771 - accuracy: 0.9667\n",
      "Epoch 156/200\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.1750 - accuracy: 0.9733\n",
      "Epoch 157/200\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.1747 - accuracy: 0.9667\n",
      "Epoch 158/200\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.1734 - accuracy: 0.9733\n",
      "Epoch 159/200\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.1753 - accuracy: 0.9600\n",
      "Epoch 160/200\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.1727 - accuracy: 0.9733\n",
      "Epoch 161/200\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.1711 - accuracy: 0.9733\n",
      "Epoch 162/200\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.1706 - accuracy: 0.9733\n",
      "Epoch 163/200\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.1706 - accuracy: 0.9733\n",
      "Epoch 164/200\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.1696 - accuracy: 0.9667\n",
      "Epoch 165/200\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.1679 - accuracy: 0.9733\n",
      "Epoch 166/200\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.1689 - accuracy: 0.9667\n",
      "Epoch 167/200\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.1692 - accuracy: 0.9733\n",
      "Epoch 168/200\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.1663 - accuracy: 0.9667\n",
      "Epoch 169/200\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.1658 - accuracy: 0.9667\n",
      "Epoch 170/200\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.1659 - accuracy: 0.9667\n",
      "Epoch 171/200\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.1631 - accuracy: 0.9733\n",
      "Epoch 172/200\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.1634 - accuracy: 0.9667\n",
      "Epoch 173/200\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.1622 - accuracy: 0.9733\n",
      "Epoch 174/200\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.1633 - accuracy: 0.9733\n",
      "Epoch 175/200\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.1603 - accuracy: 0.9733\n",
      "Epoch 176/200\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.1607 - accuracy: 0.9667\n",
      "Epoch 177/200\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.1598 - accuracy: 0.9733\n",
      "Epoch 178/200\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.1589 - accuracy: 0.9733\n",
      "Epoch 179/200\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.1586 - accuracy: 0.9733\n",
      "Epoch 180/200\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.1594 - accuracy: 0.9667\n",
      "Epoch 181/200\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.1561 - accuracy: 0.9667\n",
      "Epoch 182/200\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.1562 - accuracy: 0.9667\n",
      "Epoch 183/200\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.1561 - accuracy: 0.9733\n",
      "Epoch 184/200\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.1552 - accuracy: 0.9733\n",
      "Epoch 185/200\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.1558 - accuracy: 0.9733\n",
      "Epoch 186/200\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.1545 - accuracy: 0.9733\n",
      "Epoch 187/200\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.1545 - accuracy: 0.9733\n",
      "Epoch 188/200\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.1529 - accuracy: 0.9667\n",
      "Epoch 189/200\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.1544 - accuracy: 0.9733\n",
      "Epoch 190/200\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.1528 - accuracy: 0.9733\n",
      "Epoch 191/200\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.1527 - accuracy: 0.9733\n",
      "Epoch 192/200\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.1513 - accuracy: 0.9733\n",
      "Epoch 193/200\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.1506 - accuracy: 0.9733\n",
      "Epoch 194/200\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.1499 - accuracy: 0.9733\n",
      "Epoch 195/200\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.1489 - accuracy: 0.9733\n",
      "Epoch 196/200\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.1494 - accuracy: 0.9733\n",
      "Epoch 197/200\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.1492 - accuracy: 0.9667\n",
      "Epoch 198/200\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.1479 - accuracy: 0.9733\n",
      "Epoch 199/200\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.1463 - accuracy: 0.9733\n",
      "Epoch 200/200\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.1478 - accuracy: 0.9733\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential # 케라스의 Sequential()을 임포트\n",
    "from tensorflow.keras.layers import Dense # 케라스의 Dense()를 임포트\n",
    "from tensorflow.keras import optimizers # 케라스의 옵티마이저를 임포트\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "# 입력의 차원은 4, 출력의 차원은 3, activation function은 softmax\n",
    "model.add(Dense(3, input_dim=4, activation='softmax'))\n",
    "\n",
    "# 학습률(learning rate, lr)은 0.01로.\n",
    "sgd = optimizers.SGD(lr=0.01)\n",
    "\n",
    "# 옵티마이저는 경사하강법의 일종인 adam을 사용.\n",
    "# 손실 함수(Loss function)는 크로스 엔트로피 함수를 사용.\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam',metrics=['accuracy'])\n",
    "\n",
    "# 주어진 X와 y데이터에 대해서 오차를 최소화하는 작업을 200번 시도.\n",
    "history = model.fit(x_data, y_one_hot, batch_size=1, epochs=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TwnK5eYPONF1"
   },
   "source": [
    "# 소프트맥스 회귀 구현하기 (Tape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vGtizvZxOOM0"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import load_iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "U1_p2Zo7OnMh",
    "outputId": "367142d4-1e83-45ff-dec0-c326c56851e0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['data', 'target', 'target_names', 'DESCR', 'feature_names', 'filename'])"
      ]
     },
     "execution_count": 105,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = load_iris()\n",
    "df.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 87
    },
    "id": "UR4A_XtVOpZM",
    "outputId": "e2919852-10a8-4f19-afba-b13265013666"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_data: (150, 4)\n",
      "y_data: (150,)\n",
      "nb_features: 4\n",
      "nb_classes: 3\n"
     ]
    }
   ],
   "source": [
    "x_data = np.array(df.data, dtype=np.float32)\n",
    "y_data = np.array(df.target, dtype=np.int32)\n",
    "\n",
    "nb_features = x_data.shape[1]\n",
    "nb_classes = len(set(y_data))\n",
    "\n",
    "print(\"x_data:\", x_data.shape)\n",
    "print(\"y_data:\", y_data.shape)\n",
    "\n",
    "print(\"nb_features:\", nb_features)\n",
    "print(\"nb_classes:\", nb_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 158
    },
    "id": "61-fwai_UhGF",
    "outputId": "1c10c264-c227-44a7-b51f-043426a0d9b9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Weights: \n",
      " [[-0.10099822  0.6847899   1.6258512 ]\n",
      " [ 0.88112587 -0.63692456 -0.1427695 ]\n",
      " [ 0.82411087 -0.9132699  -0.45101833]\n",
      " [ 0.58053356  1.3066356  -0.60428965]] \n",
      "\n",
      "# Bias: \n",
      " [ 0.38414615 -0.6159301  -0.5453214 ]\n"
     ]
    }
   ],
   "source": [
    "# Weights\n",
    "tf.random.set_seed(2020)\n",
    "W = tf.Variable(tf.random.normal([nb_features, nb_classes], mean=0.0))\n",
    "b = tf.Variable(tf.random.normal([nb_classes], mean=0.0))\n",
    "\n",
    "# One-Hot Encoding\n",
    "y_one_hot = tf.one_hot(indices=list(y_data), depth=nb_classes)\n",
    "\n",
    "print('# Weights: \\n', W.numpy(), '\\n\\n# Bias: \\n', b.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "stsunqqXUiCH",
    "outputId": "62c86a8d-8538-48b6-c397-3fd2361305c6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> #0 \n",
      " Weights: \n",
      "[[-0.11743642  0.70453906  1.6225401 ]\n",
      " [ 0.87678254 -0.62771267 -0.14763813]\n",
      " [ 0.80348897 -0.8990886  -0.44457772]\n",
      " [ 0.5725719   1.3110503  -0.60074264]] \n",
      " Bias: \n",
      "[ 0.382134   -0.61260384 -0.54663545] \n",
      " cost: 3.9675086\n",
      "\n",
      ">>> #1000 \n",
      " Weights: \n",
      "[[ 0.16433328  1.3574839   0.68781775]\n",
      " [ 1.7573065  -0.64877206 -1.007102  ]\n",
      " [-0.8606213  -0.5406397   0.8610839 ]\n",
      " [-0.19550528  1.0364842   0.4419003 ]] \n",
      " Bias: \n",
      "[ 0.5655053  -0.43386924 -0.9087409 ] \n",
      " cost: 0.40306073\n",
      "\n",
      ">>> #2000 \n",
      " Weights: \n",
      "[[ 0.3168866   1.532144    0.36060667]\n",
      " [ 2.0306032  -0.6994984  -1.2296745 ]\n",
      " [-1.2645829  -0.5937341   1.3181393 ]\n",
      " [-0.3816476   0.7259963   0.9385296 ]] \n",
      " Bias: \n",
      "[ 0.62806755 -0.33476606 -1.0704057 ] \n",
      " cost: 0.2934371\n",
      "\n",
      ">>> #3000 \n",
      " Weights: \n",
      "[[ 0.42719203  1.6423253   0.14011881]\n",
      " [ 2.2220879  -0.712384   -1.4082736 ]\n",
      " [-1.5467923  -0.63064843  1.6372666 ]\n",
      " [-0.511728    0.4970248   1.297582  ]] \n",
      " Bias: \n",
      "[ 0.6729266 -0.2532305 -1.1967993] \n",
      " cost: 0.23829417\n",
      "\n",
      ">>> #4000 \n",
      " Weights: \n",
      "[[ 0.5144231   1.7170737  -0.02186147]\n",
      " [ 2.370571   -0.7091586  -1.5599793 ]\n",
      " [-1.7671055  -0.6548333   1.8817647 ]\n",
      " [-0.6135869   0.31790715  1.5785578 ]] \n",
      " Bias: \n",
      "[ 0.70841926 -0.18307568 -1.302447  ] \n",
      " cost: 0.20493014\n",
      "\n",
      ">>> #5000 \n",
      " Weights: \n",
      "[[ 0.586819    1.7708834  -0.14806877]\n",
      " [ 2.4918392  -0.6979826  -1.6924238 ]\n",
      " [-1.9482719  -0.67131037  2.0794067 ]\n",
      " [-0.6976658   0.17082891  1.8097142 ]] \n",
      " Bias: \n",
      "[ 0.73791003 -0.12064996 -1.3943636 ] \n",
      " cost: 0.18246922\n",
      "\n",
      ">>> #6000 \n",
      " Weights: \n",
      "[[ 0.6488224   1.8113606  -0.25055242]\n",
      " [ 2.594311   -0.6827015  -1.8101757 ]\n",
      " [-2.102253   -0.6829625   2.245039  ]\n",
      " [-0.76940626  0.04584502  2.0064385 ]] \n",
      " Bias: \n",
      "[ 0.7631948  -0.06381456 -1.4764842 ] \n",
      " cost: 0.16624017\n",
      "\n",
      ">>> #7000 \n",
      " Weights: \n",
      "[[ 0.7031179   1.8428282  -0.33632088]\n",
      " [ 2.6830328  -0.6653319  -1.9162678 ]\n",
      " [-2.2362247  -0.69143146  2.387479  ]\n",
      " [-0.8320591  -0.06300654  2.1779428 ]] \n",
      " Bias: \n",
      "[ 0.78535825 -0.0112307  -1.551231  ] \n",
      " cost: 0.15391423\n",
      "\n",
      ">>> #8000 \n",
      " Weights: \n",
      "[[ 0.7514565   1.8679215  -0.40975875]\n",
      " [ 2.7612686  -0.6469991  -2.012835  ]\n",
      " [-2.3548448  -0.6977035   2.512368  ]\n",
      " [-0.88773024 -0.15955025  2.3301563 ]] \n",
      " Bias: \n",
      "[ 0.8051084   0.03799441 -1.6202062 ] \n",
      " cost: 0.14420128\n",
      "\n",
      ">>> #9000 \n",
      " Weights: \n",
      "[[ 0.795046    1.8883383  -0.47377267]\n",
      " [ 2.8312435  -0.6283568  -2.1014516 ]\n",
      " [-2.4613104  -0.70240194  2.6235282 ]\n",
      " [-0.9378642  -0.24637938  2.467119  ]] \n",
      " Bias: \n",
      "[ 0.8229339   0.08448672 -1.684524  ] \n",
      " cost: 0.1363281\n",
      "\n",
      ">>> #10000 \n",
      " Weights: \n",
      "[[ 0.8347577   1.9052246  -0.5303765 ]\n",
      " [ 2.8945458  -0.6097892  -2.1833184 ]\n",
      " [-2.557909   -0.70594424  2.7236621 ]\n",
      " [-0.98349607 -0.32533324  2.591703  ]] \n",
      " Bias: \n",
      "[ 0.8391873   0.12870306 -1.7449929 ] \n",
      " cost: 0.12980226\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Learning Rate\n",
    "learning_rate = 0.01\n",
    "\n",
    "# Softmax Function\n",
    "def softmax(X):\n",
    "    sm = tf.nn.softmax(tf.matmul(x_data, W) + b)\n",
    "    return sm\n",
    "\n",
    "# Training\n",
    "for i in range(10000+1):\n",
    "\n",
    "    with tf.GradientTape() as tape:\n",
    "\n",
    "        sm = softmax(x_data)\n",
    "        cost = tf.reduce_mean(-tf.reduce_sum(y_one_hot*tf.math.log(sm), axis=1))        \n",
    "        W_grad, b_grad = tape.gradient(cost, [W, b])\n",
    "\n",
    "        W.assign_sub(learning_rate * W_grad)\n",
    "        b.assign_sub(learning_rate * b_grad)\n",
    "\n",
    "    if i % 1000 == 0:\n",
    "        print(\">>> #%s \\n Weights: \\n%s \\n Bias: \\n%s \\n cost: %s\\n\" % (i, W.numpy(), b.numpy(), cost.numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "IVdk_i4UUnHu",
    "outputId": "b10f3a3d-102b-447d-d21c-5a8adec4649c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.97333336\n"
     ]
    }
   ],
   "source": [
    "predicted = tf.argmax(softmax(x_data), axis=1)\n",
    "real = tf.argmax(y_one_hot, axis=1)\n",
    "\n",
    "def acc(predicted, real):\n",
    "    accuracy = tf.reduce_mean(tf.cast(tf.equal(predicted, real), dtype=tf.float32))\n",
    "    return accuracy\n",
    "\n",
    "accuracy = acc(predicted, real).numpy()\n",
    "print(\"Accuracy: %s\" % accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ewfoQrKdCIQa"
   },
   "source": [
    "# 다층 퍼셉트론으로 MNIST 분류하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DnHvujL0CS33"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential # 케라스의 Sequential()을 임포트\n",
    "from tensorflow.keras.layers import Dense, Flatten, Dropout # 케라스의 Dense(), Flatten()를 임포트\n",
    "from tensorflow.keras import optimizers # 케라스의 옵티마이저를 임포트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CqyGHAE3Cd2G",
    "outputId": "4725342d-c030-472a-b189-877758c12495"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "11493376/11490434 [==============================] - 0s 0us/step\n",
      "11501568/11490434 [==============================] - 0s 0us/step\n"
     ]
    }
   ],
   "source": [
    "mnist = tf.keras.datasets.mnist\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yuYgB3Wal_gN",
    "outputId": "bc2ad365-58ba-482a-cb3e-654ff1e23fc3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28, 28)\n",
      "[5 0 4 ... 5 6 8]\n"
     ]
    }
   ],
   "source": [
    "print(x_train[0].shape)\n",
    "print(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MRpskDDFCfnW"
   },
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "  Flatten(input_shape=(28, 28)), # Dense(28*28)\n",
    "  Dense(128, activation='relu'),\n",
    "  Dropout(0.2),\n",
    "  Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 230
    },
    "id": "u5F-xbK_E9CM",
    "outputId": "9324785a-fc59-43d6-d770-a70e4eb9e322"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.3019 - accuracy: 0.9121\n",
      "Epoch 2/5\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1466 - accuracy: 0.9571\n",
      "Epoch 3/5\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1089 - accuracy: 0.9666\n",
      "Epoch 4/5\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0890 - accuracy: 0.9722\n",
      "Epoch 5/5\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0751 - accuracy: 0.9768\n",
      "313/313 - 1s - loss: 0.0780 - accuracy: 0.9758\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.07796133309602737, 0.9757999777793884]"
      ]
     },
     "execution_count": 66,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, epochs=5)\n",
    "\n",
    "model.evaluate(x_test,  y_test, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7SbQah4u_bKx"
   },
   "source": [
    "# 다층 퍼셉트론으로 20개의 뉴스그룹 분류하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yRy-YUaa_ei0"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "09c6MYJd_hcr"
   },
   "source": [
    "사이킷런에서는 20개의 다른 주제를 가진 18,846개의 뉴스 그룹 이메일 데이터를 제공."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "id": "lP9xAhZP_iAV",
    "outputId": "e6f219f9-7970-48da-d4e5-894765870320"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading 20news dataset. This may take a few minutes.\n",
      "Downloading dataset from https://ndownloader.figshare.com/files/5975967 (14 MB)\n"
     ]
    }
   ],
   "source": [
    "newsdata = fetch_20newsgroups(subset = 'train') # 'train'을 기재하면 훈련 데이터만 리턴한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sju7AlXU_j_x"
   },
   "source": [
    "위의 subset의 값으로 'all'을 넣으면 전체 데이터인 18,846개의 샘플을 다운로드할 수 있으며, 'train'을 넣으면 훈련 데이터를, 'test'를 넣으면 테스트 데이터를 다운로드. newsdata.keys()를 출력하면 해당 데이터의 속성을 확인."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "Ysyh4pCg_k48",
    "outputId": "d6f90984-9696-4a63-db3b-deacc2a6fb30"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['data', 'filenames', 'target_names', 'target', 'DESCR'])\n"
     ]
    }
   ],
   "source": [
    "print(newsdata.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I8Mr61SS_r4h"
   },
   "source": [
    "해당 데이터는 data, filenames, target_names, target, DESCR, description이라는 6개 속성을 갖고 있음. 이 중 실제로 훈련에 사용할 속성은 이메일 본문인 data와 메일이 어떤 주제인지 기재된 숫자 레이블인 target. 우선 훈련용 샘플의 개수를 확인."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "svpaeHsT_sTl",
    "outputId": "97872e71-9f61-4400-8d97-776a25930dad"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련용 샘플의 개수 : 11314\n"
     ]
    }
   ],
   "source": [
    "print('훈련용 샘플의 개수 : {}'.format(len(newsdata.data)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j2WB8hrG_u6s"
   },
   "source": [
    "훈련 샘플은 11,314개가 존재. target_names에는 20개의 주제의 이름을 담고있음. 어떤 주제가 있는지 확인."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72
    },
    "id": "odY-n84K_tBd",
    "outputId": "cdb906bf-6d6d-4b00-99da-c297af92b239"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "총 주제의 개수 : 20\n",
      "['alt.atheism', 'comp.graphics', 'comp.os.ms-windows.misc', 'comp.sys.ibm.pc.hardware', 'comp.sys.mac.hardware', 'comp.windows.x', 'misc.forsale', 'rec.autos', 'rec.motorcycles', 'rec.sport.baseball', 'rec.sport.hockey', 'sci.crypt', 'sci.electronics', 'sci.med', 'sci.space', 'soc.religion.christian', 'talk.politics.guns', 'talk.politics.mideast', 'talk.politics.misc', 'talk.religion.misc']\n"
     ]
    }
   ],
   "source": [
    "print('총 주제의 개수 : {}'.format(len(newsdata.target_names)))\n",
    "print(newsdata.target_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hs4dWwb__w1j"
   },
   "source": [
    "이번 실습의 목적은 테스트 데이터에서 이메일 본문을 보고 20개의 주제 중 어떤 주제인지를 맞추는 것. 레이블인 target에는 총 0부터 19까지의 숫자가 들어가있는데 첫번째 샘플의 경우에는 몇 번 주제인지 확인."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "VnxPyBY5_wat",
    "outputId": "b3bff38b-3b15-48fc-acc2-e13b6641591d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "첫번째 샘플의 레이블 : 7\n"
     ]
    }
   ],
   "source": [
    "print('첫번째 샘플의 레이블 : {}'.format(newsdata.target[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "br6HhWT5_yQl",
    "outputId": "ada9a5f4-9480-470d-f00f-f5e51d135973"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7번 레이블이 의미하는 주제 : rec.autos\n"
     ]
    }
   ],
   "source": [
    "print('7번 레이블이 의미하는 주제 : {}'.format(newsdata.target_names[7]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 407
    },
    "id": "KcgW0oHg_1M1",
    "outputId": "ea8d0b82-7016-4b14-f4d2-141f6de080db"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From: lerxst@wam.umd.edu (where's my thing)\n",
      "Subject: WHAT car is this!?\n",
      "Nntp-Posting-Host: rac3.wam.umd.edu\n",
      "Organization: University of Maryland, College Park\n",
      "Lines: 15\n",
      "\n",
      " I was wondering if anyone out there could enlighten me on this car I saw\n",
      "the other day. It was a 2-door sports car, looked to be from the late 60s/\n",
      "early 70s. It was called a Bricklin. The doors were really small. In addition,\n",
      "the front bumper was separate from the rest of the body. This is \n",
      "all I know. If anyone can tellme a model name, engine specs, years\n",
      "of production, where this car is made, history, or whatever info you\n",
      "have on this funky looking car, please e-mail.\n",
      "\n",
      "Thanks,\n",
      "- IL\n",
      "   ---- brought to you by your neighborhood Lerxst ----\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(newsdata.data[0]) # 첫번째 샘플 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 197
    },
    "id": "orMWgpuM_2M1",
    "outputId": "98ae9a2a-4366-40a8-a23c-3597511857b6"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>email</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>From: lerxst@wam.umd.edu (where's my thing)\\nS...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>From: guykuo@carson.u.washington.edu (Guy Kuo)...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>From: twillis@ec.ecn.purdue.edu (Thomas E Will...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>From: jgreen@amber (Joe Green)\\nSubject: Re: W...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>From: jcm@head-cfa.harvard.edu (Jonathan McDow...</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               email  target\n",
       "0  From: lerxst@wam.umd.edu (where's my thing)\\nS...       7\n",
       "1  From: guykuo@carson.u.washington.edu (Guy Kuo)...       4\n",
       "2  From: twillis@ec.ecn.purdue.edu (Thomas E Will...       4\n",
       "3  From: jgreen@amber (Joe Green)\\nSubject: Re: W...       1\n",
       "4  From: jcm@head-cfa.harvard.edu (Jonathan McDow...      14"
      ]
     },
     "execution_count": 46,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.DataFrame(newsdata.data, columns = ['email']) # data로부터 데이터프레임 생성\n",
    "data['target'] = pd.Series(newsdata.target) # target 열 추가\n",
    "data[:5] # 상위 5개 행을 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 176
    },
    "id": "FWIB0kuE_3IN",
    "outputId": "a3b787ba-e89a-48a8-8983-6a1b855646df"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 11314 entries, 0 to 11313\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   email   11314 non-null  object\n",
      " 1   target  11314 non-null  int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 176.9+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "odIgdJCL_37M",
    "outputId": "762d22aa-3dba-465c-efd3-d8913f544e5b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 48,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().values.any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "id": "C8MnmsTk_4vM",
    "outputId": "4a3225b9-8d1d-4caa-d7bc-7f583dc600d3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "중복을 제외한 샘플의 수 : 11314\n",
      "중복을 제외한 주제의 수 : 20\n"
     ]
    }
   ],
   "source": [
    "print('중복을 제외한 샘플의 수 : {}'.format(data['email'].nunique()))\n",
    "print('중복을 제외한 주제의 수 : {}'.format(data['target'].nunique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 267
    },
    "id": "0WTpdu7e_5ec",
    "outputId": "22fd5213-9ded-4381-c31f-f3ba17fdb63b"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD7CAYAAACRxdTpAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAUIklEQVR4nO3df7BcZX3H8fcXIvgDJfy4xpiAoRJl7LQg3kH80apQNYAl1KJVOxqZtPmjKFSd0bR2hupYG9tRK9NCjY0YFEREGVLFHxhAay3IJWAAo+USgSQFckWIVbAKfvvHeaKby73Zs/fuvdk8vl8zO3vO82uf3T357Nlnd28iM5Ek1WWfPT0BSVL/Ge6SVCHDXZIqZLhLUoUMd0mqkOEuSRWas6cnAHDooYfmokWL9vQ0JGmvcuONN/4wM4cmqhuIcF+0aBEjIyN7ehqStFeJiLsmq3NZRpIqZLhLUoUMd0mqkOEuSRUy3CWpQq3CPSLmRsRlEfG9iNgUES+IiIMj4qqIuL1cH1TaRkScGxGjEbExIo6d2bsgSRqv7Zn7R4AvZ+ZRwNHAJmAlsD4zFwPryz7AScDiclkBnN/XGUuSuuoa7hFxIPD7wBqAzPx5Zj4ILAXWlmZrgdPK9lLgwmxcB8yNiPl9n7kkaVJtfsR0BDAGXBARRwM3AmcD8zLzntLmXmBe2V4AbOnov7WU3dNRRkSsoDmz5/DDD9/lBhet/GLXSd256pTd1ncbo1t/SdqbtQn3OcCxwFsz8/qI+Ai/XoIBIDMzInr6L50yczWwGmB4eHgg/zuo6b5A9ONFSpKmok24bwW2Zub1Zf8ymnC/LyLmZ+Y9Zdlle6nfBhzW0X9hKdMUDMq7mEF4ofPFUmqva7hn5r0RsSUinp2Z3wdOBL5bLsuAVeX6itJlHfCWiLgEeD6wo2P5Rtqjanmhk7pp+4fD3gpcFBH7AZuBM2g+jL00IpYDdwGvLW2vBE4GRoGHSltJ0ixqFe6ZeTMwPEHViRO0TeDMac5L0m4MynKdBpe/UJWkChnuklShgfjPOiTtnVzaGVyeuUtShQx3SaqQ4S5JFXLNXdIe4w+6Zo5n7pJUIcNdkipkuEtShQx3SaqQ4S5JFTLcJalCfhVS0l7NP4EwMc/cJalChrskVchwl6QKGe6SVCHDXZIqZLhLUoUMd0mqkOEuSRUy3CWpQoa7JFXIcJekCrUK94i4MyJuiYibI2KklB0cEVdFxO3l+qBSHhFxbkSMRsTGiDh2Ju+AJOmxejlzf1lmHpOZw2V/JbA+MxcD68s+wEnA4nJZAZzfr8lKktqZzrLMUmBt2V4LnNZRfmE2rgPmRsT8adyOJKlHbcM9ga9GxI0RsaKUzcvMe8r2vcC8sr0A2NLRd2sp20VErIiIkYgYGRsbm8LUJUmTafv33F+cmdsi4qnAVRHxvc7KzMyIyF5uODNXA6sBhoeHe+orSdq9VmfumbmtXG8HLgeOA+7budxSrreX5tuAwzq6LyxlkqRZ0jXcI+JJEfHkndvAK4BbgXXAstJsGXBF2V4HvKl8a+Z4YEfH8o0kaRa0WZaZB1weETvbX5yZX46IG4BLI2I5cBfw2tL+SuBkYBR4CDij77OWJO1W13DPzM3A0ROU3w+cOEF5Amf2ZXaSpCnxF6qSVKG235aRpGotWvnF3dbfueqUWZpJ/3jmLkkVMtwlqUKGuyRVyHCXpAoZ7pJUIb8tI0l9MGjfuPHMXZIqZLhLUoUMd0mqkOEuSRUy3CWpQoa7JFXIcJekChnuklQhw12SKmS4S1KFDHdJqpDhLkkVMtwlqUKGuyRVyHCXpAoZ7pJUIcNdkipkuEtShVqHe0TsGxE3RcQXyv4REXF9RIxGxGciYr9Svn/ZHy31i2Zm6pKkyfRy5n42sKlj/wPAhzPzSOABYHkpXw48UMo/XNpJkmZRq3CPiIXAKcC/lf0ATgAuK03WAqeV7aVln1J/YmkvSZolbc/c/wl4J/DLsn8I8GBmPlL2twILyvYCYAtAqd9R2u8iIlZExEhEjIyNjU1x+pKkiXQN94h4FbA9M2/s5w1n5urMHM7M4aGhoX4OLUm/8ea0aPMi4NSIOBl4PPAU4CPA3IiYU87OFwLbSvttwGHA1oiYAxwI3N/3mUuSJtX1zD0z/yozF2bmIuB1wNWZ+afANcDppdky4Iqyva7sU+qvzszs66wlSbs1ne+5vwt4e0SM0qyprynla4BDSvnbgZXTm6IkqVdtlmV+JTOvBa4t25uB4yZo8zPgNX2YmyRpivyFqiRVyHCXpAr1tCwjSZoZi1Z+sWubO1ed0no8z9wlqUKGuyRVyHCXpAoZ7pJUIcNdkipkuEtShQx3SaqQ4S5JFTLcJalChrskVchwl6QKGe6SVCHDXZIqZLhLUoUMd0mqkOEuSRUy3CWpQoa7JFXIcJekChnuklQhw12SKmS4S1KFuoZ7RDw+Ir4dEd+JiNsi4j2l/IiIuD4iRiPiMxGxXynfv+yPlvpFM3sXJEnjtTlz/z/ghMw8GjgGWBIRxwMfAD6cmUcCDwDLS/vlwAOl/MOlnSRpFnUN92z8pOw+rlwSOAG4rJSvBU4r20vLPqX+xIiIvs1YktRVqzX3iNg3Im4GtgNXAXcAD2bmI6XJVmBB2V4AbAEo9TuAQ/o5aUnS7rUK98x8NDOPARYCxwFHTfeGI2JFRIxExMjY2Nh0h5Mkdejp2zKZ+SBwDfACYG5EzClVC4FtZXsbcBhAqT8QuH+CsVZn5nBmDg8NDU1x+pKkibT5tsxQRMwt208AXg5sogn500uzZcAVZXtd2afUX52Z2c9JS5J2b073JswH1kbEvjQvBpdm5hci4rvAJRHxPuAmYE1pvwb4ZESMAj8CXjcD85Yk7UbXcM/MjcBzJyjfTLP+Pr78Z8Br+jI7SdKU+AtVSaqQ4S5JFTLcJalChrskVchwl6QKGe6SVCHDXZIqZLhLUoUMd0mqkOEuSRUy3CWpQoa7JFXIcJekChnuklQhw12SKmS4S1KFDHdJqpDhLkkVMtwlqUKGuyRVyHCXpAoZ7pJUIcNdkipkuEtShQx3SaqQ4S5JFeoa7hFxWERcExHfjYjbIuLsUn5wRFwVEbeX64NKeUTEuRExGhEbI+LYmb4TkqRdtTlzfwR4R2Y+BzgeODMingOsBNZn5mJgfdkHOAlYXC4rgPP7PmtJ0m51DffMvCczN5Tt/wU2AQuApcDa0mwtcFrZXgpcmI3rgLkRMb/vM5ckTaqnNfeIWAQ8F7gemJeZ95Sqe4F5ZXsBsKWj29ZSNn6sFRExEhEjY2NjPU5bkrQ7rcM9Ig4APgf8ZWb+uLMuMxPIXm44M1dn5nBmDg8NDfXSVZLURatwj4jH0QT7RZn5+VJ8387llnK9vZRvAw7r6L6wlEmSZkmbb8sEsAbYlJkf6qhaBywr28uAKzrK31S+NXM8sKNj+UaSNAvmtGjzIuCNwC0RcXMp+2tgFXBpRCwH7gJeW+quBE4GRoGHgDP6OmNJUlddwz0zvwnEJNUnTtA+gTOnOS9J0jT4C1VJqpDhLkkVMtwlqUKGuyRVyHCXpAoZ7pJUIcNdkipkuEtShQx3SaqQ4S5JFTLcJalChrskVchwl6QKGe6SVCHDXZIqZLhLUoUMd0mqkOEuSRUy3CWpQoa7JFXIcJekChnuklQhw12SKmS4S1KFDHdJqlDXcI+Ij0fE9oi4taPs4Ii4KiJuL9cHlfKIiHMjYjQiNkbEsTM5eUnSxNqcuX8CWDKubCWwPjMXA+vLPsBJwOJyWQGc359pSpJ60TXcM/MbwI/GFS8F1pbttcBpHeUXZuM6YG5EzO/XZCVJ7Ux1zX1eZt5Ttu8F5pXtBcCWjnZbS5kkaRZN+wPVzEwge+0XESsiYiQiRsbGxqY7DUlSh6mG+307l1vK9fZSvg04rKPdwlL2GJm5OjOHM3N4aGhoitOQJE1kquG+DlhWtpcBV3SUv6l8a+Z4YEfH8o0kaZbM6dYgIj4NvBQ4NCK2AucAq4BLI2I5cBfw2tL8SuBkYBR4CDhjBuYsSeqia7hn5usnqTpxgrYJnDndSUmSpsdfqEpShQx3SaqQ4S5JFTLcJalChrskVchwl6QKGe6SVCHDXZIqZLhLUoUMd0mqkOEuSRUy3CWpQoa7JFXIcJekChnuklQhw12SKmS4S1KFDHdJqpDhLkkVMtwlqUKGuyRVyHCXpAoZ7pJUIcNdkipkuEtShQx3SarQjIR7RCyJiO9HxGhErJyJ25AkTa7v4R4R+wL/ApwEPAd4fUQ8p9+3I0ma3EycuR8HjGbm5sz8OXAJsHQGbkeSNInIzP4OGHE6sCQz/6zsvxF4fma+ZVy7FcCKsvts4Pu7GfZQ4IfTnFotYwzCHAZljEGYw6CMMQhzGJQxBmEOszXGMzJzaKKKOdO84SnLzNXA6jZtI2IkM4enc3u1jDEIcxiUMQZhDoMyxiDMYVDGGIQ5DMIYM7Essw04rGN/YSmTJM2SmQj3G4DFEXFEROwHvA5YNwO3I0maRN+XZTLzkYh4C/AVYF/g45l52zSHbbV88xsyxiDMYVDGGIQ5DMoYgzCHQRljEOawx8fo+weqkqQ9z1+oSlKFDHdJqpDhLkkV2mPfcx90Hd/0+Z/M/FpEvAF4IbAJWJ2Zv2gxxm8Br6b5auijwH8DF2fmj2du5v0XEWcBl2fmlj09l50i4sU0v4a+NTO/Osu3fRSwALg+M3/SUb4kM7/cov9xQGbmDeVPcywBvpeZV7a8/ecDmzLzxxHxBGAlcCzwXeD9mbmj93s1fRFxYWa+aU/c9nSV53QpzfMKzde312Xmpj03q+nxA9VJRMRFNC9+TwQeBA4APg+cSPO4LevS/yzgVcA3gJOBm8o4fwT8RWZeO2OT77OI2AH8FLgD+DTw2cwc68O4T83M7S3bfjszjyvbfw6cCVwOvAL498xcNd35tJzHWeW2NwHHAGdn5hWlbkNmHtul/zk0f3dpDnAV8HzgGuDlwFcy8+9azOE24OjyzbTVwEPAZTTH5tGZ+eqp3r8y/hmZeUGXNuO/3hzAy4CrATLz1OnMYToi4pDMvL+H9u8CXk/zp1K2luKFNCd3l8zWsdV3mTlwF+BAYBXwPeBHwP00/5hWAXNb9F8ybqw1wEbgYmBeyzlsLNdzgPuAfct+7Kzr0v+Wjj5PBK4t24cDN/XpcfpSizZPA86n+WNuhwB/W+Z2KTC/5e3cRLOE94ryWI4BXwaWAU9uOcbB4y6HAHcCBwEHt5lDx/YNwFDZfhJwS8s5PAX4e+CTwBvG1Z3XcoxbgAPK9iJghCbgd5ljt+OiHBM/Bp5Syp/Q5rgqbTd1bG8YV3dzH46ru1u02QB8Cngp8JJyfU/ZfkkPt7UB+BvgmVOc6yrg0LI9DGwGRoG72s6D5h314yYo3w+4veUYwzQv0p+iead+FbCjHKvPbTnGAcB7gdtK3zHgOuDNU3lsBnXN/VLgAeClmXlwZh5Cc1bwQKnr5v0d2x+kOej+kOaB/mjLOexTlmaeTPMP8cBSvj/wuJZj7Fz22p/miSMz7+6hPxFx7CSX59GcOXbzCZq361toDr6Had5J/Afwry2nkZn5y8z8amYuB54OnEeznLC55Rg/BG7suIzQvAXeULa72SciDoqIQ2jeOY2Vif0UeKTlHC6geXH+HPC6iPhcROxf6o5vOcY+WZZiMvNOmlA7KSI+VMbu5pHMfDQzHwLuyLJEl5kPA79sOYdbI+KMsv2diBgGiIhnAV2XC0vbjZNcbgHmtRhimOZ5fDewI5t3og9n5tcz8+st7wc0L+5zgWsi4tsR8baIeHoP/U/JzJ1/e+UfgT/JzCNp3gl9sOUYv6Q5psebT/vn5DzgH4AvAt8CPpqZB9IsmZ3XcoyLaP49vRJ4D3Au8EbgZRHx/t11nNB0X+Vn4gJ8fyp1HW02dGzfPK6u1ZkN8LbyQN8FnAWsBz5Gc+Z1Tov+Z9O8W/gYzTuQM0r5EPCNHh6LR2ne6l4zweXhFv07z3jvHlfX9rGY9IwUeGLLMd5Bc7b/Ox1lP+jhcbizPB8/KNfzS/kBPdyP8cfCu4H/pHkXsaHlGFcDx4wrmwNcCDzaov/1Ox8zmheKneUH9jCHA2letO8o4/2iPCZfp1mWaTPGfTQnB88Yd1lE8zlT2+dlIfBZ4J/HH18t+3f+W/09miC8txzfK1r03wTMKdvXjatr+45uCc3Z/pdofjS0uhyro3SsAnQZY3f/zlq9Uwe+M27/hp3HCc1nMr09tr12mI0L8FXgnXQsodCcTbwL+FqL/luBt5dA2Uz5bKHUtXrrW9o+HXh62Z4LnA4c10P/3y59jprGY3ErsHiSui29HDDA+8bVtT34n9Wn53VnEHyI5h3R5j6M+UTgiJZtN3UGail7M83b4Lt6uA9Pm6TuRS367z9J+aF0vPC1nMtTgKOB59FyubGj7xrgxZPUXTyF5+EUmg9ze+33mBc0mmWrJcAFLfq/teTFCTRLjh+hWRp6D/DJHuaxD827tz8ul+Mpy6ot+/8XzbLla2hOCE8r5S8BRlqO8a2dzwlwKs1nMDvrup7UPma8XjvMxoXmrdoH+PWa+4/KP8wPAAe16H/OuMvO9dmnARfu6fvX42NxOvDsSepOa9H/vZQ14nHlRwKX7aH7dCrNWuK9s3y7/wD8wQTlS2i5tuql78/JJX0Y46XAZ2g+G7oFuJLmz4nPmcX7cTTNn1z5EnBUeZF5sJw4vLDlGL8LfJtm+fmblJMqmnf7Z/U6p73u2zJtPsmfyf6DZG9+LMpX+J6ZmbcOwnMyCHPQrvbm47vf85jKGHtjuN+dmYfvqf6DpJbHYhDmMQhz0K48vqc3xkD+iCkiNk5WRYtP8qfbf5DU8lgMwjwGYQ7alcd3f8foNJDhTnNHXkmz9tQpaD50mOn+g6SWx2IQ5jEIc9CuPL77O8avDGq4f4HmQ8Cbx1dExLWz0H+Q1PJYDMI8BmEO2pXHd3/H+HWfvW3NXZLU3aD+QlWSNA2GuyRVyHCXpAoZ7pJUIcNdkir0/zoqX5Z1392AAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "data['target'].value_counts().plot(kind='bar');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 390
    },
    "id": "LVpruQmD_6WN",
    "outputId": "e0402273-756a-4293-95d9-f1f68ede374e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    target  count\n",
      "0        0    480\n",
      "1        1    584\n",
      "2        2    591\n",
      "3        3    590\n",
      "4        4    578\n",
      "5        5    593\n",
      "6        6    585\n",
      "7        7    594\n",
      "8        8    598\n",
      "9        9    597\n",
      "10      10    600\n",
      "11      11    595\n",
      "12      12    591\n",
      "13      13    594\n",
      "14      14    593\n",
      "15      15    599\n",
      "16      16    546\n",
      "17      17    564\n",
      "18      18    465\n",
      "19      19    377\n"
     ]
    }
   ],
   "source": [
    "print(data.groupby('target').size().reset_index(name='count'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JvNMFSTw_7I0"
   },
   "outputs": [],
   "source": [
    "newsdata_test = fetch_20newsgroups(subset='test', shuffle=True) # 'test'를 기재하면 테스트 데이터만 리턴.\n",
    "train_email = data['email'] # 훈련 데이터의 본문 저장\n",
    "train_label = data['target'] # 훈련 데이터의 레이블 저장\n",
    "test_email = newsdata_test.data # 테스트 데이터의 본문 저장\n",
    "test_label = newsdata_test.target # 테스트 데이터의 레이블 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tQUlukql_8AU"
   },
   "outputs": [],
   "source": [
    "max_words = 10000 # 실습에 사용할 단어의 최대 개수\n",
    "num_classes = 20 # 레이블의 수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "auzMtd0u_8tV"
   },
   "outputs": [],
   "source": [
    "def prepare_data(train_data, test_data, mode): # 전처리 함수\n",
    "    t = Tokenizer(num_words = max_words) # max_words 개수만큼의 단어만 사용.\n",
    "    t.fit_on_texts(train_data)\n",
    "    X_train = t.texts_to_matrix(train_data, mode=mode) # 샘플 수 × max_words 크기의 행렬 생성\n",
    "    X_test = t.texts_to_matrix(test_data, mode=mode) # 샘플 수 × max_words 크기의 행렬 생성\n",
    "    return X_train, X_test, t.index_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "piiW0JVM_9a0"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, index_to_word = prepare_data(train_email, test_email, 'binary') # binary 모드로 변환\n",
    "y_train = to_categorical(train_label, num_classes) # 원-핫 인코딩\n",
    "y_test = to_categorical(test_label, num_classes) # 원-핫 인코딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 87
    },
    "id": "QjfZTAgq_-fk",
    "outputId": "ee378769-afaa-4b25-aff2-7cdccfb793ed"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 샘플 본문의 크기 : (11314, 10000)\n",
      "훈련 샘플 레이블의 크기 : (11314, 20)\n",
      "테스트 샘플 본문의 크기 : (7532, 10000)\n",
      "테스트 샘플 레이블의 크기 : (7532, 20)\n"
     ]
    }
   ],
   "source": [
    "print('훈련 샘플 본문의 크기 : {}'.format(X_train.shape))\n",
    "print('훈련 샘플 레이블의 크기 : {}'.format(y_train.shape))\n",
    "print('테스트 샘플 본문의 크기 : {}'.format(X_test.shape))\n",
    "print('테스트 샘플 레이블의 크기 : {}'.format(y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "id": "ylqiP846__cU",
    "outputId": "ab15d803-d498-48f6-9962-1ea600e822e1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "빈도수 상위 1번 단어 : the\n",
      "빈도수 상위 9999번 단어 : mic\n"
     ]
    }
   ],
   "source": [
    "print('빈도수 상위 1번 단어 : {}'.format(index_to_word[1]))\n",
    "print('빈도수 상위 9999번 단어 : {}'.format(index_to_word[9999]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iMgQGHNtAAOE"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yfqotVlaABTc"
   },
   "outputs": [],
   "source": [
    "def fit_and_evaluate(X_train, y_train, X_test, y_test):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(256, input_shape=(10000,), activation='relu'))\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dense(20, activation='softmax'))\n",
    "    # 입력층이 10000, 은닉층 #1이 256, 은닉층 #2가 128, 출력층이 20\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    model.fit(X_train, y_train, batch_size=128, epochs=5, verbose=1, validation_split=0.1)\n",
    "    score = model.evaluate(X_test, y_test, batch_size=128, verbose=0)\n",
    "    return score[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 798
    },
    "id": "4hKd26WCACA1",
    "outputId": "5a584f5f-3ca2-4006-a62f-74dbc601b44b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "80/80 [==============================] - 1s 14ms/step - loss: 2.3028 - accuracy: 0.3381 - val_loss: 0.9875 - val_accuracy: 0.8348\n",
      "Epoch 2/5\n",
      "80/80 [==============================] - 1s 7ms/step - loss: 0.8687 - accuracy: 0.7612 - val_loss: 0.4757 - val_accuracy: 0.8772\n",
      "Epoch 3/5\n",
      "80/80 [==============================] - 1s 6ms/step - loss: 0.4369 - accuracy: 0.8840 - val_loss: 0.3406 - val_accuracy: 0.9108\n",
      "Epoch 4/5\n",
      "80/80 [==============================] - 1s 7ms/step - loss: 0.2592 - accuracy: 0.9350 - val_loss: 0.3160 - val_accuracy: 0.9152\n",
      "Epoch 5/5\n",
      "80/80 [==============================] - 1s 6ms/step - loss: 0.1853 - accuracy: 0.9557 - val_loss: 0.3072 - val_accuracy: 0.9099\n",
      "binary 모드의 테스트 정확도: 0.8266064524650574\n",
      "Epoch 1/5\n",
      "80/80 [==============================] - 1s 9ms/step - loss: 2.7914 - accuracy: 0.2474 - val_loss: 1.6552 - val_accuracy: 0.7323\n",
      "Epoch 2/5\n",
      "80/80 [==============================] - 1s 7ms/step - loss: 1.5090 - accuracy: 0.6208 - val_loss: 0.7008 - val_accuracy: 0.8498\n",
      "Epoch 3/5\n",
      "80/80 [==============================] - 1s 7ms/step - loss: 0.7983 - accuracy: 0.7967 - val_loss: 0.5172 - val_accuracy: 0.8781\n",
      "Epoch 4/5\n",
      "80/80 [==============================] - 1s 7ms/step - loss: 0.5545 - accuracy: 0.8729 - val_loss: 0.4377 - val_accuracy: 0.8869\n",
      "Epoch 5/5\n",
      "80/80 [==============================] - 1s 7ms/step - loss: 0.3685 - accuracy: 0.9099 - val_loss: 0.4089 - val_accuracy: 0.9002\n",
      "count 모드의 테스트 정확도: 0.8231545686721802\n",
      "Epoch 1/5\n",
      "80/80 [==============================] - 1s 8ms/step - loss: 2.2821 - accuracy: 0.3490 - val_loss: 0.8281 - val_accuracy: 0.8251\n",
      "Epoch 2/5\n",
      "80/80 [==============================] - 1s 6ms/step - loss: 0.8724 - accuracy: 0.7606 - val_loss: 0.4360 - val_accuracy: 0.8852\n",
      "Epoch 3/5\n",
      "80/80 [==============================] - 1s 6ms/step - loss: 0.4543 - accuracy: 0.8834 - val_loss: 0.3352 - val_accuracy: 0.9170\n",
      "Epoch 4/5\n",
      "80/80 [==============================] - 1s 6ms/step - loss: 0.2937 - accuracy: 0.9208 - val_loss: 0.3133 - val_accuracy: 0.9170\n",
      "Epoch 5/5\n",
      "80/80 [==============================] - 1s 6ms/step - loss: 0.2235 - accuracy: 0.9482 - val_loss: 0.3082 - val_accuracy: 0.9214\n",
      "tfidf 모드의 테스트 정확도: 0.8299256563186646\n",
      "Epoch 1/5\n",
      "80/80 [==============================] - 1s 8ms/step - loss: 2.9774 - accuracy: 0.0817 - val_loss: 2.9279 - val_accuracy: 0.1979\n",
      "Epoch 2/5\n",
      "80/80 [==============================] - 1s 6ms/step - loss: 2.7257 - accuracy: 0.2030 - val_loss: 2.4177 - val_accuracy: 0.3375\n",
      "Epoch 3/5\n",
      "80/80 [==============================] - 1s 6ms/step - loss: 2.2235 - accuracy: 0.3175 - val_loss: 1.9183 - val_accuracy: 0.5707\n",
      "Epoch 4/5\n",
      "80/80 [==============================] - 1s 6ms/step - loss: 1.7766 - accuracy: 0.4633 - val_loss: 1.4974 - val_accuracy: 0.6678\n",
      "Epoch 5/5\n",
      "80/80 [==============================] - 0s 6ms/step - loss: 1.4017 - accuracy: 0.5830 - val_loss: 1.1749 - val_accuracy: 0.7217\n",
      "freq 모드의 테스트 정확도: 0.6687467098236084\n"
     ]
    }
   ],
   "source": [
    "modes = ['binary', 'count', 'tfidf', 'freq'] # 4개의 모드를 리스트에 저장.\n",
    "\n",
    "for mode in modes: # 4개의 모드에 대해서 각각 아래의 작업을 반복.\n",
    "    X_train, X_test, _ = prepare_data(train_email, test_email, mode) # 모드에 따라서 데이터를 전처리\n",
    "    score = fit_and_evaluate(X_train, y_train, X_test, y_test) # 모델을 훈련하고 평가.\n",
    "    print(mode+' 모드의 테스트 정확도:', score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XsHM192jK1vU"
   },
   "source": [
    "# 함수형 API 이야기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fG0IzJuXK3qc"
   },
   "source": [
    "## sequential API로 만든 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YmPQHJ3XK5kZ"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "model=Sequential()\n",
    "model.add(Dense(3, input_dim=4, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MkTnwPehK93s"
   },
   "source": [
    "## functional API로 만든 모델"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "df4VjgahL0Wa"
   },
   "source": [
    "앞에서 케라스를 사용하여 모델을 설계하는 방식을 sequential API를 사용하였다고 함. 그런데 sequential API는 여러층을 공유하거나 다양한 종류의 입력과 출력을 사용하는 등의 복잡한 모델을 만드는 일을 하기에는 한계가 있음. 이번에는 복잡한 모델을 생성할 수 있는 방식인 functional API(함수형 API)에 대해서 알아봄."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JJk-9sqZL4dp"
   },
   "source": [
    "functional API는 각 층을 일종의 함수(function)로서 정의. 그리고 각 함수를 조합하기 위한 연산자들을 제공하는데, 이를 이용하여 신경망을 설계. functional API로 FFNN, RNN 등 다양한 모델을 만들면서 기존의 sequential API와의 차이를 이해.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QFTLoLMTLCeH"
   },
   "source": [
    "### 피드 포워드 신경망"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nIeK_HXwK_jA"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "# 입력\n",
    "inputs = Input(shape=(10,))\n",
    "\n",
    "hidden1 = Dense(64, activation='relu')(inputs)\n",
    "hidden2 = Dense(64, activation='relu')(hidden1)\n",
    "\n",
    "# 출력\n",
    "output = Dense(1, activation='sigmoid')(hidden2)\n",
    "\n",
    "# 입력과 출력 정의\n",
    "model = Model(inputs=inputs, outputs=output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yYF18dFoLNRP"
   },
   "source": [
    "### 선형 회귀"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-rdcF2s2LRQq"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "inputs = Input(shape=(3,))\n",
    "output = Dense(1, activation='linear')(inputs)\n",
    "linear_model = Model(inputs, output)\n",
    "\n",
    "linear_model.compile(optimizer='sgd', loss='mse')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vnzck6bmLbBu"
   },
   "source": [
    "### 로지스틱 회귀"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "g38giGvyLcL6"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "inputs = Input(shape=(3,))\n",
    "output = Dense(1, activation='sigmoid')(inputs)\n",
    "logistic_model = Model(inputs, output)\n",
    "\n",
    "logistic_model.compile(optimizer='sgd', loss = 'binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5S6Q1aZmLfL3"
   },
   "source": [
    "### 다중 입력을 받는 모델(model that accepts multiple inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CurzrkxLLhqD"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input, Dense, concatenate\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "# 두 개의 입력층을 정의\n",
    "inputA = Input(shape=(64,))\n",
    "inputB = Input(shape=(128,))\n",
    "\n",
    "# 첫번째 입력층으로부터 분기되어 진행되는 인공 신경망을 정의\n",
    "x = Dense(16, activation=\"relu\")(inputA)\n",
    "x = Dense(8, activation=\"relu\")(x)\n",
    "x = Model(inputs=inputA, outputs=x)\n",
    "\n",
    "# 두번째 입력층으로부터 분기되어 진행되는 인공 신경망을 정의\n",
    "y = Dense(64, activation=\"relu\")(inputB)\n",
    "y = Dense(32, activation=\"relu\")(y)\n",
    "y = Dense(8, activation=\"relu\")(y)\n",
    "y = Model(inputs=inputB, outputs=y)\n",
    "\n",
    "# 두개의 인공 신경망의 출력을 연결(concatenate)\n",
    "result = concatenate([x.output, y.output])\n",
    "\n",
    "# 연결된 값을 입력으로 받는 밀집층을 추가(Dense layer)\n",
    "z = Dense(2, activation=\"relu\")(result)\n",
    "# 선형 회귀를 위해 activation=linear를 설정\n",
    "z = Dense(1, activation=\"linear\")(z)\n",
    "\n",
    "# 결과적으로 이 모델은 두 개의 입력층으로부터 분기되어 진행된 후 마지막에는 하나의 출력을 예측하는 모델이 됨.\n",
    "model = Model(inputs=[x.input, y.input], outputs=z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B3uTuvhsLldi"
   },
   "source": [
    "### 다르게 보이지만 동일한 표기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1bOip8kdLndI"
   },
   "source": [
    "encoder = Dense(128)(input)  \n",
    "\n",
    "이와 같은 표현은  \n",
    "\n",
    "encoder = Dense(128)  \n",
    "encoder(input)\n",
    "\n",
    "이 표현과 같음."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "QG_BPc4o-_jc",
    "FyL3hSOoJDzs",
    "NVVaHQ-rJIEy",
    "KZkN9y5BJLGP",
    "nEEbNRvTJjHw",
    "uo2vTvP3JtMH",
    "lqZ5f4wNJzzo",
    "M5NRpIp8J5QI",
    "tWBTaTvoKBWf",
    "vloTgnLOBEvj",
    "W0TUbK48Ec59",
    "MNeBoHQ2Hjyh",
    "db_z1dvBHl8J",
    "6VpSK_S5BSsO",
    "IPZ78iD2BpDl",
    "xOVfLLqvB_q0",
    "YaMqLWD0U0Kd",
    "TwnK5eYPONF1",
    "ewfoQrKdCIQa",
    "7SbQah4u_bKx",
    "XsHM192jK1vU",
    "fG0IzJuXK3qc",
    "MkTnwPehK93s",
    "QFTLoLMTLCeH",
    "yYF18dFoLNRP",
    "vnzck6bmLbBu",
    "5S6Q1aZmLfL3",
    "B3uTuvhsLldi",
    "AShjrishFP9W",
    "MYZPxP-TFqLq",
    "NFzimbZBFwgo",
    "t4tAK15-GJiN",
    "VVfhi2tTHPVl",
    "DigXtkNpHnuZ",
    "nh-YlIvnHySl"
   ],
   "machine_shape": "hm",
   "name": "learning spoons 2강.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
