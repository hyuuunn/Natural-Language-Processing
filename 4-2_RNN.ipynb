{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tISU0nwyf-cf"
   },
   "source": [
    "# 1. 순환 신경망 RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sbe5iO0mAUYd"
   },
   "source": [
    "## Numpy로 순환 신경망 구현하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JYgSWKuLAW4D"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "timesteps = 10 # 시점의 수. NLP에서는 보통 문장의 길이가 된다.\n",
    "input_dim = 4 # 입력의 차원. NLP에서는 보통 단어 벡터의 차원이 된다.\n",
    "hidden_size = 8 # 은닉 상태의 크기. 메모리 셀의 용량이다.\n",
    "\n",
    "inputs = np.random.random((timesteps, input_dim)) # 입력에 해당되는 2D 텐서\n",
    "\n",
    "# 은닉 상태의 크기 hidden_size로 은닉 상태를 만든다.\n",
    "hidden_state_t = np.zeros((hidden_size,)) # 초기 은닉 상태는 0(벡터)로 초기화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "id": "oxtMec2tAbCc",
    "outputId": "91328e56-f650-4191-85de-d281759395d2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "print(hidden_state_t) # 8의 크기를 가지는 은닉 상태. 현재는 초기 은닉 상태로 모든 차원이 0의 값을 가짐."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7K0DCudXAc4L"
   },
   "outputs": [],
   "source": [
    "Wx = np.random.random((hidden_size, input_dim))  # (8, 4)크기의 2D 텐서 생성. 입력에 대한 가중치.\n",
    "Wh = np.random.random((hidden_size, hidden_size)) # (8, 8)크기의 2D 텐서 생성. 은닉 상태에 대한 가중치.\n",
    "b = np.random.random((hidden_size,)) # (8,)크기의 1D 텐서 생성. 이 값은 편향(bias)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 73
    },
    "id": "81P8rfX4AfqN",
    "outputId": "fef167b4-5590-49ff-dedb-cec4713ef42c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8, 4)\n",
      "(8, 8)\n",
      "(8,)\n"
     ]
    }
   ],
   "source": [
    "print(np.shape(Wx))\n",
    "print(np.shape(Wh))\n",
    "print(np.shape(b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 574
    },
    "id": "AAVic5BiAge_",
    "outputId": "23010fa9-1799-4051-f4ac-61531a9186a1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 8)\n",
      "(2, 8)\n",
      "(3, 8)\n",
      "(4, 8)\n",
      "(5, 8)\n",
      "(6, 8)\n",
      "(7, 8)\n",
      "(8, 8)\n",
      "(9, 8)\n",
      "(10, 8)\n",
      "[[0.91391596 0.91198046 0.973877   0.41717514 0.90204106 0.90876622\n",
      "  0.8869713  0.85048275]\n",
      " [0.99999893 0.99998373 0.99998539 0.99922499 0.99995356 0.99974347\n",
      "  0.99976692 0.99948329]\n",
      " [0.99999967 0.99998751 0.99999478 0.99988551 0.99999334 0.99990435\n",
      "  0.99993471 0.99956022]\n",
      " [0.9999998  0.99999151 0.99999463 0.99987614 0.99999498 0.9999452\n",
      "  0.99993689 0.99974377]\n",
      " [0.99999943 0.99999042 0.99999444 0.99979308 0.99997669 0.99987004\n",
      "  0.99987005 0.99972147]\n",
      " [0.99999976 0.99999084 0.9999963  0.99988601 0.99999445 0.99993322\n",
      "  0.99994933 0.99973169]\n",
      " [0.99999959 0.99998847 0.99999123 0.99980814 0.9999892  0.99980489\n",
      "  0.99989285 0.99941045]\n",
      " [0.99999979 0.99999094 0.99999586 0.99988305 0.99999582 0.99992009\n",
      "  0.99995453 0.99966936]\n",
      " [0.9999999  0.99999636 0.99999762 0.99984534 0.99999629 0.9999648\n",
      "  0.99996473 0.99991356]\n",
      " [0.99999968 0.99999062 0.99999127 0.99982809 0.99998916 0.99992403\n",
      "  0.99987553 0.99970603]]\n"
     ]
    }
   ],
   "source": [
    "total_hidden_states = []\n",
    "\n",
    "# 메모리 셀 동작\n",
    "for input_t in inputs: # 각 시점에 따라서 입력값이 입력됨.\n",
    "  output_t = np.tanh(np.dot(Wx,input_t) + np.dot(Wh,hidden_state_t) + b) # Wx * Xt + Wh * Ht-1 + b(bias)\n",
    "  total_hidden_states.append(list(output_t)) # 각 시점의 은닉 상태의 값을 계속해서 축적\n",
    "  print(np.shape(total_hidden_states)) # 각 시점 t별 메모리 셀의 출력의 크기는 (timestep, output_dim)\n",
    "  hidden_state_t = output_t\n",
    "\n",
    "total_hidden_states = np.stack(total_hidden_states, axis = 0) \n",
    "# 출력 시 값을 깔끔하게 해준다.\n",
    "\n",
    "print(total_hidden_states) # (timesteps, output_dim)의 크기. 이 경우 (10, 8)의 크기를 가지는 메모리 셀의 2D 텐서를 출력."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e3fe-sgyAR8k"
   },
   "source": [
    "## 순환 신경망 구현 이해하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "A9i9jTim_d2y"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import SimpleRNN, Bidirectional, LSTM, GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LFYnTDyo_q6S",
    "outputId": "978ee0dd-d3e9-4ad8-9ddd-95015460d10e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "simple_rnn_2 (SimpleRNN)     (None, 3)                 42        \n",
      "=================================================================\n",
      "Total params: 42\n",
      "Trainable params: 42\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(SimpleRNN(3, input_shape=(2, 10)))\n",
    "# model.add(SimpleRNN(3, input_length=2, input_dim=10))와 동일.\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3TmThonZAI4S"
   },
   "source": [
    "input_length = time_step"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2JuGB51aBxmb"
   },
   "source": [
    "파라미터수가 왜 42가 되는지 생각. 입력 차원이 10일 때, hidden_size는 3.  \n",
    "참고로 time_step은 파라미터 수에 전혀 영향을 주지 않음.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pFUpMd5F_34u"
   },
   "source": [
    "출력값이 (batch_size, output_dim) 크기의 2D 텐서일 때, output_dim은 hidden_size의 값인 3. 이 경우 batch_size를 현 단계에서는 알 수 없으므로 (None, 3)이 됨. 이번에는 batch_size를 미리 정의."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uhhpGupVmppI",
    "outputId": "94df1325-0027-465f-823a-d2d2e6ad7461"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "simple_rnn_3 (SimpleRNN)     (None, 10, 3)             42        \n",
      "=================================================================\n",
      "Total params: 42\n",
      "Trainable params: 42\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(SimpleRNN(3, input_shape=(10,10), return_sequences=True))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bgHZP_AKmsui"
   },
   "source": [
    "배치 크기는 추정이 안 되므로 None이고, 문장의 길이. 즉, timesteps는 10이므로 (None, 10, 3)입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 194
    },
    "id": "F0adsrlU_6Mh",
    "outputId": "b51cf965-904a-46b9-f273-4bc6c16a8bc1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "simple_rnn_1 (SimpleRNN)     (8, 3)                    42        \n",
      "=================================================================\n",
      "Total params: 42\n",
      "Trainable params: 42\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(SimpleRNN(3, batch_input_shape=(8,2,10)))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PyMJG-0C_882"
   },
   "source": [
    "batch_size를 8로 기재하자, 출력의 크기가 (8, 3)이 된 것을 볼 수 있음. 이제 return_sequences 매개 변수에 True를 기재하여 출력값으로 (batch_size, timesteps, output_dim) 크기의 3D 텐서를 리턴하도록 모델을 생성."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 194
    },
    "id": "IffYIPFTAAAw",
    "outputId": "a8938f80-9afb-47e1-ad42-579cfd6ad942"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "simple_rnn_2 (SimpleRNN)     (8, 2, 3)                 42        \n",
      "=================================================================\n",
      "Total params: 42\n",
      "Trainable params: 42\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(SimpleRNN(3, batch_input_shape=(8,2,10), return_sequences=True))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lz3rctYIAA0p"
   },
   "source": [
    "출력의 크기가 (8, 2, 3)이 된 것을 확인할 수 있음."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TI0LaKEQArI8"
   },
   "source": [
    "## 은닉층이 2개인 깊은 순환 신경망"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sS41QIGxAuQC"
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(SimpleRNN(hidden_size, return_sequences = True))\n",
    "model.add(SimpleRNN(hidden_size, return_sequences = True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zm9KCtglA04x"
   },
   "source": [
    "## 양방향 순환 신경망"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eVOz_RyLA1t7"
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Bidirectional(SimpleRNN(hidden_size, return_sequences = True), input_shape=(timesteps, input_dim)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZVI6mRPfBLjo"
   },
   "source": [
    "## 깊은 양방향 순환 신경망"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "t1lHo1HyBOci"
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Bidirectional(SimpleRNN(hidden_size, return_sequences = True), input_shape=(timesteps, input_dim)))\n",
    "model.add(Bidirectional(SimpleRNN(hidden_size, return_sequences = True)))\n",
    "model.add(Bidirectional(SimpleRNN(hidden_size, return_sequences = True)))\n",
    "model.add(Bidirectional(SimpleRNN(hidden_size, return_sequences = True)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q2wie_xuBSVF"
   },
   "source": [
    "## LSTM 구현하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tkdVSJslBeLw"
   },
   "outputs": [],
   "source": [
    "# 실제 LSTM 은닉층을 추가하는 코드.\n",
    "model = Sequential()\n",
    "model.add(LSTM(hidden_size, input_shape=(timesteps, input_dim)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dgJ6cjdzBaEz"
   },
   "source": [
    "## GRU 구현하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "us9f0EKPBU3C"
   },
   "outputs": [],
   "source": [
    "# 실제 GRU 은닉층을 추가하는 코드.\n",
    "model = Sequential()\n",
    "model.add(GRU(hidden_size, input_shape=(timesteps, input_dim)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OyI8PfV_CUyp"
   },
   "source": [
    "# RNN 언어 모델 (char 단위)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-buBGWx3DXAB"
   },
   "source": [
    "## 데이터 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qpjGG-huCXsQ"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import urllib.request\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aIviUeahCZ81"
   },
   "outputs": [],
   "source": [
    "urllib.request.urlretrieve(\"http://www.gutenberg.org/files/11/11-0.txt\", filename=\"11-0.txt\")\n",
    "f = open('11-0.txt', 'rb')\n",
    "lines=[]\n",
    "for line in f: # 데이터를 한 줄씩 읽는다.\n",
    "    line=line.strip() # strip()을 통해 \\r, \\n을 제거한다.\n",
    "    line=line.lower() # 소문자화.\n",
    "    line=line.decode('ascii', 'ignore') # \\xe2\\x80\\x99 등과 같은 바이트 열 제거\n",
    "    if len(line) > 0:\n",
    "        lines.append(line)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 105
    },
    "id": "iqgBNqfMCblA",
    "outputId": "dc288e9f-e64e-4b8d-c1db-5b5edaa1f498"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['the project gutenberg ebook of alices adventures in wonderland, by lewis carroll',\n",
       " 'this ebook is for the use of anyone anywhere at no cost and with',\n",
       " 'almost no restrictions whatsoever.  you may copy it, give it away or',\n",
       " 're-use it under the terms of the project gutenberg license included',\n",
       " 'with this ebook or online at www.gutenberg.org']"
      ]
     },
     "execution_count": 56,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "jr0hQIn9CdJ1",
    "outputId": "5637beff-764d-4d0b-f60a-b02c909fe56b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "문자열의 길이 또는 총 글자의 개수: 159612\n"
     ]
    }
   ],
   "source": [
    "text = ' '.join(lines)\n",
    "print('문자열의 길이 또는 총 글자의 개수: %d' % len(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "id": "dQi7EiSfCe7L",
    "outputId": "3abcc719-3fc0-4a51-c342-dd4385b1d728"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the project gutenberg ebook of alices adventures in wonderland, by lewis carroll this ebook is for the use of anyone anywhere at no cost and with almost no restrictions whatsoever.  you may copy it, g\n"
     ]
    }
   ],
   "source": [
    "print(text[:200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "GuKxqL-4ChLY",
    "outputId": "cbd70df0-99c9-47cf-a729-ef2c254f865a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "글자 집합의 크기 : 57\n"
     ]
    }
   ],
   "source": [
    "char_vocab = sorted(list(set(text)))\n",
    "vocab_size=len(char_vocab)\n",
    "print ('글자 집합의 크기 : {}'.format(vocab_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "id": "5SllSQxGCknd",
    "outputId": "ac878c4d-ca2c-42da-d22a-e06b80f7953b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{' ': 0, '!': 1, '\"': 2, '#': 3, '$': 4, '%': 5, \"'\": 6, '(': 7, ')': 8, '*': 9, ',': 10, '-': 11, '.': 12, '/': 13, '0': 14, '1': 15, '2': 16, '3': 17, '4': 18, '5': 19, '6': 20, '7': 21, '8': 22, '9': 23, ':': 24, ';': 25, '?': 26, '@': 27, '[': 28, ']': 29, '_': 30, 'a': 31, 'b': 32, 'c': 33, 'd': 34, 'e': 35, 'f': 36, 'g': 37, 'h': 38, 'i': 39, 'j': 40, 'k': 41, 'l': 42, 'm': 43, 'n': 44, 'o': 45, 'p': 46, 'q': 47, 'r': 48, 's': 49, 't': 50, 'u': 51, 'v': 52, 'w': 53, 'x': 54, 'y': 55, 'z': 56}\n"
     ]
    }
   ],
   "source": [
    "char_to_index = dict((c, i) for i, c in enumerate(char_vocab)) # 글자에 고유한 정수 인덱스 부여\n",
    "print(char_to_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Qw63xAvhCl0y"
   },
   "outputs": [],
   "source": [
    "index_to_char={}\n",
    "for key, value in char_to_index.items():\n",
    "    index_to_char[value] = key"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "igs67pDSCsls"
   },
   "source": [
    "Example) 샘플의 길이가 4라면 4개의 입력 글자 시퀀스로 부터 4개의 출력 글자  시퀀스를 예측.  \n",
    "즉, RNN의 time step은 4번  \n",
    "appl -> pple  \n",
    "appl은 train_X(입력 시퀀스), pple는 train_y(예측해야하는 시퀀스)에 저장한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "SUw8y3n9C0Ce",
    "outputId": "448ee1fa-6149-490d-e2e4-24204db95ff5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "문장 샘플의 수 : 2660\n"
     ]
    }
   ],
   "source": [
    "seq_length = 60 # 문장의 길이를 60으로 한다.\n",
    "n_samples = int(np.floor((len(text) - 1) / seq_length)) # 문자열을 60등분한다. 그러면 즉, 총 샘플의 개수\n",
    "print ('문장 샘플의 수 : {}'.format(n_samples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oqEDviN6C02A"
   },
   "outputs": [],
   "source": [
    "train_X = []\n",
    "train_y = []\n",
    "\n",
    "for i in range(n_samples): # 2,646번 수행\n",
    "    X_sample = text[i * seq_length: (i + 1) * seq_length]\n",
    "    # 0:60 -> 60:120 -> 120:180로 loop를 돌면서 문장 샘플을 1개씩 가져온다.\n",
    "    X_encoded = [char_to_index[c] for c in X_sample] # 하나의 문장 샘플에 대해서 정수 인코딩\n",
    "    train_X.append(X_encoded)\n",
    "\n",
    "    y_sample = text[i * seq_length + 1: (i + 1) * seq_length + 1] # 오른쪽으로 1칸 쉬프트한다.\n",
    "    y_encoded = [char_to_index[c] for c in y_sample]\n",
    "    train_y.append(y_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "id": "vrqxQY8HC2du",
    "outputId": "c3a6c9c6-39ca-4339-cc32-c38228cfe04e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[50, 38, 35, 0, 46, 48, 45, 40, 35, 33, 50, 0, 37, 51, 50, 35, 44, 32, 35, 48, 37, 0, 35, 32, 45, 45, 41, 0, 45, 36, 0, 31, 42, 39, 33, 35, 49, 0, 31, 34, 52, 35, 44, 50, 51, 48, 35, 49, 0, 39, 44, 0, 53, 45, 44, 34, 35, 48, 42, 31]\n"
     ]
    }
   ],
   "source": [
    "print(train_X[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "id": "fFKlFFB6C4EV",
    "outputId": "1052d0eb-e4ad-4f0e-9e81-81395a7d66c5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[38, 35, 0, 46, 48, 45, 40, 35, 33, 50, 0, 37, 51, 50, 35, 44, 32, 35, 48, 37, 0, 35, 32, 45, 45, 41, 0, 45, 36, 0, 31, 42, 39, 33, 35, 49, 0, 31, 34, 52, 35, 44, 50, 51, 48, 35, 49, 0, 39, 44, 0, 53, 45, 44, 34, 35, 48, 42, 31, 44]\n"
     ]
    }
   ],
   "source": [
    "print(train_y[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "id": "8vtl0kRyC5zX",
    "outputId": "99a5d4e5-8d09-4afe-d703-738724d83b6f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[44, 34, 10, 0, 32, 55, 0, 42, 35, 53, 39, 49, 0, 33, 31, 48, 48, 45, 42, 42, 0, 50, 38, 39, 49, 0, 35, 32, 45, 45, 41, 0, 39, 49, 0, 36, 45, 48, 0, 50, 38, 35, 0, 51, 49, 35, 0, 45, 36, 0, 31, 44, 55, 45, 44, 35, 0, 31, 44, 55]\n"
     ]
    }
   ],
   "source": [
    "print(train_X[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "id": "luNetvQdC7zf",
    "outputId": "37c43d43-89d9-4ce1-b033-39abc508c672"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[34, 10, 0, 32, 55, 0, 42, 35, 53, 39, 49, 0, 33, 31, 48, 48, 45, 42, 42, 0, 50, 38, 39, 49, 0, 35, 32, 45, 45, 41, 0, 39, 49, 0, 36, 45, 48, 0, 50, 38, 35, 0, 51, 49, 35, 0, 45, 36, 0, 31, 44, 55, 45, 44, 35, 0, 31, 44, 55, 53]\n"
     ]
    }
   ],
   "source": [
    "print(train_y[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wBKMxF4HC97Y"
   },
   "outputs": [],
   "source": [
    "train_X = to_categorical(train_X)\n",
    "train_y = to_categorical(train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "id": "QgEQqIziC_yA",
    "outputId": "72a23a86-bdb1-4b0e-90f5-ab923201625a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_X의 크기(shape) : (2660, 60, 57)\n",
      "train_y의 크기(shape) : (2660, 60, 57)\n"
     ]
    }
   ],
   "source": [
    "print('train_X의 크기(shape) : {}'.format(train_X.shape)) # 원-핫 인코딩\n",
    "print('train_y의 크기(shape) : {}'.format(train_y.shape)) # 원-핫 인코딩"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dkatA_B6DNTf"
   },
   "source": [
    "이는 샘플의 수(No. of samples)가 2,646개, 입력 시퀀스의 길이(input_length)가 60, 각 벡터의 차원(input_dim)이 57임을 의미. 원-핫 벡터의 차원은 글자 집합의 크기인 57이어야 하므로 원-핫 인코딩이 수행되었음을 알 수 있음."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8LBxXx3BDZn0"
   },
   "source": [
    "## 모델 설계하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "T_w8w5A_DapQ"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM, TimeDistributed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MS2YHs3oDcXG"
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(256, input_shape=(None, train_X.shape[2]), return_sequences=True))\n",
    "model.add(LSTM(256, return_sequences=True))\n",
    "model.add(TimeDistributed(Dense(vocab_size, activation='softmax')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "dt2VeC_RDdjC",
    "outputId": "39f9e5a2-9287-4282-b150-7256c34bff34"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/80\n",
      "84/84 - 1s - loss: 3.0858 - accuracy: 0.1806\n",
      "Epoch 2/80\n",
      "84/84 - 1s - loss: 2.7181 - accuracy: 0.2567\n",
      "Epoch 3/80\n",
      "84/84 - 1s - loss: 2.3902 - accuracy: 0.3287\n",
      "Epoch 4/80\n",
      "84/84 - 1s - loss: 2.2475 - accuracy: 0.3604\n",
      "Epoch 5/80\n",
      "84/84 - 1s - loss: 2.1407 - accuracy: 0.3877\n",
      "Epoch 6/80\n",
      "84/84 - 1s - loss: 2.0551 - accuracy: 0.4075\n",
      "Epoch 7/80\n",
      "84/84 - 1s - loss: 1.9821 - accuracy: 0.4268\n",
      "Epoch 8/80\n",
      "84/84 - 1s - loss: 1.9216 - accuracy: 0.4424\n",
      "Epoch 9/80\n",
      "84/84 - 1s - loss: 1.8667 - accuracy: 0.4600\n",
      "Epoch 10/80\n",
      "84/84 - 1s - loss: 1.8173 - accuracy: 0.4732\n",
      "Epoch 11/80\n",
      "84/84 - 1s - loss: 1.7725 - accuracy: 0.4839\n",
      "Epoch 12/80\n",
      "84/84 - 1s - loss: 1.7363 - accuracy: 0.4944\n",
      "Epoch 13/80\n",
      "84/84 - 1s - loss: 1.6948 - accuracy: 0.5052\n",
      "Epoch 14/80\n",
      "84/84 - 1s - loss: 1.6600 - accuracy: 0.5146\n",
      "Epoch 15/80\n",
      "84/84 - 1s - loss: 1.6235 - accuracy: 0.5238\n",
      "Epoch 16/80\n",
      "84/84 - 1s - loss: 1.5879 - accuracy: 0.5327\n",
      "Epoch 17/80\n",
      "84/84 - 1s - loss: 1.5543 - accuracy: 0.5412\n",
      "Epoch 18/80\n",
      "84/84 - 1s - loss: 1.5228 - accuracy: 0.5496\n",
      "Epoch 19/80\n",
      "84/84 - 1s - loss: 1.4940 - accuracy: 0.5577\n",
      "Epoch 20/80\n",
      "84/84 - 1s - loss: 1.4635 - accuracy: 0.5672\n",
      "Epoch 21/80\n",
      "84/84 - 1s - loss: 1.4313 - accuracy: 0.5758\n",
      "Epoch 22/80\n",
      "84/84 - 1s - loss: 1.4025 - accuracy: 0.5844\n",
      "Epoch 23/80\n",
      "84/84 - 1s - loss: 1.3743 - accuracy: 0.5921\n",
      "Epoch 24/80\n",
      "84/84 - 1s - loss: 1.3448 - accuracy: 0.6000\n",
      "Epoch 25/80\n",
      "84/84 - 1s - loss: 1.3169 - accuracy: 0.6079\n",
      "Epoch 26/80\n",
      "84/84 - 1s - loss: 1.2883 - accuracy: 0.6168\n",
      "Epoch 27/80\n",
      "84/84 - 1s - loss: 1.2610 - accuracy: 0.6238\n",
      "Epoch 28/80\n",
      "84/84 - 1s - loss: 1.2315 - accuracy: 0.6330\n",
      "Epoch 29/80\n",
      "84/84 - 1s - loss: 1.2025 - accuracy: 0.6414\n",
      "Epoch 30/80\n",
      "84/84 - 1s - loss: 1.1761 - accuracy: 0.6488\n",
      "Epoch 31/80\n",
      "84/84 - 1s - loss: 1.1468 - accuracy: 0.6573\n",
      "Epoch 32/80\n",
      "84/84 - 1s - loss: 1.1185 - accuracy: 0.6648\n",
      "Epoch 33/80\n",
      "84/84 - 1s - loss: 1.0889 - accuracy: 0.6736\n",
      "Epoch 34/80\n",
      "84/84 - 1s - loss: 1.0574 - accuracy: 0.6841\n",
      "Epoch 35/80\n",
      "84/84 - 1s - loss: 1.0311 - accuracy: 0.6919\n",
      "Epoch 36/80\n",
      "84/84 - 1s - loss: 0.9979 - accuracy: 0.7024\n",
      "Epoch 37/80\n",
      "84/84 - 1s - loss: 0.9696 - accuracy: 0.7104\n",
      "Epoch 38/80\n",
      "84/84 - 1s - loss: 0.9401 - accuracy: 0.7196\n",
      "Epoch 39/80\n",
      "84/84 - 1s - loss: 0.9105 - accuracy: 0.7287\n",
      "Epoch 40/80\n",
      "84/84 - 1s - loss: 0.8858 - accuracy: 0.7365\n",
      "Epoch 41/80\n",
      "84/84 - 1s - loss: 0.8523 - accuracy: 0.7469\n",
      "Epoch 42/80\n",
      "84/84 - 1s - loss: 0.8298 - accuracy: 0.7536\n",
      "Epoch 43/80\n",
      "84/84 - 1s - loss: 0.7989 - accuracy: 0.7644\n",
      "Epoch 44/80\n",
      "84/84 - 1s - loss: 0.7696 - accuracy: 0.7738\n",
      "Epoch 45/80\n",
      "84/84 - 1s - loss: 0.7445 - accuracy: 0.7815\n",
      "Epoch 46/80\n",
      "84/84 - 1s - loss: 0.7190 - accuracy: 0.7898\n",
      "Epoch 47/80\n",
      "84/84 - 1s - loss: 0.6905 - accuracy: 0.7987\n",
      "Epoch 48/80\n",
      "84/84 - 1s - loss: 0.6633 - accuracy: 0.8082\n",
      "Epoch 49/80\n",
      "84/84 - 1s - loss: 0.6383 - accuracy: 0.8163\n",
      "Epoch 50/80\n",
      "84/84 - 1s - loss: 0.6146 - accuracy: 0.8244\n",
      "Epoch 51/80\n",
      "84/84 - 1s - loss: 0.5933 - accuracy: 0.8298\n",
      "Epoch 52/80\n",
      "84/84 - 1s - loss: 0.5646 - accuracy: 0.8400\n",
      "Epoch 53/80\n",
      "84/84 - 1s - loss: 0.5460 - accuracy: 0.8459\n",
      "Epoch 54/80\n",
      "84/84 - 1s - loss: 0.5272 - accuracy: 0.8518\n",
      "Epoch 55/80\n",
      "84/84 - 1s - loss: 0.5013 - accuracy: 0.8603\n",
      "Epoch 56/80\n",
      "84/84 - 1s - loss: 0.4791 - accuracy: 0.8682\n",
      "Epoch 57/80\n",
      "84/84 - 1s - loss: 0.4629 - accuracy: 0.8726\n",
      "Epoch 58/80\n",
      "84/84 - 1s - loss: 0.4449 - accuracy: 0.8781\n",
      "Epoch 59/80\n",
      "84/84 - 1s - loss: 0.4238 - accuracy: 0.8846\n",
      "Epoch 60/80\n",
      "84/84 - 1s - loss: 0.4102 - accuracy: 0.8892\n",
      "Epoch 61/80\n",
      "84/84 - 1s - loss: 0.3888 - accuracy: 0.8966\n",
      "Epoch 62/80\n",
      "84/84 - 1s - loss: 0.3702 - accuracy: 0.9034\n",
      "Epoch 63/80\n",
      "84/84 - 1s - loss: 0.3513 - accuracy: 0.9098\n",
      "Epoch 64/80\n",
      "84/84 - 1s - loss: 0.3361 - accuracy: 0.9141\n",
      "Epoch 65/80\n",
      "84/84 - 1s - loss: 0.3191 - accuracy: 0.9197\n",
      "Epoch 66/80\n",
      "84/84 - 1s - loss: 0.3086 - accuracy: 0.9227\n",
      "Epoch 67/80\n",
      "84/84 - 1s - loss: 0.2989 - accuracy: 0.9249\n",
      "Epoch 68/80\n",
      "84/84 - 1s - loss: 0.2882 - accuracy: 0.9278\n",
      "Epoch 69/80\n",
      "84/84 - 1s - loss: 0.2707 - accuracy: 0.9340\n",
      "Epoch 70/80\n",
      "84/84 - 1s - loss: 0.2738 - accuracy: 0.9314\n",
      "Epoch 71/80\n",
      "84/84 - 1s - loss: 0.2525 - accuracy: 0.9388\n",
      "Epoch 72/80\n",
      "84/84 - 1s - loss: 0.2462 - accuracy: 0.9399\n",
      "Epoch 73/80\n",
      "84/84 - 1s - loss: 0.2301 - accuracy: 0.9452\n",
      "Epoch 74/80\n",
      "84/84 - 1s - loss: 0.2202 - accuracy: 0.9476\n",
      "Epoch 75/80\n",
      "84/84 - 1s - loss: 0.2141 - accuracy: 0.9491\n",
      "Epoch 76/80\n",
      "84/84 - 1s - loss: 0.2063 - accuracy: 0.9508\n",
      "Epoch 77/80\n",
      "84/84 - 1s - loss: 0.2096 - accuracy: 0.9492\n",
      "Epoch 78/80\n",
      "84/84 - 1s - loss: 0.2079 - accuracy: 0.9488\n",
      "Epoch 79/80\n",
      "84/84 - 1s - loss: 0.2064 - accuracy: 0.9488\n",
      "Epoch 80/80\n",
      "84/84 - 1s - loss: 0.1978 - accuracy: 0.9510\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f5841f5ab00>"
      ]
     },
     "execution_count": 72,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.fit(train_X, train_y, epochs=80, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fbdgH6ApDm8U"
   },
   "outputs": [],
   "source": [
    "def sentence_generation(model, length):\n",
    "    ix = [np.random.randint(vocab_size)] # 글자에 대한 랜덤 인덱스 생성\n",
    "    y_char = [index_to_char[ix[-1]]] # 랜덤 익덱스로부터 글자 생성\n",
    "    print(ix[-1],'번 글자',y_char[-1],'로 예측을 시작!')\n",
    "    X = np.zeros((1, length, vocab_size)) # (1, length, 55) 크기의 X 생성. 즉, LSTM의 입력 시퀀스 생성\n",
    "\n",
    "    for i in tf.range(length):\n",
    "        i = tf.cast(i, tf.int64)\n",
    "        X[0][i][ix[-1]] = 1 # X[0][i][예측한 글자의 인덱스] = 1, 즉, 예측 글자를 다음 입력 시퀀스에 추가\n",
    "        print(index_to_char[ix[-1]], end=\"\")\n",
    "        ix = np.argmax(model.predict(X[:, :i+1, :])[0], 1)\n",
    "        y_char.append(index_to_char[ix[-1]])\n",
    "    return ('').join(y_char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 70
    },
    "id": "OHvSAbQiDpTh",
    "outputId": "ca1fd06c-b2c2-4533-fdd0-e252bb030244"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35 번 글자 e 로 예측을 시작!\n",
      "e to say out of the way is. station. what extled its all asked ays. as she said the last word with s"
     ]
    },
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic": {
       "type": "string"
      },
      "text/plain": [
       "'e to say out of the way is. station. what extled its all asked ays. as she said the last word with su'"
      ]
     },
     "execution_count": 82,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_generation(model, 100)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "learning spoons 4강.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
