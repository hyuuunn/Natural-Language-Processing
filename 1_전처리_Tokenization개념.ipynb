{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7hJxnNnALVmR"
   },
   "source": [
    "# Tokenization 개념"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wbaEB1ernvtM"
   },
   "source": [
    "참고 링크 : https://wikidocs.net/21698 (정독)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gXi_05LenIYM"
   },
   "source": [
    "주어진 텍스트에서 토큰(token)이라 불리는 단위로 나누는 작업을 토큰화(tokenization)라고 부릅니다. 토큰의 단위가 상황에 따라 다르지만, 보통 의미있는 단위로 토큰을 정의.\n",
    "\n",
    "일반적으로 토큰의 단위는 크게는 '문장' 작게는 '단어'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sGAPbS4ZnTAS"
   },
   "source": [
    "**토큰화는 일반적으로 직접 수행하는게 아닌, 이미 구현되어져 있는 패키지에 의존하는 것이 훨씬 좋음.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "토큰화가 어떤 의미인지 영어와 한국어에 대해서 실습."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ri9LCOBRnid7"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UFruANiioOeT"
   },
   "source": [
    "#Word Tokenization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3Y8UCpIaoYIR"
   },
   "source": [
    "단어 단위로 토큰화를 수행하는 것을 단어 토큰화(Word Tokenization)라고 함."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iciE21O6LaLg"
   },
   "source": [
    "## 영어 : Word Tokenization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MZKPNSlTnk4H"
   },
   "source": [
    "영어로 토큰화를 할 때는 일반적으로 NLTK라는 패키지를 사용. NTLK는 영어 자연어 처리를 위한 패키지. \n",
    "Colab에서는 NLTK가 이미 설치되어져 있으므로 import nltk로 바로 사용."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HkbmprCkoiSP"
   },
   "source": [
    "NLTK에서는 다양한 영어 토크나이저(토큰화를 수행하는 도구)를 제공. \n",
    "**토큰화 결과는 토크나이저마다 규칙이 조금씩 다름. 어떤 토크나이저를 사용할 지 정답은 없음.**\n",
    "\n",
    "어떤 토크나이저를 사용할지 선택."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h7dq1AIa4YQw"
   },
   "source": [
    "### **NLTK의 토크나이저 1. word_tokenize**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "u9vsOXPY3Wqe"
   },
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ofn4FR4V3Ynv",
    "outputId": "6f4fb05f-7bdf-4377-ba9d-883d8d14c6a9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xdzieQO1obgJ"
   },
   "source": [
    "아래의 문장을 보면 Don't와 Jone's에는 아포스트로피(')가 들어있음."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Q_v2UoFX3DOr"
   },
   "outputs": [],
   "source": [
    "sentence = \"Don't be fooled by the dark sounding name, Mr. Jone's Orphanage is as cheery as cheery goes for a pastry shop.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Tg_eQnb73i9Z"
   },
   "source": [
    "**아포스트로피가 들어간 상황에서 Don't와 Jone's는 어떻게 토큰화할 수 있을까?**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GZG-ES853DRs",
    "outputId": "fee32bae-1a93-4795-e2bf-d0ae152e77d5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Do', \"n't\", 'be', 'fooled', 'by', 'the', 'dark', 'sounding', 'name', ',', 'Mr.', 'Jone', \"'s\", 'Orphanage', 'is', 'as', 'cheery', 'as', 'cheery', 'goes', 'for', 'a', 'pastry', 'shop', '.']\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize  \n",
    "print(word_tokenize(sentence))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YWnG6YxT3qp_"
   },
   "source": [
    "Don't를 Do와 n't로 분리하였으며, Jone's는 Jone과 's로 분리"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GWmmTR1HsVXe"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FCIhWE4mpM4C"
   },
   "source": [
    "### **NLTK의 토크나이저 2. WordPunctTokenizer**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tbwe2_ny3DWj",
    "outputId": "02e54d9e-2a04-499f-8bb4-ed3adf3f6c18"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Don', \"'\", 't', 'be', 'fooled', 'by', 'the', 'dark', 'sounding', 'name', ',', 'Mr', '.', 'Jone', \"'\", 's', 'Orphanage', 'is', 'as', 'cheery', 'as', 'cheery', 'goes', 'for', 'a', 'pastry', 'shop', '.']\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import WordPunctTokenizer  \n",
    "print(WordPunctTokenizer().tokenize(sentence))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ErJrv2nT3sMP"
   },
   "source": [
    "Don't를 Don과 '와 t로 분리하였으며, Jone's를 Jone과 '와 s로 분리"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YFuuDjG_3_i-"
   },
   "source": [
    "**다시 말하지만 뭐가 더 좋은지 정답은 없음. 사실 토크나이저마다 각자 규칙이 다르기 때문에 사용하고자 하는 목적에 따라 토크나이저를 선택하는 것이 중요.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G6Umwj-OsUod"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yBn2S23BpUY0"
   },
   "source": [
    " ### **NLTK의 토크나이저 3. TreebankWordTokenizer**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Zot_67ckA4TZ"
   },
   "source": [
    "Penn Treebank Tokenizer의 규칙\n",
    "\n",
    "규칙 1. 하이푼으로 구성된 단어는 하나로 유지.  \n",
    "규칙 2. doesn't와 같이 아포스트로피로 '접어'가 함께하는 단어는 분리.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sTDxdxLk4-IG",
    "outputId": "a3a15135-3a5d-4cc1-8596-ec1cacffc044"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Starting', 'a', 'home-based', 'restaurant', 'may', 'be', 'an', 'ideal.', 'it', 'does', \"n't\", 'have', 'a', 'food', 'chain', 'or', 'restaurant', 'of', 'their', 'own', '.']\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import TreebankWordTokenizer\n",
    "tokenizer=TreebankWordTokenizer()\n",
    "text = \"Starting a home-based restaurant may be an ideal. it doesn't have a food chain or restaurant of their own.\"\n",
    "print(tokenizer.tokenize(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ARx4uEMRqg7F"
   },
   "source": [
    "지금까지 주어진 문자열로부터 NLTK가 제공하는 토크나이저 3개를 사용하여 단어 토큰화를 수행.  \n",
    "\n",
    "결과가 전부 다름"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PNZexhH6segP"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zZCS4energVw"
   },
   "source": [
    "### **띄어쓰기를 기준으로 하는 단어 토큰화 (잘 되는 것 같아도 가급적 No!)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u-hoqLUEtAPh"
   },
   "source": [
    "**사실 영어는 띄어쓰기를 기준으로 단어 토큰화를 한다고 하더라도 꽤 잘 되는 편.**  \n",
    "하지만 그럼에도 띄어쓰기를 기준으로 단어 토큰화를 하는 것은 하지 않는 것이 좋음.\n",
    "그 이유는?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "w0a3clHxrH4K"
   },
   "outputs": [],
   "source": [
    "en_text = \"A Dog Run back corner near spare bedrooms\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8EbN949GrMLE"
   },
   "source": [
    "우선 앞서 배운 NLTK로 토큰화."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NocCRtterOG4",
    "outputId": "4e9d5525-2fc2-42ab-8dab-beb9dfd45713"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['A', 'Dog', 'Run', 'back', 'corner', 'near', 'spare', 'bedrooms']\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "print(word_tokenize(en_text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bnbVGvKAtpd3"
   },
   "source": [
    "잘 동작."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r1KPhStArVm8"
   },
   "source": [
    "이번에는 NLTK가 아닌 그냥 띄어쓰기 단위로 토큰화.  \n",
    "파이썬은 주어진 문자열에 .split()을 하면 띄어쓰기를 기준으로 전부 원소를 잘라서 리스트 형태로 리턴."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1BC_cEmbrYqy",
    "outputId": "9c419c4f-eaab-4556-96ed-0d7d4731fb4d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['A', 'Dog', 'Run', 'back', 'corner', 'near', 'spare', 'bedrooms']\n"
     ]
    }
   ],
   "source": [
    "print(en_text.split())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vib_14zGrZyp"
   },
   "source": [
    "보이시나요? 이게 바로 띄어쓰기를 기준으로 단어 토큰화를 수행한 결과.  \n",
    "\n",
    "사실 영어는 NLTK라는 패키지를 사용하면 좀 더 섬세한 토큰화를 하기는 하지만, 띄어쓰기를 하는 것만으로도 거의 토큰화가 잘 되는 편. 하지만 그럼에도 띄어쓰기를 기준으로 하는 것을 지양(하지마세요)하라는 것은 이유가 있음.  \n",
    "\n",
    "예를 들어 영어 문장에 특수 문자를 추가."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "arWjY45-rtc2"
   },
   "outputs": [],
   "source": [
    "en_text = \"A Dog Run back corner near spare bedrooms... bedrooms!!\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wkZXiT-zrwyw"
   },
   "source": [
    "NLTK로 토큰화."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "232vN1A4rwPo",
    "outputId": "45581180-5914-4f50-ab86-d7e72bcb66ef"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['A', 'Dog', 'Run', 'back', 'corner', 'near', 'spare', 'bedrooms', '...', 'bedrooms', '!', '!']\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "print(word_tokenize(en_text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gcbsBZQPr0Q-"
   },
   "source": [
    "보시면 특수문자들도 알아서 다 띄워서 bedrooms이 정상적으로 분리. 하지만 띄어쓰기 단위로 토큰화를 한다면?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tzo9_R4Vr5h1",
    "outputId": "2bfc2ace-b456-4985-fa1e-de89d5354e7f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['A', 'Dog', 'Run', 'back', 'corner', 'near', 'spare', 'bedrooms...', 'bedrooms!!']\n"
     ]
    }
   ],
   "source": [
    "print(en_text.split())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3aBFM4gAr_eL"
   },
   "source": [
    "bedrooms와 ...가 붙어서 bedrooms...가 나오고,  \n",
    "bedrooms와 !!!가 붙어서 bedrooms!!!가 나옴.  \n",
    "\n",
    "파이썬이 보기에 이들은 전부 다른 단어로 인식."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LQU8ZeZosG2M",
    "outputId": "de68e604-2269-4b72-91ff-7d6911bf7051"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "이 둘은 다릅니다.\n"
     ]
    }
   ],
   "source": [
    "if 'bedrooms' == 'bedrooms...':\n",
    "  print('이 둘은 같습니다.')\n",
    "else:\n",
    "  print('이 둘은 다릅니다.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nVhcrmUfsJ22",
    "outputId": "0253a979-9918-46ff-e209-10bae47040ec"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 14,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'bedrooms...' == 'bedrooms!!'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QhhZq9dwtr1X"
   },
   "source": [
    "NLTK가 훨씬 섬세하게 동작한다는 것을 알 수 있음."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0GbPMPZSoGzF"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uSMrszdyBLQj"
   },
   "source": [
    "## 한국어 : Word Tokenization(KoNLPy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QJNy3EKWq2qI"
   },
   "source": [
    "### 띄어쓰기를 기준으로 하는 단어 토큰화 (그냥 No!)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZGJAEiGhrAEE"
   },
   "source": [
    "사실 영어의 경우에는 띄어쓰기 단위로 토큰화를 해도 단어들 간 구분이 꽤나 명확한 편. 하지만 한국어의 경우에는 토큰화 작업이 훨씬 까다로움. 그 이유는 **한국어는 조사, 접사 등으로 인해 단순 띄어쓰기 단위로 나누면 같은 단어가 다른 단어로 인식되는 경우가 너무 너무 너무 많기 때문.**\n",
    "\n",
    "한국어는 띄어쓰기로 토큰화하는 것은 명확한 실험 목적이 없다면 거의 쓰지 않는 것이 좋음. 예시를 통해서 이해."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-xWyJGP-t4Eu",
    "outputId": "5b055b1c-c9f3-4766-acf7-87349c3cd0af"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['사과의', '놀라운', '효능이라는', '글을', '봤어.', '그래서', '오늘', '사과를', '먹으려고', '했는데', '사과가', '썩어서', '슈퍼에', '가서', '사과랑', '오렌지', '사왔어']\n"
     ]
    }
   ],
   "source": [
    "kor_text = \"사과의 놀라운 효능이라는 글을 봤어. 그래서 오늘 사과를 먹으려고 했는데 사과가 썩어서 슈퍼에 가서 사과랑 오렌지 사왔어\"\n",
    "print(kor_text.split())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lM84f6Krt6_C"
   },
   "source": [
    "위의 예제에서는 '사과'란 단어가 총 4번 등장했는데  \n",
    "모두 '의', '를', '가', '랑' 등이 붙어있어 이를 제거해주지 않으면 기계는 전부 다른 단어로 인식."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eqc89ew5uVFH",
    "outputId": "b89bdcf0-66bd-451a-81bd-56c5a998c809"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'사과' == '사과의'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iIBKIli0uafi",
    "outputId": "5d53152e-0ee5-4316-fb72-ed29921079ae"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'사과의' == '사과를'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yLFh10PPucii",
    "outputId": "2f0bd1fd-b8a0-4375-fa70-77d6a6d792c0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'사과를' == '사과가'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "V-mGZxemueGR",
    "outputId": "60e66c1d-cf6a-42b1-f2c1-5f34083a6b82"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'사과가' == '사과랑'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3gud9KnwugP-"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y8ca0ljXt8Gg"
   },
   "source": [
    "### 형태소 분석기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YWGTCavJuCXF"
   },
   "source": [
    "단어 토큰화를 위해서 영어에 NLTK가 있다면 한국어에는 형태소 분석기 패키지인 KoNLPy(코엔엘파이)가 존재.  \n",
    "KoNLPy는 Colab에 설치되어져 있지 않으므로 별도로 설치."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pQMm9UPdBhCP",
    "outputId": "a658cccc-83ec-49d3-ed43-94c190bb93c1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting konlpy\n",
      "  Downloading konlpy-0.5.2-py2.py3-none-any.whl (19.4 MB)\n",
      "\u001b[K     |████████████████████████████████| 19.4 MB 4.4 MB/s \n",
      "\u001b[?25hCollecting colorama\n",
      "  Downloading colorama-0.4.4-py2.py3-none-any.whl (16 kB)\n",
      "Requirement already satisfied: numpy>=1.6 in /usr/local/lib/python3.7/dist-packages (from konlpy) (1.19.5)\n",
      "Collecting JPype1>=0.7.0\n",
      "  Downloading JPype1-1.3.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (448 kB)\n",
      "\u001b[K     |████████████████████████████████| 448 kB 50.7 MB/s \n",
      "\u001b[?25hRequirement already satisfied: lxml>=4.1.0 in /usr/local/lib/python3.7/dist-packages (from konlpy) (4.2.6)\n",
      "Collecting beautifulsoup4==4.6.0\n",
      "  Downloading beautifulsoup4-4.6.0-py3-none-any.whl (86 kB)\n",
      "\u001b[K     |████████████████████████████████| 86 kB 5.1 MB/s \n",
      "\u001b[?25hRequirement already satisfied: tweepy>=3.7.0 in /usr/local/lib/python3.7/dist-packages (from konlpy) (3.10.0)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from JPype1>=0.7.0->konlpy) (3.10.0.2)\n",
      "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tweepy>=3.7.0->konlpy) (1.15.0)\n",
      "Requirement already satisfied: requests[socks]>=2.11.1 in /usr/local/lib/python3.7/dist-packages (from tweepy>=3.7.0->konlpy) (2.23.0)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tweepy>=3.7.0->konlpy) (1.3.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->tweepy>=3.7.0->konlpy) (3.1.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (2021.10.8)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (1.24.3)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (2.10)\n",
      "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (1.7.1)\n",
      "Installing collected packages: JPype1, colorama, beautifulsoup4, konlpy\n",
      "  Attempting uninstall: beautifulsoup4\n",
      "    Found existing installation: beautifulsoup4 4.6.3\n",
      "    Uninstalling beautifulsoup4-4.6.3:\n",
      "      Successfully uninstalled beautifulsoup4-4.6.3\n",
      "Successfully installed JPype1-1.3.0 beautifulsoup4-4.6.0 colorama-0.4.4 konlpy-0.5.2\n"
     ]
    }
   ],
   "source": [
    "!pip install konlpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W47LzDKLuhjm"
   },
   "source": [
    "NLTK도 내부적으로 여러 토크나이저가 있던 것처럼 KoNLPy 또한 다양한 형태소 분석기를 가지고 있지만, Mecab이라는 형태소 분석기는 특이하게도 별도 설치 필요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2j4Q8HvpGrgd",
    "outputId": "5bc8765e-027c-4965-9c4f-e2374ca6b7f2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'Mecab-ko-for-Google-Colab'...\n",
      "remote: Enumerating objects: 91, done.\u001b[K\n",
      "remote: Total 91 (delta 0), reused 0 (delta 0), pack-reused 91\u001b[K\n",
      "Unpacking objects: 100% (91/91), done.\n",
      "/content/Mecab-ko-for-Google-Colab\n",
      "Installing konlpy.....\n",
      "Requirement already satisfied: konlpy in /usr/local/lib/python3.7/dist-packages (0.5.2)\n",
      "Requirement already satisfied: tweepy>=3.7.0 in /usr/local/lib/python3.7/dist-packages (from konlpy) (3.10.0)\n",
      "Requirement already satisfied: JPype1>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from konlpy) (1.3.0)\n",
      "Requirement already satisfied: beautifulsoup4==4.6.0 in /usr/local/lib/python3.7/dist-packages (from konlpy) (4.6.0)\n",
      "Requirement already satisfied: lxml>=4.1.0 in /usr/local/lib/python3.7/dist-packages (from konlpy) (4.2.6)\n",
      "Requirement already satisfied: colorama in /usr/local/lib/python3.7/dist-packages (from konlpy) (0.4.4)\n",
      "Requirement already satisfied: numpy>=1.6 in /usr/local/lib/python3.7/dist-packages (from konlpy) (1.19.5)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from JPype1>=0.7.0->konlpy) (3.10.0.2)\n",
      "Requirement already satisfied: requests[socks]>=2.11.1 in /usr/local/lib/python3.7/dist-packages (from tweepy>=3.7.0->konlpy) (2.23.0)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tweepy>=3.7.0->konlpy) (1.3.0)\n",
      "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tweepy>=3.7.0->konlpy) (1.15.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->tweepy>=3.7.0->konlpy) (3.1.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (2021.10.8)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (1.24.3)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (2.10)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (3.0.4)\n",
      "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (1.7.1)\n",
      "Done\n",
      "Installing mecab-0.996-ko-0.9.2.tar.gz.....\n",
      "Downloading mecab-0.996-ko-0.9.2.tar.gz.......\n",
      "from https://bitbucket.org/eunjeon/mecab-ko/downloads/mecab-0.996-ko-0.9.2.tar.gz\n",
      "--2022-01-02 02:08:45--  https://bitbucket.org/eunjeon/mecab-ko/downloads/mecab-0.996-ko-0.9.2.tar.gz\n",
      "Resolving bitbucket.org (bitbucket.org)... 104.192.141.1, 2406:da00:ff00::22cd:e0db, 2406:da00:ff00::6b17:d1f5, ...\n",
      "Connecting to bitbucket.org (bitbucket.org)|104.192.141.1|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://bbuseruploads.s3.amazonaws.com/eunjeon/mecab-ko/downloads/mecab-0.996-ko-0.9.2.tar.gz?Signature=EhQfXe2fyp6J6EcOvZLAv%2FEUNU0%3D&Expires=1641090940&AWSAccessKeyId=AKIA6KOSE3BNA7WTAGHW&versionId=null&response-content-disposition=attachment%3B%20filename%3D%22mecab-0.996-ko-0.9.2.tar.gz%22&response-content-encoding=None [following]\n",
      "--2022-01-02 02:08:45--  https://bbuseruploads.s3.amazonaws.com/eunjeon/mecab-ko/downloads/mecab-0.996-ko-0.9.2.tar.gz?Signature=EhQfXe2fyp6J6EcOvZLAv%2FEUNU0%3D&Expires=1641090940&AWSAccessKeyId=AKIA6KOSE3BNA7WTAGHW&versionId=null&response-content-disposition=attachment%3B%20filename%3D%22mecab-0.996-ko-0.9.2.tar.gz%22&response-content-encoding=None\n",
      "Resolving bbuseruploads.s3.amazonaws.com (bbuseruploads.s3.amazonaws.com)... 52.217.37.156\n",
      "Connecting to bbuseruploads.s3.amazonaws.com (bbuseruploads.s3.amazonaws.com)|52.217.37.156|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 1414979 (1.3M) [application/x-tar]\n",
      "Saving to: ‘mecab-0.996-ko-0.9.2.tar.gz’\n",
      "\n",
      "mecab-0.996-ko-0.9. 100%[===================>]   1.35M  7.63MB/s    in 0.2s    \n",
      "\n",
      "2022-01-02 02:08:46 (7.63 MB/s) - ‘mecab-0.996-ko-0.9.2.tar.gz’ saved [1414979/1414979]\n",
      "\n",
      "Done\n",
      "Unpacking mecab-0.996-ko-0.9.2.tar.gz.......\n",
      "Done\n",
      "Change Directory to mecab-0.996-ko-0.9.2.......\n",
      "installing mecab-0.996-ko-0.9.2.tar.gz........\n",
      "configure\n",
      "make\n",
      "make check\n",
      "make install\n",
      "ldconfig\n",
      "Done\n",
      "Change Directory to /content\n",
      "Downloading mecab-ko-dic-2.1.1-20180720.tar.gz.......\n",
      "from https://bitbucket.org/eunjeon/mecab-ko-dic/downloads/mecab-ko-dic-2.1.1-20180720.tar.gz\n",
      "--2022-01-02 02:10:23--  https://bitbucket.org/eunjeon/mecab-ko-dic/downloads/mecab-ko-dic-2.1.1-20180720.tar.gz\n",
      "Resolving bitbucket.org (bitbucket.org)... 104.192.141.1, 2406:da00:ff00::22cd:e0db, 2406:da00:ff00::22c5:2ef4, ...\n",
      "Connecting to bitbucket.org (bitbucket.org)|104.192.141.1|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://bbuseruploads.s3.amazonaws.com/a4fcd83e-34f1-454e-a6ac-c242c7d434d3/downloads/b5a0c703-7b64-45ed-a2d7-180e962710b6/mecab-ko-dic-2.1.1-20180720.tar.gz?Signature=6QZ0yLnmenirIXK9J5Nn3PUe34g%3D&Expires=1641091039&AWSAccessKeyId=AKIA6KOSE3BNA7WTAGHW&versionId=tzyxc1TtnZU_zEuaaQDGN4F76hPDpyFq&response-content-disposition=attachment%3B%20filename%3D%22mecab-ko-dic-2.1.1-20180720.tar.gz%22&response-content-encoding=None [following]\n",
      "--2022-01-02 02:10:23--  https://bbuseruploads.s3.amazonaws.com/a4fcd83e-34f1-454e-a6ac-c242c7d434d3/downloads/b5a0c703-7b64-45ed-a2d7-180e962710b6/mecab-ko-dic-2.1.1-20180720.tar.gz?Signature=6QZ0yLnmenirIXK9J5Nn3PUe34g%3D&Expires=1641091039&AWSAccessKeyId=AKIA6KOSE3BNA7WTAGHW&versionId=tzyxc1TtnZU_zEuaaQDGN4F76hPDpyFq&response-content-disposition=attachment%3B%20filename%3D%22mecab-ko-dic-2.1.1-20180720.tar.gz%22&response-content-encoding=None\n",
      "Resolving bbuseruploads.s3.amazonaws.com (bbuseruploads.s3.amazonaws.com)... 54.231.197.233\n",
      "Connecting to bbuseruploads.s3.amazonaws.com (bbuseruploads.s3.amazonaws.com)|54.231.197.233|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 49775061 (47M) [application/x-tar]\n",
      "Saving to: ‘mecab-ko-dic-2.1.1-20180720.tar.gz’\n",
      "\n",
      "mecab-ko-dic-2.1.1- 100%[===================>]  47.47M  53.7MB/s    in 0.9s    \n",
      "\n",
      "2022-01-02 02:10:24 (53.7 MB/s) - ‘mecab-ko-dic-2.1.1-20180720.tar.gz’ saved [49775061/49775061]\n",
      "\n",
      "Done\n",
      "Unpacking  mecab-ko-dic-2.1.1-20180720.tar.gz.......\n",
      "Done\n",
      "Change Directory to mecab-ko-dic-2.1.1-20180720\n",
      "Done\n",
      "installing........\n",
      "configure\n",
      "make\n",
      "make install\n",
      "apt-get update\n",
      "apt-get upgrade\n",
      "apt install curl\n",
      "apt install git\n",
      "bash <(curl -s https://raw.githubusercontent.com/konlpy/konlpy/master/scripts/mecab.sh)\n",
      "Done\n",
      "Successfully Installed\n",
      "Now you can use Mecab\n",
      "from konlpy.tag import Mecab\n",
      "mecab = Mecab()\n",
      "사용자 사전 추가 방법 : https://bit.ly/3k0ZH53\n",
      "NameError: name 'Tagger' is not defined 오류 발생 시 런타임을 재실행 해주세요\n",
      "블로그에 해결 방법을 남겨주신 tana님 감사합니다.\n"
     ]
    }
   ],
   "source": [
    "# Colab에 Mecab 설치\n",
    "!git clone https://github.com/SOMJANG/Mecab-ko-for-Google-Colab.git\n",
    "%cd Mecab-ko-for-Google-Colab\n",
    "!bash install_mecab-ko_on_colab190912.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "p3pxdKtsDK4E"
   },
   "outputs": [],
   "source": [
    "from konlpy.tag import *\n",
    "\n",
    "hannanum = Hannanum()\n",
    "kkma = Kkma()\n",
    "komoran = Komoran()\n",
    "okt = Okt()\n",
    "mecab = Mecab()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O3z0QlzhGEJl"
   },
   "source": [
    "위 형태소 분석기들은 공통적으로 아래의 함수를 제공.  \n",
    "nouns : 명사 추출  \n",
    "morphs : 형태소 추출  \n",
    "pos : 품사 부착"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YBTatyJgCcdB"
   },
   "source": [
    "### 형태소 분석기 Okt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_21rq8q93DgG",
    "outputId": "447dad9f-29a4-4858-a9ea-01098ad7b66e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['코딩', '당신', '연휴', '여행']\n",
      "['열심히', '코딩', '한', '당신', ',', '연휴', '에는', '여행', '을', '가봐요']\n",
      "[('열심히', 'Adverb'), ('코딩', 'Noun'), ('한', 'Josa'), ('당신', 'Noun'), (',', 'Punctuation'), ('연휴', 'Noun'), ('에는', 'Josa'), ('여행', 'Noun'), ('을', 'Josa'), ('가봐요', 'Verb')]\n"
     ]
    }
   ],
   "source": [
    "print(okt.nouns(\"열심히 코딩한 당신, 연휴에는 여행을 가봐요\"))\n",
    "print(okt.morphs(\"열심히 코딩한 당신, 연휴에는 여행을 가봐요\"))\n",
    "print(okt.pos(\"열심히 코딩한 당신, 연휴에는 여행을 가봐요\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5HIC4M1nCnSQ"
   },
   "source": [
    "### 형태소 분석기 꼬꼬마"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cK7W4wMy3Der",
    "outputId": "942247a0-dbd0-4405-b307-5e5f7ed411d7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['코딩', '당신', '연휴', '여행']\n",
      "['열심히', '코딩', '하', 'ㄴ', '당신', ',', '연휴', '에', '는', '여행', '을', '가보', '아요']\n",
      "[('열심히', 'MAG'), ('코딩', 'NNG'), ('하', 'XSV'), ('ㄴ', 'ETD'), ('당신', 'NP'), (',', 'SP'), ('연휴', 'NNG'), ('에', 'JKM'), ('는', 'JX'), ('여행', 'NNG'), ('을', 'JKO'), ('가보', 'VV'), ('아요', 'EFN')]\n"
     ]
    }
   ],
   "source": [
    "print(kkma.nouns(\"열심히 코딩한 당신, 연휴에는 여행을 가봐요\"))\n",
    "print(kkma.morphs(\"열심히 코딩한 당신, 연휴에는 여행을 가봐요\"))\n",
    "print(kkma.pos(\"열심히 코딩한 당신, 연휴에는 여행을 가봐요\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Dw5M9NoTDWxv"
   },
   "source": [
    "### 형태소 분석기 코모란"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xYr7mO3C3DZc",
    "outputId": "3d195710-1061-41d1-bf6d-cda75799e568"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['코', '당신', '연휴', '여행']\n",
      "['열심히', '코', '딩', '하', 'ㄴ', '당신', ',', '연휴', '에', '는', '여행', '을', '가', '아', '보', '아요']\n",
      "[('열심히', 'MAG'), ('코', 'NNG'), ('딩', 'MAG'), ('하', 'XSV'), ('ㄴ', 'ETM'), ('당신', 'NNP'), (',', 'SP'), ('연휴', 'NNG'), ('에', 'JKB'), ('는', 'JX'), ('여행', 'NNG'), ('을', 'JKO'), ('가', 'VV'), ('아', 'EC'), ('보', 'VX'), ('아요', 'EC')]\n"
     ]
    }
   ],
   "source": [
    "print(komoran.nouns(\"열심히 코딩한 당신, 연휴에는 여행을 가봐요\"))\n",
    "print(komoran.morphs(\"열심히 코딩한 당신, 연휴에는 여행을 가봐요\"))\n",
    "print(komoran.pos(\"열심히 코딩한 당신, 연휴에는 여행을 가봐요\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XSGyZZVkF_GS"
   },
   "source": [
    "### 형태소 분석기 한나눔"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Uvdqq2Lz3DUh",
    "outputId": "e0ca082c-f89c-4ed2-9abd-d55a9b121054"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['코딩', '당신', '연휴', '여행']\n",
      "['열심히', '코딩', '하', 'ㄴ', '당신', ',', '연휴', '에는', '여행', '을', '가', '아', '보', '아']\n",
      "[('열심히', 'M'), ('코딩', 'N'), ('하', 'X'), ('ㄴ', 'E'), ('당신', 'N'), (',', 'S'), ('연휴', 'N'), ('에는', 'J'), ('여행', 'N'), ('을', 'J'), ('가', 'P'), ('아', 'E'), ('보', 'P'), ('아', 'E')]\n"
     ]
    }
   ],
   "source": [
    "print(hannanum.nouns(\"열심히 코딩한 당신, 연휴에는 여행을 가봐요\"))\n",
    "print(hannanum.morphs(\"열심히 코딩한 당신, 연휴에는 여행을 가봐요\"))\n",
    "print(hannanum.pos(\"열심히 코딩한 당신, 연휴에는 여행을 가봐요\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w2XrKQ8ZGlVA"
   },
   "source": [
    "### 형태소 분석기 Mecab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KhDAAPcmGzw7",
    "outputId": "d1c96d32-6c3a-4a0f-9c5e-ecf7bd6e2a24"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['코딩', '당신', '연휴', '여행']\n",
      "['열심히', '코딩', '한', '당신', ',', '연휴', '에', '는', '여행', '을', '가', '봐요']\n",
      "[('열심히', 'MAG'), ('코딩', 'NNG'), ('한', 'XSA+ETM'), ('당신', 'NP'), (',', 'SC'), ('연휴', 'NNG'), ('에', 'JKB'), ('는', 'JX'), ('여행', 'NNG'), ('을', 'JKO'), ('가', 'VV'), ('봐요', 'EC+VX+EC')]\n"
     ]
    }
   ],
   "source": [
    "print(mecab.nouns(\"열심히 코딩한 당신, 연휴에는 여행을 가봐요\"))\n",
    "print(mecab.morphs(\"열심히 코딩한 당신, 연휴에는 여행을 가봐요\"))\n",
    "print(mecab.pos(\"열심히 코딩한 당신, 연휴에는 여행을 가봐요\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JOXF6YzWKF1J"
   },
   "source": [
    "**각 형태소 분석기는 성능과 결과가 다르게 나오기 때문에**, 형태소 분석기의 선택은 사용하고자 하는 필요 용도에 어떤 형태소 분석기가 가장 적절한지를 판단하고 사용하면 됨. 예를 들어서 속도를 중시한다면 메캅을 사용할 수 있음.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_ykZiIzWiUfr"
   },
   "source": [
    "참고 : https://iostream.tistory.com/144 (형태소 분석기 성능 비교)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "AdhSbOSwT70z",
    "-9MGzYEfUcJT",
    "zlZwcrE-8yXf",
    "MuTbHcsV6BLg",
    "fLes_LQ7_TN1",
    "A0o_f1rAGoID",
    "UyMx1Yq-GqIh",
    "sY38lpX8GxfC",
    "k9zsoaPWersA",
    "e3WAEwbakd7f",
    "M4dlH7lCkk4X",
    "HaMDuF_vSs6j",
    "o_IqLzCDSvPt"
   ],
   "name": "딥 러닝을 이용한 자연어 처리 1강 - 전처리.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "274px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
