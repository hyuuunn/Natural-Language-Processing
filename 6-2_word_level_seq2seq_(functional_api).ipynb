{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "7-8N0MOX-M9g",
    "outputId": "b89c27bf-2551-469b-f143-0a470fbb0656"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'2.6.0'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LYBG2l-0YS_q"
   },
   "source": [
    "# 필요한 도구 임포트\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PT-fPRLQD_BB"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "deZRa94GD-8K"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JPm7GViCDRmo"
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "import numpy as np\n",
    "import re\n",
    "import shutil\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Embedding, GRU, Dense\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import pandas as pd\n",
    "import os\n",
    "import unicodedata\n",
    "import urllib3\n",
    "import zipfile\n",
    "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0tuLZaD-W2Cv"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import urllib3\n",
    "import zipfile\n",
    "import shutil\n",
    "import os\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b4LO4Qy7YX_v"
   },
   "source": [
    "# 데이터 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BilqhuqhW3qa"
   },
   "outputs": [],
   "source": [
    "http = urllib3.PoolManager()\n",
    "url ='http://www.manythings.org/anki/fra-eng.zip'\n",
    "filename = 'fra-eng.zip'\n",
    "path = os.getcwd()\n",
    "zipfilename = os.path.join(path, filename)\n",
    "with http.request('GET', url, preload_content=False) as r, open(zipfilename, 'wb') as out_file:       \n",
    "    shutil.copyfileobj(r, out_file)\n",
    "\n",
    "with zipfile.ZipFile(zipfilename, 'r') as zip_ref:\n",
    "    zip_ref.extractall(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "vV83881FW4ts",
    "outputId": "bdfb2138-b7d2-4e7e-c88f-e8b4cc65c733"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "178009"
      ]
     },
     "execution_count": 7,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines= pd.read_csv('fra.txt', names=['src', 'tar', 'lic'], sep='\\t')\n",
    "del lines['lic']\n",
    "len(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 406
    },
    "id": "jAaHisboW_rG",
    "outputId": "bf627c75-21ea-4467-ad91-3279727db84a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>src</th>\n",
       "      <th>tar</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Go.</td>\n",
       "      <td>Va !</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hi.</td>\n",
       "      <td>Salut !</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hi.</td>\n",
       "      <td>Salut.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Run!</td>\n",
       "      <td>Cours !</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Run!</td>\n",
       "      <td>Courez !</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178004</th>\n",
       "      <td>Top-down economics never works, said Obama. \"T...</td>\n",
       "      <td>« L'économie en partant du haut vers le bas, ç...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178005</th>\n",
       "      <td>A carbon footprint is the amount of carbon dio...</td>\n",
       "      <td>Une empreinte carbone est la somme de pollutio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178006</th>\n",
       "      <td>Death is something that we're often discourage...</td>\n",
       "      <td>La mort est une chose qu'on nous décourage sou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178007</th>\n",
       "      <td>Since there are usually multiple websites on a...</td>\n",
       "      <td>Puisqu'il y a de multiples sites web sur chaqu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178008</th>\n",
       "      <td>If someone who doesn't know your background sa...</td>\n",
       "      <td>Si quelqu'un qui ne connaît pas vos antécédent...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>178009 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      src                                                tar\n",
       "0                                                     Go.                                               Va !\n",
       "1                                                     Hi.                                            Salut !\n",
       "2                                                     Hi.                                             Salut.\n",
       "3                                                    Run!                                            Cours !\n",
       "4                                                    Run!                                           Courez !\n",
       "...                                                   ...                                                ...\n",
       "178004  Top-down economics never works, said Obama. \"T...  « L'économie en partant du haut vers le bas, ç...\n",
       "178005  A carbon footprint is the amount of carbon dio...  Une empreinte carbone est la somme de pollutio...\n",
       "178006  Death is something that we're often discourage...  La mort est une chose qu'on nous décourage sou...\n",
       "178007  Since there are usually multiple websites on a...  Puisqu'il y a de multiples sites web sur chaqu...\n",
       "178008  If someone who doesn't know your background sa...  Si quelqu'un qui ne connaît pas vos antécédent...\n",
       "\n",
       "[178009 rows x 2 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vtC3TPpNYRpt"
   },
   "source": [
    "총 33,000개의 샘플을 사용할 예정입니다. 이 값을 변수에 지정합니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Z5OCcdTfDZFJ"
   },
   "outputs": [],
   "source": [
    "num_samples = 33000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ocLj77k7Ycoo"
   },
   "source": [
    "# 전처리 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "E59S6DBnDg_7"
   },
   "outputs": [],
   "source": [
    "def unicode_to_ascii(s):\n",
    "  return ''.join(c for c in unicodedata.normalize('NFD', s)\n",
    "      if unicodedata.category(c) != 'Mn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wGuKay4vDihU"
   },
   "outputs": [],
   "source": [
    "def preprocess_sentence(sent):\n",
    "    sent = unicode_to_ascii(sent.lower())\n",
    "    sent = re.sub(r\"([?.!,¿])\", r\" \\1\", sent)\n",
    "    sent = re.sub(r\"[^a-zA-Z!.?]+\", r\" \", sent)\n",
    "    sent = re.sub(r\"\\s+\", \" \", sent)\n",
    "    return sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cUhPWx-ZEBLF"
   },
   "outputs": [],
   "source": [
    "def load_preprocessed_data():\n",
    "    encoder_input, decoder_input, decoder_target = [], [], []\n",
    "\n",
    "    with open(\"fra.txt\", \"r\") as lines:\n",
    "        for i, line in enumerate(lines):\n",
    "\n",
    "            # source 데이터와 target 데이터 분리\n",
    "            src_line, tar_line, _ = line.strip().split('\\t')\n",
    "\n",
    "            # source 데이터 전처리\n",
    "            src_line = [w for w in preprocess_sentence(src_line).split()]\n",
    "\n",
    "            # target 데이터 전처리\n",
    "            tar_line = preprocess_sentence(tar_line)\n",
    "            tar_line_in = [w for w in (\"<sos> \" + tar_line).split()]\n",
    "            tar_line_out = [w for w in (tar_line + \" <eos>\").split()]\n",
    "\n",
    "            encoder_input.append(src_line)\n",
    "            decoder_input.append(tar_line_in)\n",
    "            decoder_target.append(tar_line_out)\n",
    "\n",
    "            if i == num_samples - 1:\n",
    "                break\n",
    "                \n",
    "    return encoder_input, decoder_input, decoder_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "id": "DrUSjZYxDjRz",
    "outputId": "be46692b-cec2-4e9a-8cb4-0cfa7fe1361f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "have you had dinner ?\n",
      "b'avez vous deja dine ?'\n"
     ]
    }
   ],
   "source": [
    "# 인코딩 테스트\n",
    "en_sent = u\"Have you had dinner?\"\n",
    "fr_sent = u\"Avez-vous déjà diné ?\"\n",
    "print(preprocess_sentence(en_sent))\n",
    "print(preprocess_sentence(fr_sent).encode('utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DdF0dhMtDukT"
   },
   "outputs": [],
   "source": [
    "sents_en_in, sents_fra_in, sents_fra_out = load_preprocessed_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Nhm7rDKlYkD7"
   },
   "source": [
    "# 인코더의 입력과 디코더의 입, 출력 구성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 70
    },
    "id": "xglUBclqDwFb",
    "outputId": "051f970c-269b-4377-ff3e-db9f78b5c2a7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['go', '.'], ['hi', '.'], ['hi', '.'], ['run', '!'], ['run', '!']]\n",
      "[['<sos>', 'va', '!'], ['<sos>', 'salut', '!'], ['<sos>', 'salut', '.'], ['<sos>', 'cours', '!'], ['<sos>', 'courez', '!']]\n",
      "[['va', '!', '<eos>'], ['salut', '!', '<eos>'], ['salut', '.', '<eos>'], ['cours', '!', '<eos>'], ['courez', '!', '<eos>']]\n"
     ]
    }
   ],
   "source": [
    "print(sents_en_in[:5])\n",
    "print(sents_fra_in[:5])\n",
    "print(sents_fra_out[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8SGpmq0pYqQk"
   },
   "source": [
    "이제 케라스 토크나이저를 통해 단어 집합을 생성하고, 텍스트 시퀀스를 정수 시퀀스로 변환하는 정수 인코딩 과정을 거침."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gKeW1Q7vD20T"
   },
   "outputs": [],
   "source": [
    "tokenizer_en = Tokenizer(filters=\"\", lower=False)\n",
    "tokenizer_en.fit_on_texts(sents_en_in)\n",
    "encoder_input = tokenizer_en.texts_to_sequences(sents_en_in)\n",
    "encoder_input = pad_sequences(encoder_input, padding=\"post\")\n",
    "\n",
    "tokenizer_fra = Tokenizer(filters=\"\", lower=False)\n",
    "tokenizer_fra.fit_on_texts(sents_fra_in)\n",
    "tokenizer_fra.fit_on_texts(sents_fra_out)\n",
    "\n",
    "decoder_input = tokenizer_fra.texts_to_sequences(sents_fra_in)\n",
    "decoder_input = pad_sequences(decoder_input, padding=\"post\")\n",
    "\n",
    "decoder_target = tokenizer_fra.texts_to_sequences(sents_fra_out)\n",
    "decoder_target = pad_sequences(decoder_target, padding=\"post\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Wrte_JrzYtd0"
   },
   "source": [
    "샘플은 총 33,000개 존재하며 영어 문장의 길이는 8, 프랑스어 문장의 길이는 16. 단어 집합의 크기를 정의.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 70
    },
    "id": "j1l6zAzFEKC8",
    "outputId": "78a7c638-90fa-411e-95ec-094714602098"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(33000, 8)\n",
      "(33000, 16)\n",
      "(33000, 16)\n"
     ]
    }
   ],
   "source": [
    "print(encoder_input.shape)\n",
    "print(decoder_input.shape)\n",
    "print(decoder_target.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "LpfK0jzzEK0D",
    "outputId": "5ae448fd-6629-4512-c89e-fbe22e2e70a0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "영어 단어 집합의 크기 (en): 4663, 프랑스어 단어 집합의 크기 (spa): 8038\n"
     ]
    }
   ],
   "source": [
    "vocab_size_en = len(tokenizer_en.word_index) + 1\n",
    "vocab_size_fra = len(tokenizer_fra.word_index) + 1\n",
    "print(\"영어 단어 집합의 크기 (en): {:d}, 프랑스어 단어 집합의 크기 (spa): {:d}\".format(vocab_size_en, vocab_size_fra))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Oa_OyaR4YvRK"
   },
   "source": [
    "단어 집합의 크기는 각각 4,647개와 8,022개. 단어로부터 정수를 얻는 딕셔너리와 정수로부터 단어를 얻는 딕셔너리를 각각 만들어 줌. 이들은 훈련을 마치고 예측 과정과 실제값과 결과를 비교하는 경우에 사용됨."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "W1Me68xKEMFE"
   },
   "outputs": [],
   "source": [
    "src_to_index = tokenizer_en.word_index\n",
    "index_to_src = tokenizer_en.index_word\n",
    "\n",
    "tar_to_index = tokenizer_fra.word_index\n",
    "index_to_tar = tokenizer_fra.index_word"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z0l9m1_SYzx5"
   },
   "source": [
    "이제 테스트 데이터를 분리할 차례. 테스트 데이터를 분리하기 전에, 적절한 분포를 갖도록 데이터를 섞어주는 과정을 진행. 이를 위해서 우선 순서가 섞인 정수 시퀀스 리스트를 만듬."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "v_tXbVRxEbGs"
   },
   "outputs": [],
   "source": [
    "max_src_len = encoder_input.shape[1]\n",
    "max_tar_len = decoder_input.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "k82IculyEcns"
   },
   "outputs": [],
   "source": [
    "src_vocab_size = len(tokenizer_en.word_index) + 1\n",
    "tar_vocab_size = len(tokenizer_fra.word_index) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "id": "ULv_SgdPEdxI",
    "outputId": "64320f1d-b74d-4c5f-eb63-1769102ab190"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n",
      "16\n"
     ]
    }
   ],
   "source": [
    "print(max_src_len)\n",
    "print(max_tar_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "A4dfzyf4EekM",
    "outputId": "c33d90f4-6b11-40f9-c077-1327f706ab35"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 7619 26228 14062 ... 27462 27058 22843]\n"
     ]
    }
   ],
   "source": [
    "indices = np.arange(encoder_input.shape[0])\n",
    "np.random.shuffle(indices)\n",
    "print(indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xzdqBj_EEfsb"
   },
   "outputs": [],
   "source": [
    "encoder_input = encoder_input[indices]\n",
    "decoder_input = decoder_input[indices]\n",
    "decoder_target = decoder_target[indices]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XLIsxOA3Y2pp"
   },
   "source": [
    "임의로 30,997번째 샘플을 출력. 이때, decoder_input과 decoder_target은 데이터의 구조상으로 앞에 붙은 <sos> 토큰과 뒤에 붙은 <eos>을 제외하면 동일한 정수 시퀀스를 가져야하므로 이를 확인해주면 됨."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "qWPj_gw6Eg0j",
    "outputId": "4ea85ca8-fe92-4ae3-fb18-5d9b74926503"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 25, 354,   8,   6, 833,   1,   0,   0], dtype=int32)"
      ]
     },
     "execution_count": 25,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_input[30997]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "id": "b9Ysww4xEiR0",
    "outputId": "3429f126-4659-4373-ba7a-b39c4835c2f5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   2,   71,  261,    5, 2283,    1,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0], dtype=int32)"
      ]
     },
     "execution_count": 26,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder_input[30997]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "id": "ZWXPtTMYEjdD",
    "outputId": "9757f1ac-4855-4ebc-a697-92264ddc09c4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  71,  261,    5, 2283,    1,    3,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0], dtype=int32)"
      ]
     },
     "execution_count": 27,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder_target[30997]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I2WSpWPdY50B"
   },
   "source": [
    "33,000개의 10%에 해당되는 3,300개의 데이터를 테스트 데이터로 사용.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "empNDTa1En_L",
    "outputId": "20e159b7-c5f0-4ae8-d08f-7fa1a8ed1e93"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3300\n"
     ]
    }
   ],
   "source": [
    "n_of_val = int(33000*0.1)\n",
    "print(n_of_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yo9Z-sZCE-g7"
   },
   "outputs": [],
   "source": [
    "encoder_input_train = encoder_input[:-n_of_val]\n",
    "decoder_input_train = decoder_input[:-n_of_val]\n",
    "decoder_target_train = decoder_target[:-n_of_val]\n",
    "\n",
    "encoder_input_test = encoder_input[-n_of_val:]\n",
    "decoder_input_test = decoder_input[-n_of_val:]\n",
    "decoder_target_test = decoder_target[-n_of_val:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J40n2C1gY7Uj"
   },
   "source": [
    "훈련 데이터와 테스트 데이터의 크기(shape)를 출력해 봄.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6ZelCpZZFAxk"
   },
   "outputs": [],
   "source": [
    "print(encoder_input_train.shape)\n",
    "print(decoder_input_train.shape)\n",
    "print(decoder_target_train.shape)\n",
    "print(encoder_input_test.shape)\n",
    "print(decoder_input_test.shape)\n",
    "print(decoder_target_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qH_XQlCoY8u-"
   },
   "source": [
    "# 모델 설계"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9tz2fpTdFByT"
   },
   "outputs": [],
   "source": [
    "latent_dim = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pBYVD_WMFDKz"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input, LSTM, Embedding, Dense, Masking\n",
    "from tensorflow.keras.models import Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mGFE3CPCZAge"
   },
   "source": [
    "인코더를 설계함. Masking은 패딩 토큰인 숫자 0의 경우에는 연산을 제외하는 역할을 수행함.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_DL3p2XCFHnz"
   },
   "outputs": [],
   "source": [
    "# Encoder\n",
    "encoder_inputs = Input(shape=(None,))\n",
    "enc_emb =  Embedding(src_vocab_size, latent_dim)(encoder_inputs)\n",
    "enc_masking = Masking(mask_value=0.0)(enc_emb)\n",
    "encoder_lstm = LSTM(latent_dim, return_state=True)\n",
    "encoder_outputs, state_h, state_c = encoder_lstm(enc_masking)\n",
    "encoder_states = [state_h, state_c]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qHW7FT1nZBzN"
   },
   "source": [
    "이제 디코더를 설계함.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZsjhAbjNFIcD"
   },
   "outputs": [],
   "source": [
    "decoder_inputs = Input(shape=(None,))\n",
    "dec_emb_layer = Embedding(tar_vocab_size, latent_dim)\n",
    "dec_emb = dec_emb_layer(decoder_inputs)\n",
    "dec_masking = Masking(mask_value=0.0)(dec_emb)\n",
    "\n",
    "decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True)\n",
    "decoder_outputs, _, _ = decoder_lstm(dec_masking,\n",
    "                                     initial_state=encoder_states)\n",
    "\n",
    "decoder_dense = Dense(tar_vocab_size, activation='softmax')\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lBdI0d8lZFmp"
   },
   "source": [
    "seq2seq의 디코더는 기본적으로 각각의 시점(timestep)에 대해서 다중 클래스 분류 문제를 풀고있음. 매 시점마다 프랑스어 단어 집합의 크기의 선택지에서 단어를 1개 선택하여 이를 이번 시점에서 예측한 단어로 택함. 다중 클래스 분류 문제이므로 위의 설계에서 출력층으로 소프트맥스 함수를 사용함. 이 경우 손실 함수를 지금까지 categorical_crossentropy를 사용해옴.\n",
    "\n",
    "categorical_crossentropy를 사용하려면 레이블은 원-핫 인코딩이 된 상태여야 함. 그런데 현재 decoder_outputs의 경우에는 원-핫 인코딩을 하지 않은 상태. 원-핫 인코딩을 하지 않은 상태로, 정수 레이블에 대해서 다중 클래스 분류 문제를 풀고자 하는 경우에는 categorical_crossentropy함수가 아니라 sparse_categorical_crossentropy를 사용하면 됨. 이는 케라스에서 규정한 약속."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "S8Do1kUQFUZj"
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='rmsprop', loss='sparse_categorical_crossentropy', metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 174
    },
    "id": "SFnGV0luFcwq",
    "outputId": "2d918ee8-640c-474e-f9fc-9bfa6bf07e93"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-5f15418b3570>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ur3-tcnzZJPW"
   },
   "source": [
    "128개의 배치 크기로 총 50 에포크 학습. 테스트 데이터를 검증 데이터로 사용하여 훈련이 제대로 되고있는지 모니터링."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "uYoGVgeqFifz",
    "outputId": "e5f0a116-1fcf-4082-ca09-dd7319aa135c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "233/233 [==============================] - 13s 56ms/step - loss: 3.1782 - acc: 0.6067 - val_loss: 1.9140 - val_acc: 0.6834\n",
      "Epoch 2/50\n",
      "233/233 [==============================] - 11s 45ms/step - loss: 1.7352 - acc: 0.7244 - val_loss: 1.6502 - val_acc: 0.7357\n",
      "Epoch 3/50\n",
      "233/233 [==============================] - 11s 45ms/step - loss: 1.5542 - acc: 0.7470 - val_loss: 1.5380 - val_acc: 0.7545\n",
      "Epoch 4/50\n",
      "233/233 [==============================] - 11s 45ms/step - loss: 1.4470 - acc: 0.7631 - val_loss: 1.4326 - val_acc: 0.7710\n",
      "Epoch 5/50\n",
      "233/233 [==============================] - 11s 45ms/step - loss: 1.3605 - acc: 0.7778 - val_loss: 1.3632 - val_acc: 0.7812\n",
      "Epoch 6/50\n",
      "233/233 [==============================] - 11s 45ms/step - loss: 1.2941 - acc: 0.7890 - val_loss: 1.3036 - val_acc: 0.7934\n",
      "Epoch 7/50\n",
      "233/233 [==============================] - 11s 45ms/step - loss: 1.2403 - acc: 0.7976 - val_loss: 1.2840 - val_acc: 0.7979\n",
      "Epoch 8/50\n",
      "233/233 [==============================] - 11s 45ms/step - loss: 1.1958 - acc: 0.8041 - val_loss: 1.2313 - val_acc: 0.8043\n",
      "Epoch 9/50\n",
      "233/233 [==============================] - 11s 45ms/step - loss: 1.1575 - acc: 0.8092 - val_loss: 1.2055 - val_acc: 0.8077\n",
      "Epoch 10/50\n",
      "233/233 [==============================] - 11s 46ms/step - loss: 1.1237 - acc: 0.8139 - val_loss: 1.1707 - val_acc: 0.8108\n",
      "Epoch 11/50\n",
      "233/233 [==============================] - 11s 45ms/step - loss: 1.0928 - acc: 0.8181 - val_loss: 1.1613 - val_acc: 0.8137\n",
      "Epoch 12/50\n",
      "233/233 [==============================] - 11s 45ms/step - loss: 1.0649 - acc: 0.8220 - val_loss: 1.1203 - val_acc: 0.8199\n",
      "Epoch 13/50\n",
      "233/233 [==============================] - 11s 45ms/step - loss: 1.0400 - acc: 0.8254 - val_loss: 1.1183 - val_acc: 0.8171\n",
      "Epoch 14/50\n",
      "233/233 [==============================] - 10s 45ms/step - loss: 1.0167 - acc: 0.8283 - val_loss: 1.0926 - val_acc: 0.8225\n",
      "Epoch 15/50\n",
      "233/233 [==============================] - 11s 45ms/step - loss: 0.9945 - acc: 0.8315 - val_loss: 1.0739 - val_acc: 0.8249\n",
      "Epoch 16/50\n",
      "233/233 [==============================] - 11s 45ms/step - loss: 0.9731 - acc: 0.8339 - val_loss: 1.0613 - val_acc: 0.8263\n",
      "Epoch 17/50\n",
      "233/233 [==============================] - 11s 45ms/step - loss: 0.9535 - acc: 0.8366 - val_loss: 1.0487 - val_acc: 0.8285\n",
      "Epoch 18/50\n",
      "233/233 [==============================] - 11s 46ms/step - loss: 0.9359 - acc: 0.8387 - val_loss: 1.0326 - val_acc: 0.8302\n",
      "Epoch 19/50\n",
      "233/233 [==============================] - 10s 45ms/step - loss: 0.9199 - acc: 0.8410 - val_loss: 1.0244 - val_acc: 0.8320\n",
      "Epoch 20/50\n",
      "233/233 [==============================] - 11s 45ms/step - loss: 0.9051 - acc: 0.8431 - val_loss: 1.0099 - val_acc: 0.8340\n",
      "Epoch 21/50\n",
      "233/233 [==============================] - 11s 45ms/step - loss: 0.8912 - acc: 0.8451 - val_loss: 1.0162 - val_acc: 0.8321\n",
      "Epoch 22/50\n",
      "233/233 [==============================] - 11s 45ms/step - loss: 0.8781 - acc: 0.8470 - val_loss: 1.0114 - val_acc: 0.8338\n",
      "Epoch 23/50\n",
      "233/233 [==============================] - 11s 45ms/step - loss: 0.8654 - acc: 0.8490 - val_loss: 0.9919 - val_acc: 0.8370\n",
      "Epoch 24/50\n",
      "233/233 [==============================] - 11s 45ms/step - loss: 0.8524 - acc: 0.8508 - val_loss: 0.9754 - val_acc: 0.8389\n",
      "Epoch 25/50\n",
      "233/233 [==============================] - 11s 45ms/step - loss: 0.8399 - acc: 0.8528 - val_loss: 0.9716 - val_acc: 0.8395\n",
      "Epoch 26/50\n",
      "233/233 [==============================] - 11s 46ms/step - loss: 0.8279 - acc: 0.8544 - val_loss: 0.9644 - val_acc: 0.8407\n",
      "Epoch 27/50\n",
      "233/233 [==============================] - 11s 46ms/step - loss: 0.8164 - acc: 0.8562 - val_loss: 0.9729 - val_acc: 0.8402\n",
      "Epoch 28/50\n",
      "233/233 [==============================] - 11s 45ms/step - loss: 0.8043 - acc: 0.8579 - val_loss: 0.9569 - val_acc: 0.8408\n",
      "Epoch 29/50\n",
      "233/233 [==============================] - 11s 45ms/step - loss: 0.7920 - acc: 0.8594 - val_loss: 0.9545 - val_acc: 0.8415\n",
      "Epoch 30/50\n",
      "233/233 [==============================] - 11s 45ms/step - loss: 0.7816 - acc: 0.8615 - val_loss: 0.9394 - val_acc: 0.8423\n",
      "Epoch 31/50\n",
      "233/233 [==============================] - 11s 45ms/step - loss: 0.7734 - acc: 0.8628 - val_loss: 0.9383 - val_acc: 0.8449\n",
      "Epoch 32/50\n",
      "233/233 [==============================] - 10s 45ms/step - loss: 0.7653 - acc: 0.8645 - val_loss: 0.9304 - val_acc: 0.8458\n",
      "Epoch 33/50\n",
      "233/233 [==============================] - 10s 45ms/step - loss: 0.7580 - acc: 0.8660 - val_loss: 0.9268 - val_acc: 0.8461\n",
      "Epoch 34/50\n",
      "233/233 [==============================] - 11s 45ms/step - loss: 0.7506 - acc: 0.8672 - val_loss: 0.9443 - val_acc: 0.8423\n",
      "Epoch 35/50\n",
      "233/233 [==============================] - 11s 45ms/step - loss: 0.7438 - acc: 0.8685 - val_loss: 0.9206 - val_acc: 0.8472\n",
      "Epoch 36/50\n",
      "233/233 [==============================] - 10s 45ms/step - loss: 0.7370 - acc: 0.8700 - val_loss: 0.9137 - val_acc: 0.8493\n",
      "Epoch 37/50\n",
      "233/233 [==============================] - 10s 45ms/step - loss: 0.7309 - acc: 0.8714 - val_loss: 0.9108 - val_acc: 0.8492\n",
      "Epoch 38/50\n",
      "233/233 [==============================] - 10s 45ms/step - loss: 0.7247 - acc: 0.8726 - val_loss: 0.9207 - val_acc: 0.8467\n",
      "Epoch 39/50\n",
      "233/233 [==============================] - 11s 46ms/step - loss: 0.7188 - acc: 0.8741 - val_loss: 0.9058 - val_acc: 0.8506\n",
      "Epoch 40/50\n",
      "233/233 [==============================] - 10s 45ms/step - loss: 0.7128 - acc: 0.8753 - val_loss: 0.9146 - val_acc: 0.8496\n",
      "Epoch 41/50\n",
      "233/233 [==============================] - 10s 45ms/step - loss: 0.7073 - acc: 0.8765 - val_loss: 0.9046 - val_acc: 0.8517\n",
      "Epoch 42/50\n",
      "233/233 [==============================] - 10s 45ms/step - loss: 0.7019 - acc: 0.8778 - val_loss: 0.9108 - val_acc: 0.8495\n",
      "Epoch 43/50\n",
      "233/233 [==============================] - 10s 45ms/step - loss: 0.6968 - acc: 0.8789 - val_loss: 0.8993 - val_acc: 0.8537\n",
      "Epoch 44/50\n",
      "233/233 [==============================] - 11s 45ms/step - loss: 0.6917 - acc: 0.8800 - val_loss: 0.9041 - val_acc: 0.8521\n",
      "Epoch 45/50\n",
      "233/233 [==============================] - 11s 45ms/step - loss: 0.6863 - acc: 0.8812 - val_loss: 0.9038 - val_acc: 0.8527\n",
      "Epoch 46/50\n",
      "233/233 [==============================] - 11s 45ms/step - loss: 0.6809 - acc: 0.8822 - val_loss: 0.9032 - val_acc: 0.8530\n",
      "Epoch 47/50\n",
      "233/233 [==============================] - 10s 45ms/step - loss: 0.6753 - acc: 0.8831 - val_loss: 0.8961 - val_acc: 0.8543\n",
      "Epoch 48/50\n",
      "233/233 [==============================] - 10s 45ms/step - loss: 0.6701 - acc: 0.8838 - val_loss: 0.8982 - val_acc: 0.8540\n",
      "Epoch 49/50\n",
      "233/233 [==============================] - 10s 45ms/step - loss: 0.6643 - acc: 0.8848 - val_loss: 0.8896 - val_acc: 0.8553\n",
      "Epoch 50/50\n",
      "233/233 [==============================] - 10s 45ms/step - loss: 0.6586 - acc: 0.8860 - val_loss: 0.8882 - val_acc: 0.8548\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f47f16634e0>"
      ]
     },
     "execution_count": 64,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x=[encoder_input_train, decoder_input_train], y=decoder_target_train, \\\n",
    "          validation_data = ([encoder_input_test, decoder_input_test], decoder_target_test),\n",
    "          batch_size=128, epochs=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EcHcoPgBZMya"
   },
   "source": [
    "# 테스트 과정을 위한 모델 재구성"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vLbN9S_OZOWA"
   },
   "source": [
    "seq2seq는 훈련 과정과 테스트 과정에서의 동작 방식이 다름. 그래서 테스트 과정을 위해 모델을 다시 설계해주어야 함. 특히 디코더를 많이 수정해야 함. 우선 테스트 과정에서의 인코더 모델을 설계함."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "w82HuG0hFkGz"
   },
   "outputs": [],
   "source": [
    "# Encode the input sequence to get the \"thought vectors\"\n",
    "encoder_model = Model(encoder_inputs, encoder_states)\n",
    "\n",
    "# 디코더\n",
    "# 이전 시점의 상태를 보관할 텐서\n",
    "decoder_state_input_h = Input(shape=(latent_dim,))\n",
    "decoder_state_input_c = Input(shape=(latent_dim,))\n",
    "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "\n",
    "dec_emb2= dec_emb_layer(decoder_inputs) # 훈련 때 사용했던 임베딩 층을 재사용\n",
    "\n",
    "# 다음 단어 예측을 위해 이전 시점의 상태를 현 시점의 초기 상태로 사용\n",
    "decoder_outputs2, state_h2, state_c2 = decoder_lstm(dec_emb2, initial_state=decoder_states_inputs)\n",
    "decoder_states2 = [state_h2, state_c2]\n",
    "decoder_outputs2 = decoder_dense(decoder_outputs2) # 모든 시점에 대해서 단어 예측\n",
    "\n",
    "\n",
    "decoder_model = Model(\n",
    "    [decoder_inputs] + decoder_states_inputs,\n",
    "    [decoder_outputs2] + decoder_states2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hI6chti5ZUn-"
   },
   "source": [
    "테스트 과정을 위한 모델 설계를 완료. 이제 테스트 과정에서의 동작을 위한 decode_sequence 함수를 구현.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "k2aMaYinHCWq"
   },
   "outputs": [],
   "source": [
    "def decode_sequence(input_seq):\n",
    "    # 입력으로부터 인코더의 상태를 얻음\n",
    "    states_value = encoder_model.predict(input_seq)\n",
    "\n",
    "    # <SOS>에 해당하는 정수 생성\n",
    "    target_seq = np.zeros((1,1))\n",
    "    target_seq[0, 0] = tar_to_index['<sos>']\n",
    "\n",
    "    stop_condition = False\n",
    "    decoded_sentence = ''\n",
    "\n",
    "    # stop_condition이 True가 될 때까지 루프 반복\n",
    "    # 구현의 간소화를 위해서 이 함수는 배치 크기를 1로 가정.\n",
    "    while not stop_condition:\n",
    "        # 이점 시점의 상태 states_value를 현 시점의 초기 상태로 사용\n",
    "        output_tokens, h, c = decoder_model.predict([target_seq] + states_value)\n",
    "\n",
    "        # 예측 결과를 단어로 변환\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        sampled_char = index_to_tar[sampled_token_index]\n",
    "\n",
    "         # 현재 시점의 예측 단어를 예측 문장에 추가\n",
    "        decoded_sentence += ' '+sampled_char\n",
    "\n",
    "        # <eos>에 도달하거나 정해진 길이를 넘으면 중단.\n",
    "        if (sampled_char == '<eos>' or\n",
    "           len(decoded_sentence) > 50):\n",
    "            stop_condition = True\n",
    "\n",
    "        # 현재 시점의 예측 결과를 다음 시점의 입력으로 사용하기 위해 저장\n",
    "        target_seq = np.zeros((1,1))\n",
    "        target_seq[0, 0] = sampled_token_index\n",
    "\n",
    "        # 현재 시점의 상태를 다음 시점의 상태로 사용하기 위해 저장\n",
    "        states_value = [h, c]\n",
    "\n",
    "    return decoded_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Dzrv-d2UHDtj"
   },
   "outputs": [],
   "source": [
    "# 원문의 정수 시퀀스를 텍스트 시퀀스로 변환\n",
    "def seq2src(input_seq):\n",
    "    temp=''\n",
    "    for i in input_seq:\n",
    "        if(i!=0):\n",
    "            temp = temp + index_to_src[i]+' '\n",
    "    return temp\n",
    "\n",
    "# 번역문의 정수 시퀀스를 텍스트 시퀀스로 변환\n",
    "def seq2tar(input_seq):\n",
    "    temp=''\n",
    "    for i in input_seq:\n",
    "        if((i!=0 and i!=tar_to_index['<sos>']) and i!=tar_to_index['<eos>']):\n",
    "            temp = temp + index_to_tar[i] + ' '\n",
    "    return temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 461
    },
    "id": "GMThbz_THLCT",
    "outputId": "e6c5b202-281e-4f78-c20a-ab448b14866e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "원문 :  i mopped the floor . \n",
      "번역문 : j ai lave par terre . \n",
      "예측문 :  j ai ete un fois . \n",
      "\n",
      "\n",
      "원문 :  he dislikes me . \n",
      "번역문 : il eprouve de l antipathie a mon egard . \n",
      "예측문 :  il m a de l dois . \n",
      "\n",
      "\n",
      "원문 :  i hate violence . \n",
      "번역문 : je deteste la violence . \n",
      "예측문 :  je deteste la bonne . \n",
      "\n",
      "\n",
      "원문 :  please stop . \n",
      "번역문 : veuillez arreter . \n",
      "예측문 :  s il te plait ne plait pas ! \n",
      "\n",
      "\n",
      "원문 :  they calmed down . \n",
      "번역문 : elles se sont calmees . \n",
      "예측문 :  ils se sont pas . \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for seq_index in [3,50,100,300,1001]:\n",
    "  input_seq = encoder_input_train[seq_index: seq_index + 1]\n",
    "  decoded_sentence = decode_sequence(input_seq)\n",
    "  \n",
    "  print(\"원문 : \",seq2src(encoder_input_train[seq_index]))\n",
    "  print(\"번역문 :\",seq2tar(decoder_input_train[seq_index]))\n",
    "  print(\"예측문 :\",decoded_sentence[:-5])\n",
    "  print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 461
    },
    "id": "A_wo-Yt4HNHk",
    "outputId": "f35bdcfe-1bfc-4d1f-e265-22b4cf22d5f8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "원문 :  make an appointment . \n",
      "번역문 : prenez rendez vous . \n",
      "예측문 :  un importe ! \n",
      "\n",
      "\n",
      "원문 :  tom did it all . \n",
      "번역문 : tom a tout fait . \n",
      "예측문 :  tom fait tout ce coup de de nous . \n",
      "\n",
      "\n",
      "원문 :  i m afraid not . \n",
      "번역문 : je crains que non . \n",
      "예측문 :  je n ai pas de enfants . \n",
      "\n",
      "\n",
      "원문 :  is anyone hurt ? \n",
      "번역문 : quelqu un est il blesse ? \n",
      "예측문 :  quiconque est il blesse ? \n",
      "\n",
      "\n",
      "원문 :  i left you a note . \n",
      "번역문 : je vous laissai une note . \n",
      "예측문 :  je vous ai vu . \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for seq_index in [3,50,100,300,1001]:\n",
    "  input_seq = encoder_input_test[seq_index: seq_index + 1]\n",
    "  decoded_sentence = decode_sequence(input_seq)\n",
    "  \n",
    "  print(\"원문 : \",seq2src(encoder_input_test[seq_index]))\n",
    "  print(\"번역문 :\",seq2tar(decoder_input_test[seq_index]))\n",
    "  print(\"예측문 :\",decoded_sentence[:-5])\n",
    "  print(\"\\n\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "ocLj77k7Ycoo",
    "Nhm7rDKlYkD7",
    "qH_XQlCoY8u-",
    "EcHcoPgBZMya"
   ],
   "machine_shape": "hm",
   "name": "Learning Spoons 6강 word-level seq2seq (functional api).ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
