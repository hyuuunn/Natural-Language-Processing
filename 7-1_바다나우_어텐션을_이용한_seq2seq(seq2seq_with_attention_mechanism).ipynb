{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NbOYObhfIybC"
   },
   "source": [
    "# 바다나우 어텐션을 사용한 seq2seq 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LtdsMpkFHp5d"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import unicodedata\n",
    "import re\n",
    "import numpy as np\n",
    "import os\n",
    "import io\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lBo1YqjFI2cs"
   },
   "source": [
    "## 데이터 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ru0PSk3rH3ra",
    "outputId": "b84aef26-3774-4cb9-b722-f6ec04e4b31f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from http://storage.googleapis.com/download.tensorflow.org/data/spa-eng.zip\n",
      "2646016/2638744 [==============================] - 0s 0us/step\n",
      "2654208/2638744 [==============================] - 0s 0us/step\n"
     ]
    }
   ],
   "source": [
    "path_to_zip = tf.keras.utils.get_file(\n",
    "    'spa-eng.zip', origin='http://storage.googleapis.com/download.tensorflow.org/data/spa-eng.zip',\n",
    "    extract=True)\n",
    "\n",
    "path_to_file = os.path.dirname(path_to_zip)+\"/spa-eng/spa.txt\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CLhPJ7wxI3pR"
   },
   "source": [
    "## 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pN95rOREH5CA"
   },
   "outputs": [],
   "source": [
    "# 유니코드를 아스키로 변환\n",
    "def unicode_to_ascii(s):\n",
    "  return ''.join(c for c in unicodedata.normalize('NFD', s)\n",
    "      if unicodedata.category(c) != 'Mn')\n",
    "\n",
    "\n",
    "def preprocess_sentence(w):\n",
    "  w = unicode_to_ascii(w.lower().strip())\n",
    "\n",
    "  # 단어와 특수 문자 사이에 공백 넣기\n",
    "  # eg: \"he is a boy.\" => \"he is a boy .\"\n",
    "  # Reference:- https://stackoverflow.com/questions/3645931/python-padding-punctuation-with-white-spaces-keeping-punctuation\n",
    "  w = re.sub(r\"([?.!,¿])\", r\" \\1 \", w)\n",
    "  w = re.sub(r'[\" \"]+', \" \", w)\n",
    "\n",
    "  # 영어와 일부 특수문자(a-z, A-Z, \".\", \"?\", \"!\", \",\")를 제외하고는 전부 공백으로 변환\n",
    "  w = re.sub(r\"[^a-zA-Z?.!,¿]+\", \" \", w)\n",
    "\n",
    "  w = w.strip()\n",
    "\n",
    "  # 문장의 시작과 끝에 <start> 토큰화 <end> 토큰 추가\n",
    "  w = '<start> ' + w + ' <end>'\n",
    "  return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oEp9mshtH6eo",
    "outputId": "06820ab4-17c0-45f9-899e-b924bcca0972"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<start> may i borrow this book ? <end>\n",
      "b'<start> \\xc2\\xbf puedo tomar prestado este libro ? <end>'\n"
     ]
    }
   ],
   "source": [
    "# 임의 선정한 문장에 대해서 전처리 결과 확인\n",
    "en_sentence = u\"May I borrow this book?\"\n",
    "sp_sentence = u\"¿Puedo tomar prestado este libro?\"\n",
    "print(preprocess_sentence(en_sentence))\n",
    "print(preprocess_sentence(sp_sentence).encode('utf-8'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eCu_zEnzNgmu"
   },
   "source": [
    "## 토큰화 / 정수 인코딩 / 패딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8RvGuDT2H7aw"
   },
   "outputs": [],
   "source": [
    "def create_dataset(path, num_examples):\n",
    "  lines = io.open(path, encoding='UTF-8').read().strip().split('\\n')\n",
    "  word_pairs = [[preprocess_sentence(w) for w in l.split('\\t')]  for l in lines[:num_examples]]\n",
    "  return zip(*word_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xBHYgwywH9KJ",
    "outputId": "6a6389c2-48e9-4c60-a30f-d55568c011fc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<start> if you want to sound like a native speaker , you must be willing to practice saying the same sentence over and over in the same way that banjo players practice the same phrase over and over until they can play it correctly and at the desired tempo . <end>\n",
      "<start> si quieres sonar como un hablante nativo , debes estar dispuesto a practicar diciendo la misma frase una y otra vez de la misma manera en que un musico de banjo practica el mismo fraseo una y otra vez hasta que lo puedan tocar correctamente y en el tiempo esperado . <end>\n"
     ]
    }
   ],
   "source": [
    "# 지금까지 선언한 전처리 함수들을 실제 데이터셋에 적용한다면?\n",
    "en, sp = create_dataset(path_to_file, None)\n",
    "print(en[-1])\n",
    "print(sp[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BujkIGW3H-Yh"
   },
   "outputs": [],
   "source": [
    "# 토큰화 / 정수 인코딩 / 패딩을 하는 함수\n",
    "def tokenize(lang):\n",
    "  lang_tokenizer = tf.keras.preprocessing.text.Tokenizer(\n",
    "      filters='')\n",
    "  lang_tokenizer.fit_on_texts(lang)\n",
    "\n",
    "  tensor = lang_tokenizer.texts_to_sequences(lang)\n",
    "\n",
    "  tensor = tf.keras.preprocessing.sequence.pad_sequences(tensor,\n",
    "                                                         padding='post')\n",
    "\n",
    "  return tensor, lang_tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2ON5PeOLH_Qg"
   },
   "outputs": [],
   "source": [
    "# 입력된 데이터셋에 대해서 토큰화 / 정수 인코딩 / 패딩을 수행\n",
    "def load_dataset(path, num_examples=None):\n",
    "  # creating cleaned input, output pairs\n",
    "  targ_lang, inp_lang = create_dataset(path, num_examples)\n",
    "\n",
    "  input_tensor, inp_lang_tokenizer = tokenize(inp_lang)\n",
    "  target_tensor, targ_lang_tokenizer = tokenize(targ_lang)\n",
    "\n",
    "  return input_tensor, target_tensor, inp_lang_tokenizer, targ_lang_tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qMbF1yltIAJA"
   },
   "outputs": [],
   "source": [
    "# 샘플 수는 3만개로 제한하며\n",
    "# 실제로 토큰화, 정수 인코딩, 패딩을 수행\n",
    "num_examples = 30000\n",
    "input_tensor, target_tensor, inp_lang, targ_lang = load_dataset(path_to_file, num_examples)\n",
    "\n",
    "# 최대 길이 계산\n",
    "max_length_targ, max_length_inp = target_tensor.shape[1], input_tensor.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QIUa4DCmIHOK",
    "outputId": "e5599415-97aa-4d99-b718-b6525b86ec43"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24000 24000 6000 6000\n"
     ]
    }
   ],
   "source": [
    "# 8:2 비율로 분할\n",
    "input_tensor_train, input_tensor_val, target_tensor_train, target_tensor_val = train_test_split(input_tensor, target_tensor, test_size=0.2)\n",
    "\n",
    "# 샘플 개수\n",
    "print(len(input_tensor_train), len(target_tensor_train), len(input_tensor_val), len(target_tensor_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hlHqgMzLJ7v9",
    "outputId": "4c7f40ff-3602-403e-c686-310d477c7db6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   1,    4, 2991, 1552,   10,   41,    3,    2,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0], dtype=int32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_tensor_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5GAdOavMJ92U",
    "outputId": "80f14746-6b87-43a2-c21c-976d93d040fb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   1,    5,  452, 1000,   45,    3,    2,    0,    0,    0,    0],\n",
       "      dtype=int32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_tensor_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mXawN-poJ_vk",
    "outputId": "ce6e18d6-c689-4af3-ca0d-47ecd3933847"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  1,   6,  46, 106, 863,   5,   2,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0], dtype=int32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_tensor_val[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UVyxguFUKBN3",
    "outputId": "9c85decd-75f8-4bf5-ed8d-f5e702c913e1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  1,  60, 180,  15,  72,  17,   7,   2,   0,   0,   0], dtype=int32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_tensor_val[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_2NgIgRxIMMy"
   },
   "outputs": [],
   "source": [
    "def convert(lang, tensor):\n",
    "  for t in tensor:\n",
    "    if t!=0:\n",
    "      print (\"%d ----> %s\" % (t, lang.index_word[t]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "r8J31C_7IOwA",
    "outputId": "20c3993a-0243-43e5-81d6-953e3b24b7b4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Language; index to word mapping\n",
      "1 ----> <start>\n",
      "4 ----> tom\n",
      "2991 ----> seguia\n",
      "1552 ----> llamando\n",
      "10 ----> a\n",
      "41 ----> mary\n",
      "3 ----> .\n",
      "2 ----> <end>\n",
      "\n",
      "Target Language; index to word mapping\n",
      "1 ----> <start>\n",
      "5 ----> tom\n",
      "452 ----> kept\n",
      "1000 ----> calling\n",
      "45 ----> mary\n",
      "3 ----> .\n",
      "2 ----> <end>\n"
     ]
    }
   ],
   "source": [
    "print (\"Input Language; index to word mapping\")\n",
    "convert(inp_lang, input_tensor_train[0])\n",
    "print ()\n",
    "print (\"Target Language; index to word mapping\")\n",
    "convert(targ_lang, target_tensor_train[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NrtxudgANj5T"
   },
   "source": [
    "## 텐서플로우 데이터셋 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Q7jSoEehIPw4"
   },
   "outputs": [],
   "source": [
    "# 하이퍼파라미터 정의\n",
    "BUFFER_SIZE = len(input_tensor_train)\n",
    "BATCH_SIZE = 64\n",
    "steps_per_epoch = len(input_tensor_train)//BATCH_SIZE\n",
    "embedding_dim = 256\n",
    "units = 1024\n",
    "\n",
    "# 단어 집합의 크기 정의\n",
    "vocab_inp_size = len(inp_lang.word_index)+1\n",
    "vocab_tar_size = len(targ_lang.word_index)+1\n",
    "\n",
    "# 데이터셋 생성\n",
    "dataset = tf.data.Dataset.from_tensor_slices((input_tensor_train, target_tensor_train)).shuffle(BUFFER_SIZE)\n",
    "dataset = dataset.batch(BATCH_SIZE, drop_remainder=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9evNF3UIIRlw",
    "outputId": "7f67d65c-6b03-4ebb-eaea-0a9fd2d773e7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([64, 16]), TensorShape([64, 11]))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 첫번째 배치에 대해서 크기 출력\n",
    "example_input_batch, example_target_batch = next(iter(dataset))\n",
    "example_input_batch.shape, example_target_batch.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1oAGjZ0lNnYZ"
   },
   "source": [
    "## 인코더 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tkxeiQOiIS6o"
   },
   "outputs": [],
   "source": [
    "# 인코더 구현\n",
    "class Encoder(tf.keras.Model):\n",
    "  def __init__(self, vocab_size, embedding_dim, enc_units, batch_sz):\n",
    "    super(Encoder, self).__init__()\n",
    "    # 선언부\n",
    "    self.batch_sz = batch_sz\n",
    "    self.enc_units = enc_units\n",
    "\n",
    "    # 임베딩 층\n",
    "    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
    "\n",
    "    # GRU\n",
    "    self.gru = tf.keras.layers.GRU(self.enc_units,\n",
    "                                   return_sequences=True, # 인코더의 모든 히든스테이트를 사용.\n",
    "                                   return_state=True,\n",
    "                                   recurrent_initializer='glorot_uniform')\n",
    "\n",
    "  # 함수형 API와 유사하게 실제 동작은 이곳에서 정의\n",
    "  def call(self, x, hidden):\n",
    "    x = self.embedding(x)\n",
    "    output, state = self.gru(x, initial_state = hidden)\n",
    "    return output, state\n",
    "\n",
    "  # 초기 은닉 상태는 제로 벡터로 사용\n",
    "  def initialize_hidden_state(self):\n",
    "    return tf.zeros((self.batch_sz, self.enc_units))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7DB_PkKuIUW5"
   },
   "outputs": [],
   "source": [
    "# 인코더 구현\n",
    "encoder = Encoder(vocab_inp_size, embedding_dim, units, BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2Uww1VNyKZ8F",
    "outputId": "b33fd724-36d3-4d9f-d913-36f4bacceb81"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoder output shape: (batch size, sequence length, units) (64, 16, 1024)\n",
      "Encoder Hidden state shape: (batch size, units) (64, 1024)\n"
     ]
    }
   ],
   "source": [
    "# 제로 벡터 생성\n",
    "sample_hidden = encoder.initialize_hidden_state()\n",
    "\n",
    "# 임의의 테스트 입력과 제로 벡터를 입력\n",
    "sample_output, sample_hidden = encoder(example_input_batch, sample_hidden)\n",
    "\n",
    "# (64, 16, 1024)는 각각 (배치 크기, 문장 길이, 은닉 상태의 차원)\n",
    "# (64, 1024)는 각각 (배치 크기, 은닉 상태의 차원)\n",
    "print ('Encoder output shape: (batch size, sequence length, units) {}'.format(sample_output.shape))\n",
    "print ('Encoder Hidden state shape: (batch size, units) {}'.format(sample_hidden.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_RedqobyNose"
   },
   "source": [
    "## 바다나우 어텐션 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "biLXhaYNIVLw"
   },
   "outputs": [],
   "source": [
    "# 바다나우 어텐션 구현\n",
    "class BahdanauAttention(tf.keras.layers.Layer):\n",
    "  def __init__(self, units):\n",
    "    super(BahdanauAttention, self).__init__()\n",
    "    self.W1 = tf.keras.layers.Dense(units)\n",
    "    self.W2 = tf.keras.layers.Dense(units)\n",
    "    self.V = tf.keras.layers.Dense(1)\n",
    "\n",
    "  def call(self, query, values):\n",
    "    # query hidden state shape == (batch_size, hidden size)\n",
    "    # query_with_time_axis shape == (batch_size, 1, hidden size)\n",
    "    # values shape == (batch_size, max_len, hidden size)\n",
    "    # we are doing this to broadcast addition along the time axis to calculate the score\n",
    "    query_with_time_axis = tf.expand_dims(query, 1)\n",
    "    print('query_with_time_axis의 shape', query_with_time_axis.shape)\n",
    "\n",
    "    # score shape == (batch_size, max_length, 1)\n",
    "    # we get 1 at the last axis because we are applying score to self.V\n",
    "    # the shape of the tensor before applying self.V is (batch_size, max_length, units)\n",
    "    score = self.V(tf.nn.tanh(\n",
    "        self.W1(query_with_time_axis) + self.W2(values)))\n",
    "\n",
    "    # attention_weights shape == (batch_size, max_length, 1)\n",
    "    attention_weights = tf.nn.softmax(score, axis=1)\n",
    "\n",
    "    # context_vector shape after sum == (batch_size, hidden_size)\n",
    "    context_vector = attention_weights * values\n",
    "    context_vector = tf.reduce_sum(context_vector, axis=1)\n",
    "\n",
    "    return context_vector, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XqKdg7KvIWK4",
    "outputId": "18b8b7ed-3a0f-4a1e-8655-44925f5b2d2b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "query_with_time_axis의 shape (64, 1, 1024)\n",
      "Attention result shape: (batch size, units) (64, 1024)\n",
      "Attention weights shape: (batch_size, sequence_length, 1) (64, 16, 1)\n"
     ]
    }
   ],
   "source": [
    "# 바다나우 어텐션 실제 구현 및 리턴한 값 크기 확인\n",
    "attention_layer = BahdanauAttention(10)\n",
    "attention_result, attention_weights = attention_layer(sample_hidden, sample_output)\n",
    "\n",
    "print(\"Attention result shape: (batch size, units) {}\".format(attention_result.shape))\n",
    "print(\"Attention weights shape: (batch_size, sequence_length, 1) {}\".format(attention_weights.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QTfriV2TNqJu"
   },
   "source": [
    "## 디코더 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xx993wZwIXHQ"
   },
   "outputs": [],
   "source": [
    "# 바다나우 어텐션을 사용한 디코더 구현\n",
    "\n",
    "class Decoder(tf.keras.Model):\n",
    "  def __init__(self, vocab_size, embedding_dim, dec_units, batch_sz):\n",
    "    super(Decoder, self).__init__()\n",
    "    self.batch_sz = batch_sz\n",
    "    self.dec_units = dec_units\n",
    "    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
    "    self.gru = tf.keras.layers.GRU(self.dec_units,\n",
    "                                   return_sequences=True,\n",
    "                                   return_state=True,\n",
    "                                   recurrent_initializer='glorot_uniform')\n",
    "    self.fc = tf.keras.layers.Dense(vocab_size)\n",
    "\n",
    "    # 어텐션 사용\n",
    "    self.attention = BahdanauAttention(self.dec_units)\n",
    "\n",
    "  def call(self, x, hidden, enc_output):\n",
    "    # enc_output는 인코더의모든 시점의 은닉 상태\n",
    "    # enc_output shape == (batch_size, max_length, hidden_size)\n",
    "    context_vector, attention_weights = self.attention(hidden, enc_output)\n",
    "\n",
    "    # x shape after passing through embedding == (batch_size, 1, embedding_dim)\n",
    "    x = self.embedding(x)\n",
    "\n",
    "    # 임베딩 벡터와 바다나우 어텐션으로 얻은 컨텍스트 벡터를 concat.\n",
    "    x = tf.concat([tf.expand_dims(context_vector, 1), x], axis=-1)\n",
    "\n",
    "    # concat한 결과를 GRU의 입력으로 사용.\n",
    "    output, state = self.gru(x)\n",
    "\n",
    "    # 현재 시점의 은닉 상태를 리턴\n",
    "    output = tf.reshape(output, (-1, output.shape[2]))\n",
    "\n",
    "    # 이로부터 현재 시점의 단어 예측\n",
    "    x = self.fc(output)\n",
    "\n",
    "    return x, state, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ptmE2cTDIYKA",
    "outputId": "c36dbd22-6e2b-4f6b-8dac-ee4b61d07d1f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decoder output shape: (batch_size, vocab size) (64, 4935)\n"
     ]
    }
   ],
   "source": [
    "decoder = Decoder(vocab_tar_size, embedding_dim, units, BATCH_SIZE)\n",
    "\n",
    "sample_decoder_output, _, _ = decoder(tf.random.uniform((BATCH_SIZE, 1)),\n",
    "                                      sample_hidden, sample_output)\n",
    "\n",
    "print ('Decoder output shape: (batch_size, vocab size) {}'.format(sample_decoder_output.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tCmeSfzyNrZB"
   },
   "source": [
    "## 옵티마이저와 손실 함수 구현"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wMFO87Q6aX0m"
   },
   "source": [
    "categorical_crossentropy : 실제값이 원-핫 인코딩이 되어있어야함.  \n",
    "sparse_categorical_crossentropy : 실제값이 정수여도 됨. (원-핫 인코딩 안 해도 됨.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kluda3OOIZJw"
   },
   "outputs": [],
   "source": [
    "# 옵티마이저와 손실 함수 구현\n",
    "optimizer = tf.keras.optimizers.Adam()\n",
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "    from_logits=True, reduction='none')\n",
    "\n",
    "def loss_function(real, pred):\n",
    "  mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
    "  loss_ = loss_object(real, pred)\n",
    "  print(loss_.dtype)\n",
    "  mask = tf.cast(mask, dtype=loss_.dtype)\n",
    "  loss_ *= mask\n",
    "\n",
    "  return tf.reduce_mean(loss_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-1JMDCL9N1st"
   },
   "source": [
    "## train_step을 이용한 모델 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XBM89d1SIaQI"
   },
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(inp, targ, enc_hidden):\n",
    "  loss = 0\n",
    "\n",
    "  with tf.GradientTape() as tape:\n",
    "    # enc_output = 모든 시점의 인코더의 hidden state : h1, h2, h3, h4\n",
    "    # 어텐션 메커니즘의 values\n",
    "\n",
    "    # enc_hidden : 마지막 시점의 인코더의 hidden state : h4\n",
    "    enc_output, enc_hidden = encoder(inp, enc_hidden)\n",
    "\n",
    "    # 디코더의 첫번째 hidden state로 사용\n",
    "    dec_hidden = enc_hidden\n",
    "\n",
    "    # <SOS> 토큰\n",
    "    dec_input = tf.expand_dims([targ_lang.word_index['<start>']] * BATCH_SIZE, 1)\n",
    "\n",
    "    # 교사 강요 - 현재 시점의 타겟을 다음 시점의 입력으로 사용한다.\n",
    "    for t in range(1, targ.shape[1]):\n",
    "      # enc_output는 인코더의 모든 시점의 은닉 상태\n",
    "      predictions, dec_hidden, _ = decoder(dec_input, dec_hidden, enc_output)\n",
    "\n",
    "      loss += loss_function(targ[:, t], predictions)\n",
    "\n",
    "      # 현재 시점의 타겟을 다음 시점의 입력으로 사용\n",
    "      #tf.print(targ[:, t])\n",
    "      # print(targ[:, t].shape)\n",
    "      dec_input = tf.expand_dims(targ[:, t], 1)\n",
    "      #tf.print(dec_input)\n",
    "      # print(dec_input.shape)\n",
    "\n",
    "  batch_loss = (loss / int(targ.shape[1]))\n",
    "\n",
    "  variables = encoder.trainable_variables + decoder.trainable_variables\n",
    "\n",
    "  # 미분\n",
    "  gradients = tape.gradient(loss, variables)\n",
    "\n",
    "  # 파라미터 업데이트\n",
    "  optimizer.apply_gradients(zip(gradients, variables))\n",
    "\n",
    "  return batch_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xnt7QD5NN5Qj"
   },
   "source": [
    "## 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "n6l2lso5IcRA",
    "outputId": "a0304767-0f8e-4eee-de98-6a116236c6ea"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<dtype: 'float32'>\n",
      "<dtype: 'float32'>\n",
      "<dtype: 'float32'>\n",
      "<dtype: 'float32'>\n",
      "<dtype: 'float32'>\n",
      "<dtype: 'float32'>\n",
      "<dtype: 'float32'>\n",
      "<dtype: 'float32'>\n",
      "<dtype: 'float32'>\n",
      "<dtype: 'float32'>\n",
      "<dtype: 'float32'>\n",
      "<dtype: 'float32'>\n",
      "<dtype: 'float32'>\n",
      "<dtype: 'float32'>\n",
      "<dtype: 'float32'>\n",
      "<dtype: 'float32'>\n",
      "<dtype: 'float32'>\n",
      "<dtype: 'float32'>\n",
      "<dtype: 'float32'>\n",
      "<dtype: 'float32'>\n",
      "Epoch 1 Batch 0 Loss 4.5541\n",
      "Epoch 1 Batch 100 Loss 2.1702\n",
      "Epoch 1 Batch 200 Loss 1.8380\n",
      "Epoch 1 Batch 300 Loss 1.6552\n",
      "Epoch 1 Loss 2.0218\n",
      "Time taken for 1 epoch 36.02767276763916 sec\n",
      "\n",
      "Epoch 2 Batch 0 Loss 1.4782\n",
      "Epoch 2 Batch 100 Loss 1.4109\n",
      "Epoch 2 Batch 200 Loss 1.3605\n",
      "Epoch 2 Batch 300 Loss 1.3023\n",
      "Epoch 2 Loss 1.3638\n",
      "Time taken for 1 epoch 24.60355281829834 sec\n",
      "\n",
      "Epoch 3 Batch 0 Loss 1.1087\n",
      "Epoch 3 Batch 100 Loss 1.0323\n",
      "Epoch 3 Batch 200 Loss 0.9410\n",
      "Epoch 3 Batch 300 Loss 0.8995\n",
      "Epoch 3 Loss 0.9552\n",
      "Time taken for 1 epoch 24.61910629272461 sec\n",
      "\n",
      "Epoch 4 Batch 0 Loss 0.5929\n",
      "Epoch 4 Batch 100 Loss 0.6818\n",
      "Epoch 4 Batch 200 Loss 0.5869\n",
      "Epoch 4 Batch 300 Loss 0.6251\n",
      "Epoch 4 Loss 0.6393\n",
      "Time taken for 1 epoch 24.614850997924805 sec\n",
      "\n",
      "Epoch 5 Batch 0 Loss 0.3736\n",
      "Epoch 5 Batch 100 Loss 0.4114\n",
      "Epoch 5 Batch 200 Loss 0.4848\n",
      "Epoch 5 Batch 300 Loss 0.4515\n",
      "Epoch 5 Loss 0.4259\n",
      "Time taken for 1 epoch 24.83034634590149 sec\n",
      "\n",
      "Epoch 6 Batch 0 Loss 0.2435\n",
      "Epoch 6 Batch 100 Loss 0.2299\n",
      "Epoch 6 Batch 200 Loss 0.3689\n",
      "Epoch 6 Batch 300 Loss 0.3204\n",
      "Epoch 6 Loss 0.2895\n",
      "Time taken for 1 epoch 24.723517656326294 sec\n",
      "\n",
      "Epoch 7 Batch 0 Loss 0.1604\n",
      "Epoch 7 Batch 100 Loss 0.1616\n",
      "Epoch 7 Batch 200 Loss 0.2160\n",
      "Epoch 7 Batch 300 Loss 0.2512\n",
      "Epoch 7 Loss 0.2020\n",
      "Time taken for 1 epoch 24.67216920852661 sec\n",
      "\n",
      "Epoch 8 Batch 0 Loss 0.1610\n",
      "Epoch 8 Batch 100 Loss 0.1043\n",
      "Epoch 8 Batch 200 Loss 0.1546\n",
      "Epoch 8 Batch 300 Loss 0.1612\n",
      "Epoch 8 Loss 0.1501\n",
      "Time taken for 1 epoch 24.668740034103394 sec\n",
      "\n",
      "Epoch 9 Batch 0 Loss 0.1119\n",
      "Epoch 9 Batch 100 Loss 0.1272\n",
      "Epoch 9 Batch 200 Loss 0.1011\n",
      "Epoch 9 Batch 300 Loss 0.1344\n",
      "Epoch 9 Loss 0.1152\n",
      "Time taken for 1 epoch 24.494884490966797 sec\n",
      "\n",
      "Epoch 10 Batch 0 Loss 0.0689\n",
      "Epoch 10 Batch 100 Loss 0.0917\n",
      "Epoch 10 Batch 200 Loss 0.0882\n",
      "Epoch 10 Batch 300 Loss 0.0793\n",
      "Epoch 10 Loss 0.0938\n",
      "Time taken for 1 epoch 24.616642951965332 sec\n",
      "\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 10\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "  start = time.time()\n",
    "\n",
    "  enc_hidden = encoder.initialize_hidden_state()\n",
    "  total_loss = 0\n",
    "\n",
    "  for (batch, (inp, targ)) in enumerate(dataset.take(steps_per_epoch)):\n",
    "    batch_loss = train_step(inp, targ, enc_hidden)\n",
    "    total_loss += batch_loss\n",
    "\n",
    "    if batch % 100 == 0:\n",
    "      print('Epoch {} Batch {} Loss {:.4f}'.format(epoch + 1,\n",
    "                                                   batch,\n",
    "                                                   batch_loss.numpy()))\n",
    "\n",
    "  print('Epoch {} Loss {:.4f}'.format(epoch + 1,\n",
    "                                      total_loss / steps_per_epoch))\n",
    "  print('Time taken for 1 epoch {} sec\\n'.format(time.time() - start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I21KTNVEN6R3"
   },
   "source": [
    "## 테스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YyWkH9ZxIgrw"
   },
   "outputs": [],
   "source": [
    "# 테스트 단계에서의 동작\n",
    "def evaluate(sentence):\n",
    "  attention_plot = np.zeros((max_length_targ, max_length_inp))\n",
    "\n",
    "  # 입력된 문장에 대해서 전처리\n",
    "  sentence = preprocess_sentence(sentence)\n",
    "\n",
    "  # 토큰화 및 정수 인코딩 및 패딩\n",
    "  inputs = [inp_lang.word_index[i] for i in sentence.split(' ')]\n",
    "  inputs = tf.keras.preprocessing.sequence.pad_sequences([inputs],\n",
    "                                                         maxlen=max_length_inp,\n",
    "                                                         padding='post')\n",
    "  inputs = tf.convert_to_tensor(inputs)\n",
    "\n",
    "  result = ''\n",
    "\n",
    "  hidden = [tf.zeros((1, units))]\n",
    "\n",
    "  # 인코더 수행\n",
    "  enc_out, enc_hidden = encoder(inputs, hidden)\n",
    "\n",
    "  dec_hidden = enc_hidden\n",
    "  # 시작 토큰 정의\n",
    "  dec_input = tf.expand_dims([targ_lang.word_index['<start>']], 0)\n",
    "\n",
    "  # 테스트 단계\n",
    "  for t in range(max_length_targ):\n",
    "    # 디코더를 동작.\n",
    "    predictions, dec_hidden, attention_weights = decoder(dec_input,\n",
    "                                                         dec_hidden,\n",
    "                                                         enc_out)\n",
    "\n",
    "    # 뒤에서 그래프를 그리기 위해서 어텐션 가중치를 저장\n",
    "    # attention_weights = tf.reshape(attention_weights, (-1, ))\n",
    "    # attention_plot[t] = attention_weights.numpy()\n",
    "\n",
    "    # 예측으로부터 얻은 정수\n",
    "    predicted_id = tf.argmax(predictions[0]).numpy()\n",
    "\n",
    "    # 현재 시점에 예측한 단어를 최종 결과로 리턴할 문장에 추가\n",
    "    result += targ_lang.index_word[predicted_id] + ' '\n",
    "\n",
    "    # eos를 만나면 종료\n",
    "    if targ_lang.index_word[predicted_id] == '<end>':\n",
    "      return result, sentence, attention_plot\n",
    "\n",
    "    # 현재 시점의 예측을 다음 시점의 입력으로 사용\n",
    "    dec_input = tf.expand_dims([predicted_id], 0)\n",
    "\n",
    "  return result, sentence, attention_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KgZ6KdsHIiXQ"
   },
   "outputs": [],
   "source": [
    "# 어텐션 가중치의 시각화\n",
    "def plot_attention(attention, sentence, predicted_sentence):\n",
    "  fig = plt.figure(figsize=(10,10))\n",
    "  ax = fig.add_subplot(1, 1, 1)\n",
    "  ax.matshow(attention, cmap='viridis')\n",
    "\n",
    "  fontdict = {'fontsize': 14}\n",
    "\n",
    "  ax.set_xticklabels([''] + sentence, fontdict=fontdict, rotation=90)\n",
    "  ax.set_yticklabels([''] + predicted_sentence, fontdict=fontdict)\n",
    "\n",
    "  ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "  ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RdEAhmHIN8cT"
   },
   "source": [
    "## 번역 및 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "G657xv8UIjc4"
   },
   "outputs": [],
   "source": [
    "# 입력된 문장에 대해서 번역 및 시각화\n",
    "def translate(sentence):\n",
    "  result, sentence, attention_plot = evaluate(sentence)\n",
    "\n",
    "  print('Input: %s' % (sentence))\n",
    "  print('Predicted translation: {}'.format(result))\n",
    "\n",
    "  attention_plot = attention_plot[:len(result.split(' ')), :len(sentence.split(' '))]\n",
    "  plot_attention(attention_plot, sentence.split(' '), result.split(' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 677
    },
    "id": "xI2t75XvIkgo",
    "outputId": "1331e0dc-bf99-46dd-bc3f-0780733b8b59"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: <start> hace mucho frio aqui . <end>\n",
      "Predicted translation: it s very cold here . <end> \n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "translate(u'hace mucho frio aqui.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 677
    },
    "id": "VN6vP3VPInag",
    "outputId": "89d7b110-ce24-49d3-a8ed-07b8f77ffbe9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: <start> esta es mi vida . <end>\n",
      "Predicted translation: this is my life . <end> \n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAmYAAAJwCAYAAAAjo60MAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deZSlB1nn8d9DEhJDiMgelQCKuLBObFnEwWg8oqickcGVYACHeBwXHFxGjgdlGFHBuODgQkDZVTCjIiI6IDAgi0yIiCwKyC4EiLIkBJIQnvnj3pai0h26Kp1+n1v9+ZxTp2+999btp97T3fXtd63uDgAAy7vO0gMAALAizAAAhhBmAABDCDMAgCGEGQDAEMIMAGAIYQYAMIQwAwAYQpgBAAwhzAAAhhBmA1XVl1TVi6rqDkvPAgAcOcJsprOSnJ7kwQvPAQAcQeUm5rNUVSV5R5IXJPm2JJ/f3VcuOhQAcETYYjbP6Umun+RHk3wyyb0XnQYAOGKE2TxnJTmvuy9N8ofrzwGAo4BdmYNU1fWSvC/Jt3T3y6rqzklemeSU7v7wstMBANc2W8xm+c9JLurulyVJd782yVuSfPeiUwHABqmq61XV91XV5y49y04Js1kekOQZ25Y9I8kDj/woALCxvjPJk7P6ubpR7MocoqpukeTtSb68u9+yZfkXZnWW5ld095sXGg8ANkZVvTjJzZJc2t37lp5nJ4QZALBnVNWtkrw5yV2SvCrJad39xiVn2gm7MgepqlPX1zE74HNHeh4A2EAPSPKy9XHaf5ENu7qBMJvl7Ulusn1hVd1o/RwAcPW+L8nT14+fmeT+B9voMZEwm6WSHGjf8klJPnGEZwGAjVJVX53klCTnrRc9N8mJSb5hsaF26NilByCpqt9YP+wkv1hVl255+pis9pO/9ogPBgCb5awkz+nuS5Kkuy+vqmdndXWDFyw52KESZjPcYf1rJfnyJJdvee7yJBckOedIDwUAm6Kqjs/qMhnfs+2pZyT5q6o6aX+wTeaszCHW+7+fneTB3X3x0vMAwCapqhtndX/pZ3T3p7Y9d2aSF3b3hYsMtwPCbIiqOiar48jutEmn9QIAh4+D/4fo7iuTvDPJdZeeBQBYhi1mg1TVWVntGz+zuy9aeh4AmK6q3p4DX9HgKrr7i67lca4xB//P8hNJbp3kX6rqPUk+tvXJ7r7jIlMBwFyP3/L4pCQPS/LqJK9cL7t7Vlc3+JUjPNeuCLNZzvvsLwEA9uvufw+uqnpKksd09y9sfU1VPTzJ7Y7waLtiVyYAsCdU1UezujfmW7ctv02SC7r75GUmO3QO/gcA9oqPJTn9AMtPT3LpAZaPY1fmIFV13SQ/k9UJAKcmOW7r8919zBJzAcCG+LUkv1lV+5K8ar3sblndEeCRSw21E8Jslv+Z5LuS/GJWf7h+Msmtknx3kkcsNxYAzNfdj62qdyR5aFZ3AUiSNyU5q7ufvdhgO+AYs0HWp/z+YHf/ZVVdnOTO3f3PVfWDSc7o7vstPOJIVfWgfHor42dcB24TTo2Gva6qPi/JN+fAf0cftchQMJQtZrPcLMn+q/5fkuQG68d/meQxi0w0XFX9ZJKHJ3lCknsm+a0kt1k/dn9RWFhV3S3J85JcluQmSf4lySnrz9+RRJhxraiqG2TbsfTd/W8LjXPIHPw/y7uSfP768VuT3Gv9+O5JPr7IRPM9JMnZ3f3wJFckeXx33yer69XcctHJgCT55STPTPIFWd127uuz2nJ2fvyHk8Osqm5ZVc+vqo8n+dckH1x/XLT+dTxbzGb5kyRnZHXA4uOS/EFVPSSrf9B+ecnBBvvCrC4kmKzidf+p0H+wXv6QJYYC/t0dk3x/d3dVXZnk+O5+W1X99yS/n1W0weHy5Kz2Nn1/kvfmEO8IMIkwG2S91Wf/4/Oq6t1J7pHkzd3958tNNtqFSW6c1dbGd2a1dfG1We3O3Li/kLAHXb7l8fuz2pL9pqwO1/j8A34F7N5dktytu1+/9CC7JcwGqap7JnlFd38ySbr7b5P8bVUdW1X37O6XLjvhSC9Kcp8kFyT53SS/VlXfmeS0JBtxBg7scRck+aokb07ykiQ/X1U3S3JmktctOBd709uTHL/0ENeEszIHWW/mP6W7P7Bt+Y2SfMB1zK6qqq6T5Dr7Y7aqvivrrYxJntDdVyw5Hxzt1teTun53v7iqbpLkafn039EHdfc/LDoge0pVfX2Sn07yX7df/X9TCLNBqupTSW7W3R/ctvy2Sc7fhFtJHGlVdWqSd/e2P8hVVUlu0d3vWmYyAI609aWmjk9yTFZn/n5y6/Ob8HPUrswBqurP1g87yTOq6rItTx+T5PZJXnHEB9sMb8/q1PsPbFt+w/VztjICHD1+eOkBrilhNsO/rn+tJB/KZ14a4/Ikf5PkiUd6qA1ROfBB/idldWo+cIStL5Z9SLtjXASaw6m7n7r0DNeUMBugux+UJOvbSJzT3R9bdqL5quo31g87yS9W1dab0x6T1Zk5rz3igwFJ8vgtj09K8rCsLl/zyvWyu2f1d/RXjvBcHAXWJ5c8IMkXJ3lEd19UVfdI8t7ufvuy0312jjEbZH0ge7r7U+vPb57kW5O8sbvtytyiql68fvi1Wf1jv/WU/MuzuqL4Od39liM8GrBFVT0lq0v+/MK25Q9PcrvuPnORwdiTquork/x1Voey3C7Jl62vm/fIJLft7u9dcr5DIcwGqarnJ/nL7n5cVZ2U5B+TXC+r/3F+f3c/bdEBB6qqJyd5aHd/dOlZgKuqqo8mOW37GXJVdZskF2zCwdhsjvV/2l/a3T+3PhHgTuswu3uSP+zu8XeEsStzln1Jfmr9+L5JPprk1knun+QnsjrNnC327wber6o+J6tT8d/S3e9cZqrNY70dXFXdN8lzu/uK9eOD6u4/PkJjbZKPJTk9q9vMbXV6kku3vxiuoa/M6qr/270vq/tRjyfMZjkpyYfXj78xyZ+sfxi8KMlvLjfWXOvdJK/u7t+qqutmdRzL7ZJcXlXf3t3PX3TAoay3HTkvyc2zOvP3vKt5XcdZwAfya0l+c309s1etl90tyVlJHrnUUOxZH0/yeQdY/mW56tn7I7mJ+SzvSnKPqrpeVjcwf8F6+Q3jf5YHc698+h/7+yS5flY/RB8Z/+hfHevtEHX3dfZf9Hn9+GAfouwAuvuxWR2IfYckv7r+uEOSs7rbTcw53J6T5Oeqav/V/7uqbpXkMUn+91JD7YRjzAapqh/I6mymS7K67+Np3f2pqvrRJP+pu79+0QEHqqpPJLlNd7+nqp6U5CPd/ePrv4j/0N3XX3TAoay33Vuf8XWPJDfNZ/7ntrv7t5eZCkiSqjo5yV8kuWNWx2hfmNUuzFck+eZNuOqBXZmDdPcTqur8JKcmecH+szOT/HOSRyw32WgXJrl9Vb0vq61AZ6+Xn5TE7ZgOznrbhao6M8mT8ulrDm79n20nEWawoPWJYF+zvjXTaVn95+mC7n7hspMdOmE2RFV9bpI7dvfLkrxm29MfTvLGIz/VRvi9JM9K8t4kV2Z1mnSS3DWrs1o5MOttdx6d5LFJHrX//qxc1fpMzC9aXz/q4lzNxWadlcnhsvXnaHe/KMmLtjx3j6wuPfWhxQY8RMJsjk8leX5V3au7X75/YVXdKas/XF+w2GSDdfejqur1SW6Z5Nndvf96Zp/M6pgCDsB627WTkzxFlH1WP5Lk4vXjjb9FDhtjT/wcdfD/EN19cVYHLX7ftqcekOSvuvuiIz/Vxvh4km9I8oKqusV62XWzOlaPg7Pedu6ZSb5l6SGm6+6ndvf+e/5+e1Z/pv5gvfwzPhYckz1mr/wcFWazPC3Jd6wvX7D/TgDfm+QpSw41WVXdP8mzk7w5q2u+Hbd+6jr59DXh2MZ627WHJfnmqvrTqvqfVfWzWz+WHm6oS5M8Ncn7q+pJVfW1Sw/EnrbxP0eF2SwvyGorxreuPz8jqy0Yz11sovl+KslDuvu/ZbUbbr9XJbnzMiNtBOttd34gyTcl+eqstgR9x5aP+y0411jrW+DcLKvdm5+f1Rbad1bVL1XV7Zedjj1o43+OCrNB1mdhPiOf3gz7gCTP6m5nyR3cl+TTN0be6pKsjgfiwKy33XlEkh/v7pt29+27+w5bPu649HBTdffHuvsZ3X3vrI7z+eWsfnC+dtnJ2Gv2ws9RB//P87Qkr6mqU7P6H/kZC88z3XuT3Dar675tdc+sLjPCgVlvu3NMkj9beohNVVUnJPn6rC7Rctsk7152Ivaojf45aovZMN39hiSvz+og4/d096sXHmm6c5P8xvpU6CS5RVWdldUlDVxT6uCst915clb3ruUQ1co3VtVTk7w/qz9f701yRnffetnp2Is2/eeoLWYzPS3Jryf5maUHma67H7u+ds0LkpyQ5MVJLktyTne7v+hBWG+7dmKS/1JV90ryumy7GG93/+giU832vqx2jz8/yQOTPG/L5VnYhap6U5Iv6W4/ww9uY3+OuiXTQFV1w6wOlH1Cd1+49DyboKpOTPIVWW0FfmN3u+TDIbDedqaqXnw1T7fbpl1VVT0kyR9194eXnmWvqKofTnKj7v4fS88y1Sb/HBVmAABDOMYMAGAIYQYAMIQwG6yqzl56hk1kve2cdbY71tvuWG87Z53tziauN2E228b9gRrCets562x3rLfdsd52zjrbnY1bb8IMAGCIo/6szOvW8X1Crrf0GAd0RS7LcTl+6TE2jvW2c9bZ7lhvu2O97Zx1tjuT19vF+dBF3X2T7cuP+ovTnZDr5a61UXdrAAA23Av7vO23xEtiVyYAwBjCDABgCGEGADCEMAMAGEKYAQAMIcwAAIYQZgAAQwgzAIAhhBkAwBDCDABgCGEGADCEMAMAGEKYAQAMIcwAAIYQZgAAQwgzAIAhhBkAwBDCDABgCGEGADCEMAMAGEKYAQAMIcwAAIYQZgAAQwgzAIAhhBkAwBDCDABgCGEGADCEMAMAGEKYAQAMIcwAAIYQZgAAQwgzAIAhRoZZVZ1eVV1VN74mrwEA2CQjwqyqXlJVj9/hl70iySlJ/vVaGAkA4Ig7dukBdqu7L09y4dJzAAAcLotvMauqpyT52iQ/tN412UlutX76TlX1t1V1aVWdX1Wnbfm6z9iVWVWfW1VPr6oPVNUnquptVfVjR/r7AQDYrcXDLMlDk7wyyZOz2jV5SpJ3r5/7xSQ/neS0rHZZPrOq6iDv8/NJ7pDkW5N8aZIHJ/mXa29sAIDDa/Fdmd39kaq6PMml3X1hklTVl62ffkR3v3i97FFJ/ibJFyR5zwHe6pZJLujuV68/f+fBfs+qOjvJ2UlyQk48LN8HAMA1NWGL2dV53ZbH713/etODvPa3k3xXVf19VZ1TVV97sDft7nO7e1937zsuxx+uWQEArpHpYXbFlse9/vWAM3f387PaanZOkhsneV5VPfnaHQ8A4PCZEmaXJznmmr5Jd1/U3U/v7gcm+f4kZ1WVTWIAwEZY/BiztXckuUtV3SrJJdlFMK6PQbsgyRuy+r7um+Rt3X3ZYZsSAOBaNGWL2TlZbTV7Y5IPJjl1F+9xWZJHJ/n7JC9Pcv0k33a4BgQAuLZVd3/2V+1hJ9cN+651xtJjAABHkRf2ea/p7n3bl0/ZYgYAcNQTZgAAQwgzAIAhhBkAwBDCDABgCGEGADCEMAMAGEKYAQAMIcwAAIYQZgAAQwgzAIAhhBkAwBDCDABgCGEGADCEMAMAGEKYAQAMIcwAAIYQZgAAQwgzAIAhhBkAwBDCDABgCGEGADCEMAMAGEKYAQAMIcwAAIYQZgAAQwgzAIAhhBkAwBDCDABgCGEGADCEMAMAGEKYAQAMIcwAAIYQZgAAQwgzAIAhhBkAwBDCDABgCGEGADCEMAMAGEKYAQAMIcwAAIYQZgAAQwgzAIAhhBkAwBDCDABgCGEGADCEMAMAGEKYAQAMIcwAAIYQZgAAQwgzAIAhhBkAwBDCDABgCGEGADCEMAMAGEKYAQAMIcwAAIYQZgAAQwgzAIAhhBkAwBDCDABgCGEGADCEMAMAGEKYAQAMIcwAAIbY6DCrqqdU1Z8vPQcAwOFw7NIDXEMPTVJLDwEAcDhsdJh190eWngEA4HDZM7syq+qeVfWqqrqkqj5SVa+uqtsvPSMAwKHa6C1m+1XVsUmek+R3k9w/yXFJTkty5ZJzAQDsxJ4IsyQnJ7lBkud29z+vl/3jwV5cVWcnOTtJTsiJ1/50AACHYKN3Ze7X3f+W5ClJ/qqqnldVD6uqU6/m9ed2977u3ndcjj9icwIAXJ09EWZJ0t0PSnLXJC9Ncp8k/1RV91p2KgCAQ7dnwixJuvvvu/sx3X16kpckOWvZiQAADt2eCLOqunVV/VJVfXVV3bKqvi7JHZO8cenZAAAO1V45+P/SJLdN8kdJbpzk/UmemeQxSw4FALATGx1m3f3ALZ/ed6k5AAAOhz2xKxMAYC8QZgAAQwgzAIAhhBkAwBDCDABgCGEGADCEMAMAGEKYAQAMIcwAAIYQZgAAQwgzAIAhhBkAwBDCDABgCGEGADCEMAMAGEKYAQAMIcwAAIYQZgAAQwgzAIAhhBkAwBDCDABgCGEGADCEMAMAGEKYAQAMIcwAAIYQZgAAQwgzAIAhhBkAwBDCDABgCGEGADCEMAMAGEKYAQAMIcwAAIYQZgAAQwgzAIAhhBkAwBDCDABgCGEGADCEMAMAGEKYAQAMIcwAAIYQZgAAQwgzAIAhhBkAwBDCDABgCGEGADCEMAMAGEKYAQAMIcwAAIYQZgAAQwgzAIAhhBkAwBDCDABgCGEGADCEMAMAGEKYAQAMIcwAAIYQZgAAQwgzAIAhhBkAwBDCDABgCGEGADCEMAMAGEKYAQAMIcwAAIYQZgAAQwgzAIAhhBkAwBDCDABgiHFhVlUvqarfrqpfqap/q6oPVtVDq+r4qvrNqvpwVb2rqh6wfv2Lqurx297j5Kq6tKruu8x3AQCwc+PCbO3+SS5Octckv5Tk15P8aZI3J9mX5KlJnlRVpyR5YpLvrarjt3z99yS5JMlzj+TQAADXxNQwe0N3P7K735LkV5NclOSK7n5cd781yaOSVJJ7JPnjJJ9K8u1bvv7BSZ7W3Vcc6M2r6uyqOr+qzr8il12r3wgAwKGaGmav2/+guzvJB5L8w5ZlVyT5UJKbdvdlSZ6eVYylqm6X5C5Jfvdgb97d53b3vu7ed1yOP9jLAACOqGOXHuAgtm/p6oMs2x+WT0ryuqo6NatAe2V3v+naHREA4PCausVsR7r7DUn+NslDkpyZ5PeWnQgAYOembjHbjScm+Z2stqw9a+FZAAB2bE9sMVt7VpLLkzy7uy9eehgAgJ0at8Wsu08/wLLbH2DZzbctukGSz8nVHPQPADDZuDDbqao6LsmNkvxCkr/r7pcvPBIAwK7shV2Z90jyviRfndXB/wAAG2njt5h190uyutgsAMBG2wtbzAAA9gRhBgAwhDADABhCmAEADCHMAACGEGYAAEMIMwCAIYQZAMAQwgwAYAhhBgAwhDADABhCmAEADCHMAACGEGYAAEMIMwCAIYQZAMAQwgwAYAhhBgAwhDADABhCmAEADCHMAACGEGYAAEMIMwCAIYQZAMAQwgwAYAhhBgAwhDADABhCmAEADCHMAACGEGYAAEMIMwCAIYQZAMAQwgwAYAhhBgAwhDADABhCmAEADCHMAACGEGYAAEMIMwCAIYQZAMAQwgwAYAhhBgAwhDADABhCmAEADCHMAACGEGYAAEMIMwCAIYQZAMAQwgwAYAhhBgAwhDADABhCmAEADCHMAACGEGYAAEMIMwCAIYQZAMAQwgwAYAhhBgAwhDADABhCmAEADCHMAACGEGYAAEMIMwCAIUaGWVU9par+fPvj9efXqaonVNW/VlVX1emLDQoAcBgdu/QAh+ChSWrL5/dO8qAkpyd5W5J/W2AmAIDDbnyYdfdHti26TZL3dfcrlpgHAODaMnJX5lbbd2sm+bUkp653Y75jvbyq6qeq6p+r6uNV9Q9VdeZyUwMA7Nz4LWbbPDTJO5M8OMlXJblyvfznk9wvyQ8l+ackd0/yxKr6UHc/b4lBAQB2aqPCrLs/UlUXJ7myuy9Mkqq6XpKHJfnG7n7Z+qVvr6q7ZBVqVwmzqjo7ydlJckJOPCKzAwB8NhsVZgfxFUlOSPKXVdVblh+X5B0H+oLuPjfJuUlyct2wD/QaAIAjbS+E2f7j5L4tybu2PXfFEZ4FAGDX9kKYvTHJZUlu2d0vWnoYAIDd2vgw6+6Lq+qcJOdUVSV5aZKTktwtyafWuy0BAMbb+DBbe0SS9yf5iSS/neSjSV6b5LFLDgUAsBPVfXQf+35y3bDvWmcsPQYAcBR5YZ/3mu7et335+AvMAgAcLYQZAMAQwgwAYAhhBgAwhDADABhCmAEADCHMAACGEGYAAEMIMwCAIYQZAMAQwgwAYAhhBgAwhDADABhCmAEADCHMAACGEGYAAEMIMwCAIYQZAMAQwgwAYAhhBgAwhDADABhCmAEADCHMAACGEGYAAEMIMwCAIYQZAMAQwgwAYAhhBgAwhDADABhCmAEADCHMAACGEGYAAEMIMwCAIYQZAMAQwgwAYAhhBgAwhDADABhCmAEADCHMAACGEGYAAEMIMwCAIYQZAMAQwgwAYAhhBgAwhDADABhCmAEADCHMAACGEGYAAEMIMwCAIYQZAMAQwgwAYAhhBgAwhDADABhCmAEADCHMAACGEGYAAEMIMwCAIYQZAMAQwgwAYAhhBgAwhDADABhCmAEADCHMAACGEGYAAEMIMwCAIYQZAMAQwgwAYAhhBgAwhDADABhCmAEADHHs0gMsoarOTnJ2kpyQExeeBgBg5ajcYtbd53b3vu7ed1yOX3ocAIAkR2mYAQBMJMwAAIbYs2FWVT9cVf+49BwAAIdqz4ZZkhsn+dKlhwAAOFR7Nsy6+5HdXUvPAQBwqPZsmAEAbBphBgAwhDADABhCmAEADCHMAACGEGYAAEMIMwCAIYQZAMAQwgwAYAhhBgAwhDADABhCmAEADCHMAACGEGYAAEMIMwCAIYQZAMAQwgwAYAhhBgAwhDADABhCmAEADCHMAACGEGYAAEMIMwCAIYQZAMAQwgwAYAhhBgAwhDADABhCmAEADCHMAACGEGYAAEMIMwCAIYQZAMAQwgwAYAhhBgAwhDADABhCmAEADCHMAACGEGYAAEMIMwCAIYQZAMAQwgwAYAhhBgAwhDADABhCmAEADCHMAACGEGYAAEMIMwCAIYQZAMAQwgwAYAhhBgAwhDADABhCmAEADCHMAACGEGYAAEMIMwCAIYQZAMAQwgwAYAhhBgAwhDADABhCmAEADCHMAACGEGYAAEMIMwCAIYQZAMAQwgwAYAhhBgAwxMaEWVX9RFW9Y+k5AACuLRsTZgAAe91hCbOqOrmqbnA43msHv+dNquqEI/l7AgBcm3YdZlV1TFXdq6p+P8mFSe60Xv65VXVuVX2gqi6uqv9bVfu2fN0Dq+qSqjqjql5fVR+rqhdX1a23vf9PVdWF69c+LclJ20a4d5IL17/XPXb7fQAATLHjMKuq21XVY5O8O8mzknwsyTcleWlVVZLnJfmCJN+a5D8keWmSF1XVKVve5vgkD0/y4CR3T3KDJL+z5ff4ziQ/n+TnkpyW5J+SPGzbKM9M8r1Jrp/kBVX11qr62e2BBwCwKQ4pzKrqRlX1o1X1miR/l+TLkjw0yc27+yHd/dLu7iRfl+TOSe7X3a/u7rd29yOSvC3JA7a85bFJfmj9mtclOSfJ6euwS5IfS/LU7n5Cd7+5ux+d5NVbZ+ruT3b3X3T39yS5eZJfWP/+b6mql1TVg6tq+1a2/d/P2VV1flWdf0UuO5RVAABwrTvULWY/kuRxST6R5LbdfZ/u/qPu/sS2131lkhOTfHC9C/KSqrokye2TfPGW113W3f+05fP3Jrluks9bf/7lSV657b23f/7vuvuj3f173f11Sb4qyc2S/G6S+x3k9ed2977u3ndcjr+abxsA4Mg59hBfd26SK5J8X5LXV9WfJHl6kr/u7iu3vO46Sd6f5D8e4D0+uuXxJ7c911u+fseq6visdp2emdWxZ2/Iaqvbc3bzfgAASzikEOru93b3o7v7S5N8Q5JLkvxhkvdU1a9U1Z3XL70gq61Vn1rvxtz68YEdzPWmJHfbtuwzPq+Vr6mqJ2R18sH/SvLWJF/Z3ad19+O6+0M7+D0BABa14y1U3f2q7v7BJKdktYvztkn+X1X9xyQvTPLyJM+pqm+uqltX1d2r6n+snz9Uj0tyVlU9pKq+pKoenuSu215zZpL/k+TkJN+T5Bbd/ZPd/fqdfk8AABMc6q7Mq+juy5Kcl+S8qrppkiu7u6vq3lmdUfnEJDfNatfmy5M8bQfv/ayq+qIkj87qmLU/S/KrSR645WV/ndXJBx+96jsAAGyeWp1MefQ6uW7Yd60zlh4DADiKvLDPe01379u+3C2ZAACGEGYAAEMIMwCAIYQZAMAQwgwAYAhhBgAwhDADABhCmAEADCHMAACGEGYAAEMIMwCAIYQZAMAQwgwAYAhhBgAwhDADABhCmAEADCHMAACGEGYAAEMIMwCAIYQZAMAQwgwAYAhhBgAwhDADABhCmAEADCHMAACGEGYAAEMIMwCAIYQZAMAQwgwAYAhhBgAwhDADABhCmAEADCHMAACGEGYAAEMIMwCAIYQZAMAQwgwAYAhhBgAwhDADABhCmAEADCHMAACGEGYAAEMIMwCAIYQZAMAQwgwAYAhhBgAwhDADABhCmAEADCHMAACGEGYAAEMIMwCAIYQZAMAQwgwAYAhhBgAwhDADABhCmAEADCHMAACGEGYAAEMIMwCAIYQZAMAQwgwAYAhhBgAwhDADABhCmAEADCHMAACGEGYAAEMIMwCAIYQZAMAQwgwAYAhhBgAwxLFLD7CEqjo7ydlJckJOXHgaAICVo3KLWXef2937unvfcTl+6XEAAJIcpWEGADCRMAMAGEKYAQAMIcwAAIYQZgAAQwgzAIAhhBkAwBDCDABgCGEGADCEMAMAGEKYAQAMIcwAAIYQZgAAQwgzAIAhhF3bX60AAAEMSURBVBkAwBDCDABgCGEGADCEMAMAGEKYAQAMIcwAAIYQZgAAQwgzAIAhhBkAwBDCDABgCGEGADCEMAMAGEKYAQAMIcwAAIYQZgAAQwgzAIAhhBkAwBDCDABgCGEGADCEMAMAGEKYAQAMIcwAAIYQZgAAQ1R3Lz3Doqrqg0neufQcB3HjJBctPcQGst52zjrbHettd6y3nbPOdmfyertld99k+8KjPswmq6rzu3vf0nNsGutt56yz3bHedsd62znrbHc2cb3ZlQkAMIQwAwAYQpjNdu7SA2wo623nrLPdsd52x3rbOetsdzZuvTnGDABgCFvMAACGEGYAAEMIMwCAIYQZAMAQwgwAYIj/DyBbdLP/Y1EFAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "translate(u'esta es mi vida.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 677
    },
    "id": "DabTQgnIJotp",
    "outputId": "b07daab9-d309-4801-f9c9-0b26baa50b56"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: <start> ¿ todavia estan en casa ? <end>\n",
      "Predicted translation: are you still at home ? <end> \n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "translate(u'¿todavia estan en casa?')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UdODrOKpTQmw"
   },
   "source": [
    "# Tensorflow.Keras의 model.fit() Vs. Tensorflow Gradient Tape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JxN4FdAgTc14"
   },
   "source": [
    "케라스의 model.fit()과 Gradient Tape()를 사용한 구현의 차이를 이해해봅시다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q8QwYVcvTe-h"
   },
   "source": [
    "##in Tensorflow.Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "id": "YUJAaX1cTbe3",
    "outputId": "8c1ce2f7-389c-42a2-e680-05124e7ee65f"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "\"\\n# 신경망 모델 만들기\\nmodel = tf.keras.models.Sequential()\\n# 완전 연결층을 추가\\nmodel.add(tf.keras.layers.Dense(1))\\n# 옵티마이저와 손실 함수를 지정합니다.\\nmodel.compile(optimizer = 'sgd', loss = 'mse')\\n# 훈련 데이터를 사용하여 에포크 횟수만큼 훈련\\nmodel.fit(x_train, y_train, epochs = 10)\\n\""
      ]
     },
     "execution_count": 35,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "# 신경망 모델 만들기\n",
    "model = tf.keras.models.Sequential()\n",
    "# 완전 연결층을 추가\n",
    "model.add(tf.keras.layers.Dense(1))\n",
    "# 옵티마이저와 손실 함수를 지정합니다.\n",
    "model.compile(optimizer = 'sgd', loss = 'mse')\n",
    "# 훈련 데이터를 사용하여 에포크 횟수만큼 훈련\n",
    "model.fit(x_train, y_train, epochs = 10)\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0blxqtcxTh8Q"
   },
   "source": [
    "## in Tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uT6n4dsrTlpk"
   },
   "source": [
    "tape_gradient() 메서드는 자동 미분 기능을 수행합니다.  \n",
    "자동 미분에 대해서 실습을 통해 이해해봅시다. 임의로 2w^2+5라는 식을 세워보고, w에 대해 미분해보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nArm0SqsTjVG"
   },
   "outputs": [],
   "source": [
    "w = tf.Variable(2.)\n",
    "\n",
    "def f(w):\n",
    "  y = w**2\n",
    "  z = 2*y + 5\n",
    "  return z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wxTDtGkLToDk"
   },
   "source": [
    "이제 gradients를 출력하면 w가 속한 수식을 w로 미분한 값이 저장된 것을 확인할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uSltciVhTmnG",
    "outputId": "da2becee-d598-4420-d9c1-27eb09191484"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<tf.Tensor: shape=(), dtype=float32, numpy=8.0>]\n"
     ]
    }
   ],
   "source": [
    "with tf.GradientTape() as tape:\n",
    "  z = f(w)\n",
    "\n",
    "gradients = tape.gradient(z, [w])\n",
    "print(gradients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 107
    },
    "id": "sruBXUrnTpJG",
    "outputId": "d541cdd9-4259-458d-e8c5-8b2170549241"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'\\n# 훈련할 가중치 변수를 선언\\nw = tf.Variable(tf.zeros(shape=(1)))\\nb = tf.Variable(tf.zeros(shape=(1)))\\n\\n# 경사 하강법 옵티마이저 설정\\noptimizer = tf.optimizer.SGD(lr = 0.01)\\n# 에포크만큼 훈련\\nnum_epochs = 10\\nfor step in range(num_epochs):\\n   \\n    # 예측을 해서 손실을 구하는 과정입니다. (자동 미분을 위해 연산 과정을 기록합니다.)\\n    # tape_gradient() 메서드를 사용하면 그래디언트를 자동으로 계산할 수 있도록 합니다.\\n    with tf.GradientTape() as tape:\\n        z_net = w * x_train + b # 정방향 계산\\n        z_net = tf.reshape(z_net, [-1])\\n        sqr_errors = tf.square(y_train - z_net)\\n        mean_cost = tf.reduce_mean(sqr_errors) # 손실을 계산\\n\\n    # 경사하강법으로 파라미터를 업데이트하는 과정입니다.\\n    # 1. 가중치에 대한 그래디언트 계산\\n    grads = tape.gradient(mean_cost, [w, b])\\n\\n    # 2. 가중치를 업데이트\\n    # apply_gradients() 메서드에는 그래디언트와 가중치를 튜플로 묶은 리스트를 전달해야 합니다.\\n    # 보통 zip()을 주로 사용합니다.\\n    optimizer.apply_gradient(zip(grads, [w, b]))\\n'"
      ]
     },
     "execution_count": 38,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "# 훈련할 가중치 변수를 선언\n",
    "w = tf.Variable(tf.zeros(shape=(1)))\n",
    "b = tf.Variable(tf.zeros(shape=(1)))\n",
    "\n",
    "# 경사 하강법 옵티마이저 설정\n",
    "optimizer = tf.optimizer.SGD(lr = 0.01)\n",
    "# 에포크만큼 훈련\n",
    "num_epochs = 10\n",
    "for step in range(num_epochs):\n",
    "   \n",
    "    # 예측을 해서 손실을 구하는 과정입니다. (자동 미분을 위해 연산 과정을 기록합니다.)\n",
    "    # tape_gradient() 메서드를 사용하면 그래디언트를 자동으로 계산할 수 있도록 합니다.\n",
    "    with tf.GradientTape() as tape:\n",
    "        z_net = w * x_train + b # 정방향 계산\n",
    "        z_net = tf.reshape(z_net, [-1])\n",
    "        sqr_errors = tf.square(y_train - z_net)\n",
    "        mean_cost = tf.reduce_mean(sqr_errors) # 손실을 계산\n",
    "\n",
    "    # 경사하강법으로 파라미터를 업데이트하는 과정입니다.\n",
    "    # 1. 가중치에 대한 그래디언트 계산\n",
    "    grads = tape.gradient(mean_cost, [w, b])\n",
    "\n",
    "    # 2. 가중치를 업데이트\n",
    "    # apply_gradients() 메서드에는 그래디언트와 가중치를 튜플로 묶은 리스트를 전달해야 합니다.\n",
    "    # 보통 zip()을 주로 사용합니다.\n",
    "    optimizer.apply_gradient(zip(grads, [w, b]))\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q9OxQ8VxUCn4"
   },
   "source": [
    "# 텐서플로우 애드온을 이용한 seq2seq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T6hZ0lc1U6nD"
   },
   "source": [
    "어텐션 메커니즘과 상관없이 시간이 남으면 보여드리기 위해 추가한 분량."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DWQ7dTzyUE3P"
   },
   "outputs": [],
   "source": [
    "from datetime import date\n",
    "\n",
    "# cannot use strftime()'s %B format since it depends on the locale\n",
    "MONTHS = [\"January\", \"February\", \"March\", \"April\", \"May\", \"June\",\n",
    "          \"July\", \"August\", \"September\", \"October\", \"November\", \"December\"]\n",
    "\n",
    "def random_dates(n_dates):\n",
    "    min_date = date(1000, 1, 1).toordinal()\n",
    "    max_date = date(9999, 12, 31).toordinal()\n",
    "\n",
    "    ordinals = np.random.randint(max_date - min_date, size=n_dates) + min_date\n",
    "    dates = [date.fromordinal(ordinal) for ordinal in ordinals]\n",
    "\n",
    "    x = [MONTHS[dt.month - 1] + \" \" + dt.strftime(\"%d, %Y\") for dt in dates]\n",
    "    y = [dt.isoformat() for dt in dates]\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Fj8canCoUFwO",
    "outputId": "f068a9cc-fccf-4e26-ac30-b73d7647273e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input                    Target                   \n",
      "--------------------------------------------------\n",
      "September 20, 7075       7075-09-20               \n",
      "May 15, 8579             8579-05-15               \n",
      "January 11, 7103         7103-01-11               \n"
     ]
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "n_dates = 3\n",
    "x_example, y_example = random_dates(n_dates)\n",
    "print(\"{:25s}{:25s}\".format(\"Input\", \"Target\"))\n",
    "print(\"-\" * 50)\n",
    "for idx in range(n_dates):\n",
    "    print(\"{:25s}{:25s}\".format(x_example[idx], y_example[idx]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "lfovg-aMUGp1",
    "outputId": "6048b555-2f92-45de-869d-a9912c80fcdb"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'ADFJMNOSabceghilmnoprstuvy01234567890, '"
      ]
     },
     "execution_count": 41,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "INPUT_CHARS = \"\".join(sorted(set(\"\".join(MONTHS)))) + \"01234567890, \"\n",
    "INPUT_CHARS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "juMGdxMyUImW"
   },
   "outputs": [],
   "source": [
    "OUTPUT_CHARS = \"0123456789-\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "A9BboZRgUJNv"
   },
   "outputs": [],
   "source": [
    "def date_str_to_ids(date_str, chars=INPUT_CHARS):\n",
    "    return [chars.index(c) for c in date_str]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "J6xi0SEfUJ0V",
    "outputId": "1562a246-7edc-4679-ebf6-0c06edf613c5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[7, 11, 19, 22, 11, 16, 9, 11, 20, 38, 28, 26, 37, 38, 33, 26, 33, 31]"
      ]
     },
     "execution_count": 44,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "date_str_to_ids(x_example[0], INPUT_CHARS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BF6-W3-MUKfF",
    "outputId": "c3427eb1-3eb1-4f71-e1a2-d0b11dbca3a4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[7, 0, 7, 5, 10, 0, 9, 10, 2, 0]"
      ]
     },
     "execution_count": 45,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "date_str_to_ids(y_example[0], OUTPUT_CHARS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Z7IFA6c7ULcO"
   },
   "outputs": [],
   "source": [
    "def prepare_date_strs(date_strs, chars=INPUT_CHARS):\n",
    "    X_ids = [date_str_to_ids(dt, chars) for dt in date_strs]\n",
    "    X = tf.ragged.constant(X_ids, ragged_rank=1)\n",
    "    return (X + 1).to_tensor() # using 0 as the padding token ID\n",
    "\n",
    "def create_dataset(n_dates):\n",
    "    x, y = random_dates(n_dates)\n",
    "    return prepare_date_strs(x, INPUT_CHARS), prepare_date_strs(y, OUTPUT_CHARS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VNT-XIg5UMMN"
   },
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "X_train, Y_train = create_dataset(10000)\n",
    "X_valid, Y_valid = create_dataset(2000)\n",
    "X_test, Y_test = create_dataset(2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZkA-wZ6zUM99",
    "outputId": "2f7c3ee1-2e6a-4573-fef9-627e2056ffa3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([ 8 12 20 23 12 17 10 12 21 39 29 27 38 39 34 27 34 32], shape=(18,), dtype=int32)\n",
      "tf.Tensor([ 8  1  8  6 11  1 10 11  3  1], shape=(10,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "print(X_train[0])\n",
    "print(Y_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MbDXzrRQUNzp"
   },
   "outputs": [],
   "source": [
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jm2T8GO5UQNV"
   },
   "source": [
    "텐서플로우 애드온 프로젝트는 여러가지 seq2seq 도구를 포함하고 있어 제품 수준의 seq2seq를 쉽게 만들 수 있음.  \n",
    "우선 인코더의 LSTM에서 return_state=True를 사용한 이후는 디코더에 hidden state를 전달하기 위함.  \n",
    "LSTM을 사용하므로 cell state, hidden state 두 개를 반환.  \n",
    "\n",
    "TrainingSampler는 텐서플로우 애드온에 포함되어져 있는 여러 샘플러 중 하나.  \n",
    "이 샘플러는 각 스텝에서 디코더에게 이전 스텝의 출력이 무엇이었는지 알려줌.  \n",
    "훈련 시에는 이전 타깃 토큰의 임베딩,  \n",
    "테스트 시에는 실제로 출력되는 토큰의 임베딩.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gvlJX2pWUlHq"
   },
   "outputs": [],
   "source": [
    "sos_id = len(OUTPUT_CHARS) + 1\n",
    "\n",
    "def shifted_output_sequences(Y):\n",
    "    sos_tokens = tf.fill(dims=(len(Y), 1), value=sos_id)\n",
    "    return tf.concat([sos_tokens, Y[:, :-1]], axis=1)\n",
    "\n",
    "X_train_decoder = shifted_output_sequences(Y_train)\n",
    "X_valid_decoder = shifted_output_sequences(Y_valid)\n",
    "X_test_decoder = shifted_output_sequences(Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "V3d8_AaGUqZ_",
    "outputId": "2a2b47e3-2d6b-4934-93ed-5ff17a45b70e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([ 8  1  8  6 11  1 10 11  3  1], shape=(10,), dtype=int32)\n",
      "tf.Tensor([12  8  1  8  6 11  1 10 11  3], shape=(10,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "print(Y_train[0])\n",
    "print(X_train_decoder[0]) # 종료 토큰 제거 후 시작 토큰 추가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 388
    },
    "id": "BnoejPh2UOoV",
    "outputId": "d3649409-68b2-4413-8800-ec331de25daf"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-52-b1fff3b2cac6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow_addons\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtfa\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_seed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow_addons'",
      "",
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import tensorflow_addons as tfa\n",
    "\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "encoder_embedding_size = 32\n",
    "decoder_embedding_size = 32\n",
    "units = 128\n",
    "\n",
    "encoder_inputs = keras.layers.Input(shape=[None], dtype=np.int32)\n",
    "decoder_inputs = keras.layers.Input(shape=[None], dtype=np.int32)\n",
    "sequence_lengths = keras.layers.Input(shape=[], dtype=np.int32)\n",
    "\n",
    "encoder_embeddings = keras.layers.Embedding(\n",
    "    len(INPUT_CHARS) + 1, encoder_embedding_size)(encoder_inputs)\n",
    "\n",
    "decoder_embedding_layer = keras.layers.Embedding(\n",
    "    len(INPUT_CHARS) + 2, decoder_embedding_size)\n",
    "decoder_embeddings = decoder_embedding_layer(decoder_inputs)\n",
    "\n",
    "encoder = keras.layers.LSTM(units, return_state=True)\n",
    "encoder_outputs, state_h, state_c = encoder(encoder_embeddings)\n",
    "encoder_state = [state_h, state_c]\n",
    "\n",
    "sampler = tfa.seq2seq.sampler.TrainingSampler()\n",
    "\n",
    "decoder_cell = keras.layers.LSTMCell(units)\n",
    "output_layer = keras.layers.Dense(len(OUTPUT_CHARS) + 1)\n",
    "\n",
    "decoder = tfa.seq2seq.basic_decoder.BasicDecoder(decoder_cell,\n",
    "                                                 sampler,\n",
    "                                                 output_layer=output_layer)\n",
    "final_outputs, final_state, final_sequence_lengths = decoder(\n",
    "    decoder_embeddings,\n",
    "    initial_state=encoder_state)\n",
    "Y_proba = keras.layers.Activation(\"softmax\")(final_outputs.rnn_output)\n",
    "\n",
    "model = keras.models.Model(inputs=[encoder_inputs, decoder_inputs],\n",
    "                           outputs=[Y_proba])\n",
    "optimizer = keras.optimizers.Nadam()\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=optimizer,\n",
    "              metrics=[\"accuracy\"])\n",
    "history = model.fit([X_train, X_train_decoder], Y_train, epochs=15,\n",
    "                    validation_data=([X_valid, X_valid_decoder], Y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4mMGxqhuVUMj"
   },
   "outputs": [],
   "source": [
    "def ids_to_date_strs(ids, chars=OUTPUT_CHARS):\n",
    "    return [\"\".join([(\"?\" + chars)[index] for index in sequence])\n",
    "            for sequence in ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "puqPn1lcVO8l"
   },
   "outputs": [],
   "source": [
    "max_output_length = Y_train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FNlzCqU_Vf_d"
   },
   "outputs": [],
   "source": [
    "max_input_length = X_train.shape[1]\n",
    "\n",
    "def prepare_date_strs_padded(date_strs):\n",
    "    X = prepare_date_strs(date_strs)\n",
    "    if X.shape[1] < max_input_length:\n",
    "        X = tf.pad(X, [[0, 0], [0, max_input_length - X.shape[1]]])\n",
    "    return X\n",
    "\n",
    "def convert_date_strs(date_strs):\n",
    "    X = prepare_date_strs_padded(date_strs)\n",
    "    ids = model.predict_classes(X)\n",
    "    return ids_to_date_strs(ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OiGx7r5XVDdk"
   },
   "outputs": [],
   "source": [
    "sos_id = len(OUTPUT_CHARS) + 1\n",
    "\n",
    "def predict_date_strs(date_strs):\n",
    "    X = prepare_date_strs_padded(date_strs)\n",
    "    Y_pred = tf.fill(dims=(len(X), 1), value=sos_id)\n",
    "    for index in range(max_output_length):\n",
    "        pad_size = max_output_length - Y_pred.shape[1]\n",
    "        X_decoder = tf.pad(Y_pred, [[0, 0], [0, pad_size]])\n",
    "        Y_probas_next = model.predict([X, X_decoder])[:, index:index+1]\n",
    "        Y_pred_next = tf.argmax(Y_probas_next, axis=-1, output_type=tf.int32)\n",
    "        Y_pred = tf.concat([Y_pred, Y_pred_next], axis=1)\n",
    "    return ids_to_date_strs(Y_pred[:, 1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WGv_ZxGCUUEO"
   },
   "outputs": [],
   "source": [
    "predict_date_strs([\"July 14, 1789\", \"May 01, 2020\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ct4uYOyuxJsX"
   },
   "source": [
    "LSTM ver : https://colab.research.google.com/drive/1tpDiv4RtH9Um6StAkUUPbW0ETWv1vPy3?usp=sharing"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "machine_shape": "hm",
   "name": "seq2seq with attention mechanism.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
