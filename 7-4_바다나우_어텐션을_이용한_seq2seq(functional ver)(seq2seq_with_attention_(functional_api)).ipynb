{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Pnw36ndicd8s"
   },
   "source": [
    "어텐션 없는 ver : https://wikidocs.net/86900"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "APZoZX_6ch-x"
   },
   "source": [
    "# 데이터 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3G3OMnjzQ0Gq"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import re\n",
    "import shutil\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import pandas as pd\n",
    "import os\n",
    "import unicodedata\n",
    "import urllib3\n",
    "import zipfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "61SmqT0RRNZQ"
   },
   "outputs": [],
   "source": [
    "http = urllib3.PoolManager()\n",
    "url ='http://www.manythings.org/anki/fra-eng.zip'\n",
    "filename = 'fra-eng.zip'\n",
    "path = os.getcwd()\n",
    "zipfilename = os.path.join(path, filename)\n",
    "with http.request('GET', url, preload_content=False) as r, open(zipfilename, 'wb') as out_file:       \n",
    "    shutil.copyfileobj(r, out_file)\n",
    "\n",
    "with zipfile.ZipFile(zipfilename, 'r') as zip_ref:\n",
    "    zip_ref.extractall(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "418ggzvzcjup"
   },
   "source": [
    "# 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "erUuKm7LRULa"
   },
   "outputs": [],
   "source": [
    "num_samples = 33000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hzrSeiDURUX-"
   },
   "outputs": [],
   "source": [
    "def unicode_to_ascii(s):\n",
    "  return ''.join(c for c in unicodedata.normalize('NFD', s)\n",
    "      if unicodedata.category(c) != 'Mn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JVG9oTmLRVLe"
   },
   "outputs": [],
   "source": [
    "def preprocess_sentence(sent):\n",
    "    # 위에서 구현한 함수를 내부적으로 호출\n",
    "    sent = unicode_to_ascii(sent.lower())\n",
    "\n",
    "    # 단어와 구두점 사이에 공백을 만듭니다.\n",
    "    # Ex) \"he is a boy.\" => \"he is a boy .\"\n",
    "    sent = re.sub(r\"([?.!,¿])\", r\" \\1\", sent)\n",
    "\n",
    "    # (a-z, A-Z, \".\", \"?\", \"!\", \",\") 이들을 제외하고는 전부 공백으로 변환합니다.\n",
    "    sent = re.sub(r\"[^a-zA-Z!.?]+\", r\" \", sent)\n",
    "\n",
    "    sent = re.sub(r\"\\s+\", \" \", sent)\n",
    "    return sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "id": "NaVrT0zWRV4e",
    "outputId": "a686952b-e8fe-46ec-92fc-d0c467e39222"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "have you had dinner ?\n",
      "b'avez vous deja dine ?'\n"
     ]
    }
   ],
   "source": [
    "# 전처리 테스트\n",
    "en_sent = u\"Have you had dinner?\"\n",
    "fr_sent = u\"Avez-vous déjà diné?\"\n",
    "print(preprocess_sentence(en_sent))\n",
    "print(preprocess_sentence(fr_sent).encode('utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IbM5P5tTRWvm"
   },
   "outputs": [],
   "source": [
    "def load_preprocessed_data():\n",
    "    encoder_input, decoder_input, decoder_target = [], [], []\n",
    "\n",
    "    with open(\"fra.txt\", \"r\") as lines:\n",
    "        for i, line in enumerate(lines):\n",
    "\n",
    "            # source 데이터와 target 데이터 분리\n",
    "            src_line, tar_line, _ = line.strip().split('\\t')\n",
    "\n",
    "            # source 데이터 전처리\n",
    "            src_line_input = [w for w in preprocess_sentence(src_line).split()]\n",
    "\n",
    "            # target 데이터 전처리\n",
    "            tar_line = preprocess_sentence(tar_line)\n",
    "            tar_line_input = [w for w in (\"<sos> \" + tar_line).split()]\n",
    "            tar_line_target = [w for w in (tar_line + \" <eos>\").split()]\n",
    "\n",
    "            encoder_input.append(src_line_input)\n",
    "            decoder_input.append(tar_line_input)\n",
    "            decoder_target.append(tar_line_target)\n",
    "\n",
    "            if i == num_samples - 1:\n",
    "                break\n",
    "\n",
    "    return encoder_input, decoder_input, decoder_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 70
    },
    "id": "rkC8bLECRXqW",
    "outputId": "582536a6-6ce0-4113-8049-5e0d305302c7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['go', '.'], ['hi', '.'], ['hi', '.'], ['run', '!'], ['run', '!']]\n",
      "[['<sos>', 'va', '!'], ['<sos>', 'salut', '!'], ['<sos>', 'salut', '.'], ['<sos>', 'cours', '!'], ['<sos>', 'courez', '!']]\n",
      "[['va', '!', '<eos>'], ['salut', '!', '<eos>'], ['salut', '.', '<eos>'], ['cours', '!', '<eos>'], ['courez', '!', '<eos>']]\n"
     ]
    }
   ],
   "source": [
    "sents_en_in, sents_fra_in, sents_fra_out = load_preprocessed_data()\n",
    "print(sents_en_in[:5])\n",
    "print(sents_fra_in[:5])\n",
    "print(sents_fra_out[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D76MkTnkcnnG"
   },
   "source": [
    "# 토큰화, 정수 인코딩, 패딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aJSi7kuoRYeO"
   },
   "outputs": [],
   "source": [
    "tokenizer_en = Tokenizer(filters=\"\", lower=False)\n",
    "tokenizer_en.fit_on_texts(sents_en_in)\n",
    "encoder_input = tokenizer_en.texts_to_sequences(sents_en_in)\n",
    "\n",
    "tokenizer_fra = Tokenizer(filters=\"\", lower=False)\n",
    "tokenizer_fra.fit_on_texts(sents_fra_in)\n",
    "tokenizer_fra.fit_on_texts(sents_fra_out)\n",
    "decoder_input = tokenizer_fra.texts_to_sequences(sents_fra_in)\n",
    "decoder_target = tokenizer_fra.texts_to_sequences(sents_fra_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wAdy3YdTRZPm"
   },
   "outputs": [],
   "source": [
    "encoder_input = pad_sequences(encoder_input, padding=\"post\")\n",
    "decoder_input = pad_sequences(decoder_input, padding=\"post\")\n",
    "decoder_target = pad_sequences(decoder_target, padding=\"post\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "Eb2U-Wl6RZ5-",
    "outputId": "29935656-b4a5-4fcc-e128-c14b0801aee0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "영어 단어 집합의 크기 : 4647, 프랑스어 단어 집합의 크기 : 8022\n"
     ]
    }
   ],
   "source": [
    "src_vocab_size = len(tokenizer_en.word_index) + 1\n",
    "tar_vocab_size = len(tokenizer_fra.word_index) + 1\n",
    "print(\"영어 단어 집합의 크기 : {:d}, 프랑스어 단어 집합의 크기 : {:d}\".format(src_vocab_size, tar_vocab_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vdN1pyeHRay-"
   },
   "outputs": [],
   "source": [
    "src_to_index = tokenizer_en.word_index\n",
    "index_to_src = tokenizer_en.index_word # 훈련 후 결과 비교할 때 사용\n",
    "\n",
    "tar_to_index = tokenizer_fra.word_index # 훈련 후 예측 과정에서 사용\n",
    "index_to_tar = tokenizer_fra.index_word # 훈련 후 결과 비교할 때 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "zar5-SxfRbk-",
    "outputId": "a63fa369-9e4d-4611-ced9-9681787a3f60"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1046 12687 32195 ... 20860  1476 11338]\n"
     ]
    }
   ],
   "source": [
    "indices = np.arange(encoder_input.shape[0])\n",
    "np.random.shuffle(indices)\n",
    "print(indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rTbeweCORcW-"
   },
   "outputs": [],
   "source": [
    "encoder_input = encoder_input[indices]\n",
    "decoder_input = decoder_input[indices]\n",
    "decoder_target = decoder_target[indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "Q_pdtQPQRdPG",
    "outputId": "34508c7e-5899-4bec-d24e-da8a5285fe73"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 77,   3, 361,  33,   0,   0,   0,   0], dtype=int32)"
      ]
     },
     "execution_count": 15,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_input[30997]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "id": "pa1M1uOURd4O",
    "outputId": "32d14052-ddb7-4ad0-f662-edce98468667"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  2,   8, 430,  12,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0], dtype=int32)"
      ]
     },
     "execution_count": 16,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder_input[30997]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "id": "d9WycQpwRel2",
    "outputId": "f7c679ed-ba60-4793-cedc-40b478f51f87"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  8, 430,  12,   3,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0], dtype=int32)"
      ]
     },
     "execution_count": 17,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder_target[30997]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "x4ZfC7tuRfIm",
    "outputId": "1d6ca6c5-6c01-40a3-ffb3-26e1aa43e34a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3300\n"
     ]
    }
   ],
   "source": [
    "n_of_val = int(33000*0.1)\n",
    "print(n_of_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "L9hsZo6FRfr-"
   },
   "outputs": [],
   "source": [
    "encoder_input_train = encoder_input[:-n_of_val]\n",
    "decoder_input_train = decoder_input[:-n_of_val]\n",
    "decoder_target_train = decoder_target[:-n_of_val]\n",
    "\n",
    "encoder_input_test = encoder_input[-n_of_val:]\n",
    "decoder_input_test = decoder_input[-n_of_val:]\n",
    "decoder_target_test = decoder_target[-n_of_val:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 123
    },
    "id": "7jQin9oyRgVY",
    "outputId": "066f9ee4-1051-4ee1-a894-9a7e81e19fdb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(29700, 8)\n",
      "(29700, 16)\n",
      "(29700, 16)\n",
      "(3300, 8)\n",
      "(3300, 16)\n",
      "(3300, 16)\n"
     ]
    }
   ],
   "source": [
    "print(encoder_input_train.shape)\n",
    "print(decoder_input_train.shape)\n",
    "print(decoder_target_train.shape)\n",
    "print(encoder_input_test.shape)\n",
    "print(decoder_input_test.shape)\n",
    "print(decoder_target_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JK9apuOtcpXj"
   },
   "source": [
    "# 모델 설계"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zA2NXpQXRg_3"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input, LSTM, Embedding, Dense, Concatenate\n",
    "from tensorflow.keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KAdyRAHbWl52"
   },
   "outputs": [],
   "source": [
    "latent_dim = 50\n",
    "\n",
    "# 인코더\n",
    "encoder_inputs = Input(shape=(None,))\n",
    "\n",
    "# 인코더의 임베딩 층\n",
    "enc_emb = Embedding(src_vocab_size, latent_dim)(encoder_inputs)\n",
    "\n",
    "# 인코더의 LSTM 1\n",
    "encoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True)\n",
    "encoder_outputs, state_h, state_c = encoder_lstm(enc_emb) # 은닉 상태와 셀 상태를 리턴\n",
    "encoder_states = [state_h, state_c] # 인코더의 은닉 상태와 셀 상태를 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qnmYw4zhRjn-"
   },
   "outputs": [],
   "source": [
    "# 디코더\n",
    "decoder_inputs = Input(shape=(None,))\n",
    "\n",
    "# 디코더의 임베딩 층\n",
    "dec_emb_layer = Embedding(tar_vocab_size, latent_dim)\n",
    "dec_emb = dec_emb_layer(decoder_inputs)\n",
    "\n",
    "# 디코더의 LSTM\n",
    "decoder_lstm = LSTM(latent_dim, return_sequences = True, return_state = True)\n",
    "decoder_outputs, _, _ = decoder_lstm(dec_emb, initial_state = [state_h, state_c])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 443
    },
    "id": "c-ADZUUhXBMS",
    "outputId": "857dc5a7-06cb-40a1-8169-da5354dc9b60"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, None, 50)     232350      input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, None, 50)     401100      input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     [(None, None, 50), ( 20200       embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   [(None, None, 50), ( 20200       embedding_1[0][0]                \n",
      "                                                                 lstm[0][1]                       \n",
      "                                                                 lstm[0][2]                       \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, None, 8022)   409122      lstm_1[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 1,082,972\n",
      "Trainable params: 1,082,972\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 디코더의 출력층\n",
    "decoder_softmax_layer = Dense(tar_vocab_size, activation = 'softmax')\n",
    "decoder_softmax_outputs = decoder_softmax_layer(decoder_outputs) \n",
    "\n",
    "# 모델 정의\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_softmax_outputs)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "52ZswN_ccqv8"
   },
   "source": [
    "# 어텐션 추가 버전"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lMZT4CUPRveu"
   },
   "outputs": [],
   "source": [
    "# 바다나우 어텐션\n",
    "import urllib.request\n",
    "urllib.request.urlretrieve(\"https://raw.githubusercontent.com/thushv89/attention_keras/master/src/layers/attention.py\", filename=\"attention.py\")\n",
    "from attention import AttentionLayer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 570
    },
    "id": "aoE7DnkuRxX-",
    "outputId": "9ddd4a28-ec13-4896-ea13-578cf45f790b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, None, 50)     232350      input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, None, 50)     401100      input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     [(None, None, 50), ( 20200       embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   [(None, None, 50), ( 20200       embedding_1[0][0]                \n",
      "                                                                 lstm[0][1]                       \n",
      "                                                                 lstm[0][2]                       \n",
      "__________________________________________________________________________________________________\n",
      "attention_layer (AttentionLayer ((None, None, 50), ( 5050        lstm[0][0]                       \n",
      "                                                                 lstm_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "concat_layer (Concatenate)      (None, None, 100)    0           lstm_1[0][0]                     \n",
      "                                                                 attention_layer[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, None, 8022)   810222      concat_layer[0][0]               \n",
      "==================================================================================================\n",
      "Total params: 1,489,122\n",
      "Trainable params: 1,489,122\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 어텐션 층(어텐션 함수)\n",
    "attn_layer = AttentionLayer(name='attention_layer')\n",
    "attn_out, attn_states = attn_layer([encoder_outputs, decoder_outputs])\n",
    "\n",
    "# 어텐션의 결과와 디코더의 hidden state들을 연결\n",
    "decoder_concat_input = Concatenate(axis = -1, name='concat_layer')([decoder_outputs, attn_out])\n",
    "\n",
    "# 디코더의 출력층\n",
    "decoder_softmax_layer = Dense(tar_vocab_size, activation='softmax')\n",
    "decoder_softmax_outputs = decoder_softmax_layer(decoder_concat_input)\n",
    "\n",
    "# 모델 정의\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_softmax_outputs)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7PwKqikzSe5f"
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='rmsprop', loss='sparse_categorical_crossentropy', metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "kwVAcObaYOwe",
    "outputId": "a428eab4-fd94-4d17-8fe9-d6452ec67cf9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "233/233 [==============================] - 201s 863ms/step - loss: 2.5988 - acc: 0.6485 - val_loss: 1.7533 - val_acc: 0.7298\n",
      "Epoch 2/50\n",
      "233/233 [==============================] - 204s 877ms/step - loss: 1.6528 - acc: 0.7359 - val_loss: 1.6155 - val_acc: 0.7409\n",
      "Epoch 3/50\n",
      "233/233 [==============================] - 199s 853ms/step - loss: 1.5283 - acc: 0.7491 - val_loss: 1.4900 - val_acc: 0.7571\n",
      "Epoch 4/50\n",
      "233/233 [==============================] - 198s 851ms/step - loss: 1.3968 - acc: 0.7737 - val_loss: 1.3850 - val_acc: 0.7786\n",
      "Epoch 5/50\n",
      "233/233 [==============================] - 203s 869ms/step - loss: 1.2905 - acc: 0.7909 - val_loss: 1.3064 - val_acc: 0.7915\n",
      "Epoch 6/50\n",
      "233/233 [==============================] - 198s 848ms/step - loss: 1.2149 - acc: 0.8020 - val_loss: 1.2380 - val_acc: 0.8029\n",
      "Epoch 7/50\n",
      "233/233 [==============================] - 199s 855ms/step - loss: 1.1591 - acc: 0.8098 - val_loss: 1.1937 - val_acc: 0.8092\n",
      "Epoch 8/50\n",
      "233/233 [==============================] - 204s 874ms/step - loss: 1.1143 - acc: 0.8160 - val_loss: 1.1702 - val_acc: 0.8116\n",
      "Epoch 9/50\n",
      "233/233 [==============================] - 199s 852ms/step - loss: 1.0752 - acc: 0.8211 - val_loss: 1.1366 - val_acc: 0.8158\n",
      "Epoch 10/50\n",
      "233/233 [==============================] - 198s 852ms/step - loss: 1.0391 - acc: 0.8258 - val_loss: 1.1108 - val_acc: 0.8183\n",
      "Epoch 11/50\n",
      "233/233 [==============================] - 204s 874ms/step - loss: 1.0068 - acc: 0.8299 - val_loss: 1.0837 - val_acc: 0.8228\n",
      "Epoch 12/50\n",
      "233/233 [==============================] - 199s 852ms/step - loss: 0.9767 - acc: 0.8338 - val_loss: 1.0613 - val_acc: 0.8260\n",
      "Epoch 13/50\n",
      "233/233 [==============================] - 199s 854ms/step - loss: 0.9486 - acc: 0.8377 - val_loss: 1.0409 - val_acc: 0.8264\n",
      "Epoch 14/50\n",
      "233/233 [==============================] - 203s 873ms/step - loss: 0.9220 - acc: 0.8412 - val_loss: 1.0207 - val_acc: 0.8309\n",
      "Epoch 15/50\n",
      "233/233 [==============================] - 199s 853ms/step - loss: 0.8971 - acc: 0.8444 - val_loss: 1.0063 - val_acc: 0.8330\n",
      "Epoch 16/50\n",
      "233/233 [==============================] - 199s 855ms/step - loss: 0.8738 - acc: 0.8474 - val_loss: 0.9895 - val_acc: 0.8347\n",
      "Epoch 17/50\n",
      "233/233 [==============================] - 199s 853ms/step - loss: 0.8531 - acc: 0.8502 - val_loss: 0.9693 - val_acc: 0.8372\n",
      "Epoch 18/50\n",
      "233/233 [==============================] - 199s 854ms/step - loss: 0.8335 - acc: 0.8529 - val_loss: 0.9575 - val_acc: 0.8380\n",
      "Epoch 19/50\n",
      "233/233 [==============================] - 199s 854ms/step - loss: 0.8156 - acc: 0.8553 - val_loss: 0.9515 - val_acc: 0.8398\n",
      "Epoch 20/50\n",
      "233/233 [==============================] - 199s 856ms/step - loss: 0.7987 - acc: 0.8577 - val_loss: 0.9390 - val_acc: 0.8430\n",
      "Epoch 21/50\n",
      "233/233 [==============================] - 199s 856ms/step - loss: 0.7829 - acc: 0.8601 - val_loss: 0.9328 - val_acc: 0.8435\n",
      "Epoch 22/50\n",
      "233/233 [==============================] - 199s 856ms/step - loss: 0.7682 - acc: 0.8623 - val_loss: 0.9161 - val_acc: 0.8455\n",
      "Epoch 23/50\n",
      "233/233 [==============================] - 199s 855ms/step - loss: 0.7542 - acc: 0.8648 - val_loss: 0.9062 - val_acc: 0.8467\n",
      "Epoch 24/50\n",
      "233/233 [==============================] - 199s 856ms/step - loss: 0.7402 - acc: 0.8667 - val_loss: 0.9057 - val_acc: 0.8466\n",
      "Epoch 25/50\n",
      "233/233 [==============================] - 204s 877ms/step - loss: 0.7272 - acc: 0.8687 - val_loss: 0.8874 - val_acc: 0.8501\n",
      "Epoch 26/50\n",
      "233/233 [==============================] - 200s 858ms/step - loss: 0.7153 - acc: 0.8707 - val_loss: 0.8808 - val_acc: 0.8502\n",
      "Epoch 27/50\n",
      "233/233 [==============================] - 199s 856ms/step - loss: 0.7044 - acc: 0.8729 - val_loss: 0.8866 - val_acc: 0.8497\n",
      "Epoch 28/50\n",
      "233/233 [==============================] - 204s 877ms/step - loss: 0.6944 - acc: 0.8750 - val_loss: 0.8805 - val_acc: 0.8503\n",
      "Epoch 29/50\n",
      "233/233 [==============================] - 199s 853ms/step - loss: 0.6849 - acc: 0.8766 - val_loss: 0.8697 - val_acc: 0.8521\n",
      "Epoch 30/50\n",
      "233/233 [==============================] - 199s 855ms/step - loss: 0.6761 - acc: 0.8782 - val_loss: 0.8770 - val_acc: 0.8504\n",
      "Epoch 31/50\n",
      "233/233 [==============================] - 203s 872ms/step - loss: 0.6673 - acc: 0.8800 - val_loss: 0.8726 - val_acc: 0.8513\n",
      "Epoch 32/50\n",
      "233/233 [==============================] - 198s 849ms/step - loss: 0.6588 - acc: 0.8816 - val_loss: 0.8584 - val_acc: 0.8548\n",
      "Epoch 33/50\n",
      "233/233 [==============================] - 198s 849ms/step - loss: 0.6506 - acc: 0.8834 - val_loss: 0.8532 - val_acc: 0.8553\n",
      "Epoch 34/50\n",
      "233/233 [==============================] - 202s 869ms/step - loss: 0.6427 - acc: 0.8850 - val_loss: 0.8514 - val_acc: 0.8553\n",
      "Epoch 35/50\n",
      "233/233 [==============================] - 199s 853ms/step - loss: 0.6339 - acc: 0.8869 - val_loss: 0.8471 - val_acc: 0.8571\n",
      "Epoch 36/50\n",
      "233/233 [==============================] - 199s 853ms/step - loss: 0.6251 - acc: 0.8881 - val_loss: 0.8398 - val_acc: 0.8574\n",
      "Epoch 37/50\n",
      "233/233 [==============================] - 205s 878ms/step - loss: 0.6169 - acc: 0.8895 - val_loss: 0.8398 - val_acc: 0.8582\n",
      "Epoch 38/50\n",
      "233/233 [==============================] - 198s 852ms/step - loss: 0.6097 - acc: 0.8914 - val_loss: 0.8330 - val_acc: 0.8593\n",
      "Epoch 39/50\n",
      "233/233 [==============================] - 199s 852ms/step - loss: 0.6028 - acc: 0.8927 - val_loss: 0.8326 - val_acc: 0.8594\n",
      "Epoch 40/50\n",
      "233/233 [==============================] - 198s 851ms/step - loss: 0.5966 - acc: 0.8940 - val_loss: 0.8375 - val_acc: 0.8575\n",
      "Epoch 41/50\n",
      "233/233 [==============================] - 198s 850ms/step - loss: 0.5906 - acc: 0.8953 - val_loss: 0.8275 - val_acc: 0.8616\n",
      "Epoch 42/50\n",
      "233/233 [==============================] - 198s 850ms/step - loss: 0.5849 - acc: 0.8963 - val_loss: 0.8255 - val_acc: 0.8606\n",
      "Epoch 43/50\n",
      "233/233 [==============================] - 198s 851ms/step - loss: 0.5793 - acc: 0.8976 - val_loss: 0.8304 - val_acc: 0.8607\n",
      "Epoch 44/50\n",
      "233/233 [==============================] - 198s 851ms/step - loss: 0.5738 - acc: 0.8986 - val_loss: 0.8236 - val_acc: 0.8627\n",
      "Epoch 45/50\n",
      "233/233 [==============================] - 198s 851ms/step - loss: 0.5684 - acc: 0.8996 - val_loss: 0.8220 - val_acc: 0.8619\n",
      "Epoch 46/50\n",
      "233/233 [==============================] - 198s 850ms/step - loss: 0.5635 - acc: 0.9007 - val_loss: 0.8186 - val_acc: 0.8629\n",
      "Epoch 47/50\n",
      "233/233 [==============================] - 198s 850ms/step - loss: 0.5589 - acc: 0.9017 - val_loss: 0.8285 - val_acc: 0.8613\n",
      "Epoch 48/50\n",
      "233/233 [==============================] - 198s 850ms/step - loss: 0.5542 - acc: 0.9027 - val_loss: 0.8134 - val_acc: 0.8635\n",
      "Epoch 49/50\n",
      "233/233 [==============================] - 198s 852ms/step - loss: 0.5493 - acc: 0.9038 - val_loss: 0.8205 - val_acc: 0.8619\n",
      "Epoch 50/50\n",
      "233/233 [==============================] - 199s 853ms/step - loss: 0.5446 - acc: 0.9046 - val_loss: 0.8187 - val_acc: 0.8624\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fa56c247b70>"
      ]
     },
     "execution_count": 28,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x=[encoder_input_train, decoder_input_train], y=decoder_target_train, \\\n",
    "          validation_data = ([encoder_input_test, decoder_input_test], decoder_target_test),\n",
    "          batch_size=128, epochs=50)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "machine_shape": "hm",
   "name": "Learning Spoons 7강 seq2seq with attention (functional api).ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
