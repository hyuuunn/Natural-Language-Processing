{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WRvYAI5bn4dF"
   },
   "source": [
    "# 데이터 로드\n",
    "데이터 로드는 tensorflow 2에서 제공하는 tf.data.dataset 형식으로 로드. dataset 형식으로 데이터를 불러오면, 향후 모델을 훈련시킬 때 @tf.function 데코레이터를 활용하여 상당히 빠르게 학습할 수 있음."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "C42H5OZMmJL1"
   },
   "outputs": [],
   "source": [
    "# 포르투갈어-프랑스어 데이터 로드를 위한 임포트\n",
    "!pip install -q tf-nightly\n",
    "import tensorflow_datasets as tfds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hFNmJRi0YQ26"
   },
   "outputs": [],
   "source": [
    "# 분석에 필요한 모듈 임포트\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cv7qcd-GmMNY"
   },
   "outputs": [],
   "source": [
    "# 데이터 불러오기\n",
    "examples, metadata = tfds.load('ted_hrlr_translate/pt_to_en', with_info=True,\n",
    "                               as_supervised=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 73
    },
    "id": "XLUAtajEmkBN",
    "outputId": "e7a18d36-a687-4ce4-a6ee-223a5fe4a434"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'test': <DatasetV1Adapter shapes: ((), ()), types: (tf.string, tf.string)>,\n",
       " 'train': <DatasetV1Adapter shapes: ((), ()), types: (tf.string, tf.string)>,\n",
       " 'validation': <DatasetV1Adapter shapes: ((), ()), types: (tf.string, tf.string)>}"
      ]
     },
     "execution_count": 4,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 데이터가 test, train, validation에 있음\n",
    "# 이 데이터들의 형식은 tf.data.dataset 오브젝트\n",
    "examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "id": "_sP_h17ApCwY",
    "outputId": "76e8a857-8b74-4ba2-c456-e22b762dff98"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensorflow.python.data.ops.dataset_ops.DatasetV1Adapter"
      ]
     },
     "execution_count": 5,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(examples['train'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1YoSV2XmmSs2"
   },
   "outputs": [],
   "source": [
    "# train, validation, test 데이터로 나누기\n",
    "train_examples, val_examples, test_examples = examples['train'], examples['validation'], examples['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RHE5JQ1hs9rs"
   },
   "outputs": [],
   "source": [
    "# train_example 에는 포르투갈어 pt, 영어 en이 있음\n",
    "# 여기서 단어를 추출해서, 단어들마다 인덱싱을 부여할 것임\n",
    "# 인덱싱을 부여하는 클래스가 tokenizer_en(영어 인덱싱 부여), tokenizer_pt(포르투갈어 인덱싱 부여)\n",
    "tokenizer_en = tfds.features.text.SubwordTextEncoder.build_from_corpus(\n",
    "    (en.numpy() for pt, en in train_examples), target_vocab_size=2**13)\n",
    "\n",
    "tokenizer_pt = tfds.features.text.SubwordTextEncoder.build_from_corpus(\n",
    "    (pt.numpy() for pt, en in train_examples), target_vocab_size=2**13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "id": "VOGyn1FCqLXF",
    "outputId": "403ce195-5c76-4e5c-cfcf-e3d28c540800"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[7903, 2429, 439, 406, 7345, 7907, 1283, 7870, 9, 527, 6514, 7945, 7864]"
      ]
     },
     "execution_count": 8,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 영어를 인코딩\n",
    "tokenizer_en.encode(\"Hello man, Let's run transformer!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "id": "ZhMCauShqWkx",
    "outputId": "d65fe61b-c683-4347-d4ca-cd21a1c720c3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[141, 77, 33, 1566, 873, 4501, 217, 642, 4, 217, 101, 1073, 4824, 17, 5, 488, 200, 8004]\n"
     ]
    }
   ],
   "source": [
    "# 포르투갈어를 인코딩\n",
    "print(tokenizer_pt.encode(\"vou então muito rapidamente partilhar convosco algumas histórias de algumas coisas mágicas que aconteceram.\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uFmp4-h1tA20"
   },
   "outputs": [],
   "source": [
    "def encode(lang1, lang2):\n",
    "  \n",
    "  lang1 = [tokenizer_pt.vocab_size] + tokenizer_pt.encode(\n",
    "      lang1.numpy()) + [tokenizer_pt.vocab_size+1] # 포르투갈 어를 인코딩 할 때 시작 단어를 의미하는 숫자와, 끝 단어를 의미하는 숫자가 붙음\n",
    "\n",
    "  lang2 = [tokenizer_en.vocab_size] + tokenizer_en.encode(\n",
    "      lang2.numpy()) + [tokenizer_en.vocab_size+1] # 영어도 마찬가지임\n",
    "  return lang1, lang2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "34DVDfJ0sR6y"
   },
   "outputs": [],
   "source": [
    "lang1 = tf.constant(\"vou então muito rapidamente partilhar convosco algumas histórias de algumas coisas mágicas que aconteceram.\", dtype=tf.string)\n",
    "lang2 = tf.constant(\"Hello man, Let's run transformer!\", dtype=tf.string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 56
    },
    "id": "Nlm39twMrCKb",
    "outputId": "258b3a10-80a3-4409-ea59-f3741fa2b144"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "([8214, 141, 77, 33, 1566, 873, 4501, 217, 642, 4, 217, 101, 1073, 4824, 17, 5, 488, 200, 8004, 8215], [8087, 7903, 2429, 439, 406, 7345, 7907, 1283, 7870, 9, 527, 6514, 7945, 7864, 8088])\n"
     ]
    }
   ],
   "source": [
    "print(encode(lang1, lang2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EXgdTB2ftDov"
   },
   "outputs": [],
   "source": [
    "# tf.py_function을 활용하여 모든 문장에 숫자를 부여함\n",
    "\n",
    "def tf_encode(pt, en):\n",
    "  result_pt, result_en = tf.py_function(encode, [pt, en], [tf.int64, tf.int64]) # 인풋 값으로 pt와 en이 한문장 한문장씩 들어가서 result_pt, result_en을 아웃풋으로 내게 됨\n",
    "  result_pt.set_shape([None])\n",
    "  result_en.set_shape([None])\n",
    "  return result_pt, result_en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Z9kC4H11tFH0"
   },
   "outputs": [],
   "source": [
    "MAX_LENGTH = 40\n",
    "BUFFER_SIZE = 60000\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "# 전체 데이터에서 x가 포르투갈어 한 문장, y가 영어 한 문장인데\n",
    "# 만약 문장이 인코딩 되었을 때, 인코딩 된 길이가 40을 초과하면 데이터에서 배제하고자 하는 필터 함수임\n",
    "def filter_max_length(x, y, max_length=MAX_LENGTH):\n",
    "  return tf.logical_and(tf.size(x) <= max_length,\n",
    "                        tf.size(y) <= max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "V83U1EEQtGA-"
   },
   "outputs": [],
   "source": [
    "train_dataset = train_examples.map(tf_encode) # tf_encode 함수를 활용해서 포르투갈어, 영어 각 문장에 시작 토큰과 끝 토큰을 부여함\n",
    "train_dataset = train_dataset.filter(filter_max_length) # 문장의 길이가 40이 넘는 문장은 배제하고자 함\n",
    "# cache the dataset to memory to get a speedup while reading from it.\n",
    "train_dataset = train_dataset.cache() # cache를 활용해서 데이터를 로드할 때 빠른 처리를 기대해 봄\n",
    "train_dataset = train_dataset.shuffle(BUFFER_SIZE).padded_batch(BATCH_SIZE) \n",
    "# shuffle(60000) 인데, 이 말은 전체 데이터를 완전히 섞겠다는 뜻임\n",
    "# 전체 데이터의 수가 50000인데 50000보다 큰 숫자를 입력하면 완전하게 전체 데이터를 섞는 것이며\n",
    "# 전체 데이터 수보다 작은 수를 입력하면 전체 데이터에서 일부만 섞음\n",
    "# padded_batch는 무엇이냐면, 이번 데이터셋은 문장마다 길이가 모두 다르기에\n",
    "# 배치 사이즈(32) 만큼의 문장을 뽑을 때마다\n",
    "# 배치 사이즈에 해당하는 만큼의 문장의 길이는 일정하게 유지됨\n",
    "# 무슨 말이냐면 배치가 2개라면  이 중 하나의 문장의 길이는 37이 될 수 있고\n",
    "# 두 개의 배치(32) 중 하나의 배치는 문장의 길이를 37개로 모두 유지\n",
    "# 그 다음 배치에서 문장의 길이가 39 라면, 그 배치에서는 문장의 길이를 39로 유지\n",
    "                                                                            \n",
    "train_dataset = train_dataset.prefetch(tf.data.experimental.AUTOTUNE) # 데이터 로드와 처리의 시간을 overlap하여 속도 향상\n",
    "\n",
    "val_dataset = val_examples.map(tf_encode)\n",
    "val_dataset = val_dataset.filter(filter_max_length).padded_batch(BATCH_SIZE) #가변길이의 배치를 돌릴때 꼭 쓰자"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6Wxi5ftvtRNr"
   },
   "source": [
    "#트랜스포머 구조\n",
    "![Imgur](https://i.imgur.com/Tl2zsFL.png)\n",
    "트랜스포머 트랜스포머의 구조는 1. (위치 + 단어 임베딩) -> 2, 인코더 3. 디코더로 나뉨.  \n",
    "먼저 임베딩부터 ->\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bkpvhCMnsVAm"
   },
   "source": [
    "#임베딩 파트 정의\n",
    "트랜스포머는 단어 임베딩 + 위치 임베딩, 두 가지 임베딩을 거치게 되며  \n",
    "단어 임베딩은 많이 해봤기 때문에, 위치 임베딩만 살펴봄.  \n",
    "**위치 임베딩을 하는 이유는 RNN 계열 같이 문장 내부 단어의 순서를 나타낼 방법이 없기 때문.**  \n",
    "같은 단어라도 위치 임베딩 때문에 순서에 따라서 단어가 임베딩 된 것은 다를 수 있음.  \n",
    "![Imgur](https://i.imgur.com/sSnVRpY.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bZzxZS6Eym3W"
   },
   "source": [
    "![Imgur](https://i.imgur.com/SNIEhlA.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "v5cFMcfBymSE"
   },
   "outputs": [],
   "source": [
    "# 먼저 포지셔널 임베딩부터\n",
    "# pos / 10000 ** (2i / d_model)에 해당하는 부분을\n",
    "# get_angles 함수로 출력하기\n",
    "\n",
    "def get_angles(pos, i, d_model):\n",
    "  angle_rates = 1 / np.power(10000, (2 * (i // 2) / np.float32(d_model)))\n",
    "    # shape = (1, d_model)\n",
    "  return np.matmul(pos, angle_rates) # pos shape : (pos, 1), angle_rates shape = (1, d_model),\n",
    "                                     # np.matmul(pos, angle_rates) shape : 행렬곱 (pos,1), (1, d_model) = (pos, d_model)\n",
    "\n",
    "def positional_encoding(position, d_model):\n",
    "  angle_rads = get_angles(np.arange(position)[:, np.newaxis],\n",
    "                          np.arange(d_model)[np.newaxis, :],\n",
    "                          d_model) # shape : (position, d_model)\n",
    "  # 오른쪽으로 짝수번째 인덱스는 sin 함수를 적용\n",
    "  angle_rads[:, 0::2] = np.sin(angle_rads[:, 0::2])\n",
    "  # 오른쪽으로 홀수번째 인덱스는 cos 함수를 적용\n",
    "  angle_rads[:, 1::2] = np.cos(angle_rads[:, 1::2])\n",
    "\n",
    "  pos_encoding = angle_rads[np.newaxis, ...] # pos_encoding shape : (1, position, d_model)\n",
    "                                             # 왜 shape에 1을 추가해주냐면, batch_size 만큼 학습하기 위함임\n",
    "\n",
    "  return tf.cast(pos_encoding, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 301
    },
    "id": "va41MjAM-67o",
    "outputId": "43f0c0c2-0f5e-4f7a-f9d0-1fceb885ed9f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 50, 512)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pos_encoding = positional_encoding(50, 512)\n",
    "print(pos_encoding.shape)\n",
    "\n",
    "plt.pcolormesh(pos_encoding[0], cmap='RdBu')\n",
    "plt.xlabel(\"Depth\")\n",
    "plt.xlim((0, 512))\n",
    "plt.ylabel(\"Position\")\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aNQHsYO9-qD6"
   },
   "source": [
    "단어 임베딩 + 포지셔널 임베딩 클래스 구현  \n",
    "주의할 점은 포지셔널 단어임베딩 * sqrt(임베딩 차원), 즉 루트가 곱해져야함  \n",
    "위치 임베딩은 단순히 위치만 나타내기 때문에, 가중치가 단어 임베딩보단 적어야 신경망이 잘 학습됨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Mg5gN7cEr8m2"
   },
   "outputs": [],
   "source": [
    "class TransformerEmbedding(tf.keras.layers.Layer):\n",
    "  def __init__(self, d_model, input_vocab_size, maximum_position_encoding, dropout_rate=0.1):\n",
    "    super().__init__()\n",
    "\n",
    "    self.d_model = d_model # 하나의 단어가 d_model의 차원으로 인코딩 됨\n",
    "    self.embedding = tf.keras.layers.Embedding(input_vocab_size, d_model)\n",
    "     # vocab_size는 tokenizer 내부 vocab.txt의 사이즈\n",
    "    self.pos_encoding = positional_encoding(maximum_position_encoding, self.d_model) # 포지셔널 인코딩\n",
    "    self.dropout = tf.keras.layers.Dropout(dropout_rate) # 드롭아웃 설정\n",
    "    \n",
    "\n",
    "  def call(self, x, training):\n",
    "    # 최초 x의 shape = (batch_size, seq_len)\n",
    "    seq_len = tf.shape(x)[1]\n",
    "    out = self.embedding(x) # shape : (batch_size, input_seq_len, d_model)\n",
    "    out = out * tf.math.sqrt(tf.cast(self.d_model, tf.float32)) # x에 sqrt(d_model) 만큼을 곱해주냐면, 임베딩 벡터보다 포지셔널 인코딩 임베딩 벡터의 영향력을 줄이기 위해서임\n",
    "                                                            # 포지셔널 인코딩은 순서만을 의미하기 때문에 임베딩 벡터보다 영향력이 적어야 이치에 맞음\n",
    "    out = out + self.pos_encoding[:,:seq_len,:]\n",
    "    out = self.dropout(out, training=training)\n",
    "    \n",
    "\n",
    "    return out # shape : (batch_size, input_seq_len, d_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 277
    },
    "id": "SyuUIfwj9nuo",
    "outputId": "598d0925-c1ce-46f5-d970-aa28e7efdf56"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[-0.17745727  0.26979643 -0.9621703  ...  1.1329346  -1.1245527\n",
      "    0.86097157]\n",
      "  [ 0.6640137  -0.18990129 -0.1403141  ...  1.1329346  -1.124449\n",
      "    0.86097157]\n",
      "  [ 0.73184013 -1.1463504  -0.02575558 ...  1.1329346  -1.1243454\n",
      "    0.86097157]\n",
      "  ...\n",
      "  [-0.8209954   0.03521049 -1.8686879  ...  1.1329266  -1.1207172\n",
      "    0.8609642 ]\n",
      "  [ 0.1189113   0.22487009 -1.8255702  ...  1.1329262  -1.1206136\n",
      "    0.8609638 ]\n",
      "  [ 0.7863381  -0.46356064 -1.039402   ...  1.1329257  -1.1205099\n",
      "    0.86096334]]], shape=(1, 40, 512), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "x = np.float32(np.random.uniform(size=(1,40))) # 문장 길이 40\n",
    "Embedder = TransformerEmbedding(512, tokenizer_en.vocab_size+2, 10000)\n",
    "embedded = Embedder(x, False)\n",
    "print(embedded) # 문장이 위치 임베딩 + 포지션 임베딩"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QFL_iOsYBpYu"
   },
   "source": [
    "# 스케일드 닷 프로덕트 어텐션\n",
    "문장이 셀프 어텐션 되어서 어텐션 값과, 소프트맥스 함수를 출력하는 함수를 만들고자 함. scaled라는 의미는, 루트(단어의 차원 512)만큼 어텐션 값에서 나눠져 스케일링이 되기 때문에 스케일드 닷 프로덕트 어텐션이라는 이름이 붙여진 것.  \n",
    "![Imgur](https://i.imgur.com/9fmQJl9.png)  \n",
    "mask를 True로 설정하면 소프트맥스 아웃풋에서, 마스크 된 부분은 0으로 바뀌게 됨. 왜냐면 -1e9는 상당히 큰 값인데, e^(-1e9)는 0에 수렴하기 때문.  \n",
    "왜 트랜스포머에 마스크가 들어가는지?   \n",
    "**1) 인풋의 길이를 신경망 학습을 위해 일정한 길이로 맞추다 보면, 원래 문장의 길이를 초과하는 만큼은 패딩이 됨. 그 패딩한 부분을 어텐션 연산에 참여시키지 않기 위해 마스크를 사용하는 것.**  \n",
    "\n",
    "**2) Seq2Seq같은 기계 번역을 할 때에는 인코딩 부분과 단어 일부로 다음 단어를 예측하기 때문에, 단어 전체를 훈련하지 않고 일부분만 훈련하는 것이 논리에 맞음. 따라서 mask로 훈련에 필요하지 않은 부분은 0으로 바꿔주게 됨.**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n8II3gNaw1K_"
   },
   "source": [
    "문장들이 임베딩되면 인풋의 차원은 (batch_size, seq_len, d_model).  \n",
    "scaled_dot_product_attention 이후의 차원 또한 (batch_size, seq_len, d_model).  \n",
    "**즉 인풋과 아웃풋의 사이즈가 동일하게 됨.**  \n",
    "\n",
    "따라서 scaled_dot_product_attention의 결과는 단어들 간의 연관성을 학습한다고 이해."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "s-NM-LwEA9FI"
   },
   "outputs": [],
   "source": [
    "def scaled_dot_product_attention(q, k, v, mask=None):\n",
    "  # q shape : (batch_size, seq_len, d_model)\n",
    "  # k shape : (batch_size, seq_len, d_model)\n",
    "  # v shape : (batch_size, seq_len, d_model)\n",
    "  matmul_qk = tf.matmul(q, k, transpose_b = True)\n",
    "  #matmul_qk shape : (batch_size, seq_len, seq_len)                                                \n",
    "\n",
    "  dk = tf.cast(tf.shape(k)[-1], tf.float32)\n",
    "  scaled_attention_logits = matmul_qk / tf.math.sqrt(dk)\n",
    "\n",
    "  # scaled_attetion_logits shape : (batch_size, seq_len, seq_len)\n",
    "\n",
    "  if mask is not None:\n",
    "    scaled_attention_logits = scaled_attention_logits + (mask * -1e9)\n",
    "\n",
    "  softmax = tf.nn.softmax(scaled_attention_logits, axis=-1)\n",
    "\n",
    "  # softmax shape : (batch_size, seq_len, seq_len)\n",
    "\n",
    "  output = tf.matmul(softmax, v)\n",
    "\n",
    "  # output(attention_value) shape : (batch_size, seq_len, d_model)\n",
    "  # 즉 처음 입력 차원인 (batch_size, seq_len, d_model) 차원을 아웃풋으로 반환\n",
    "\n",
    "  return output, softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 203
    },
    "id": "9hEWUwCDLXTj",
    "outputId": "5ed21b8b-ab56-4c28-bac4-8a5942d47bc7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(1, 2, 512), dtype=float32, numpy=\n",
       " array([[[0.528983  , 0.5382048 , 0.446203  , ..., 0.58219373,\n",
       "          0.5348408 , 0.56183285],\n",
       "         [0.5456945 , 0.5419768 , 0.44791713, ..., 0.57854795,\n",
       "          0.53305835, 0.5426146 ]]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 2, 7), dtype=float32, numpy=\n",
       " array([[[0.15128171, 0.14701891, 0.13162418, 0.13860199, 0.12562224,\n",
       "          0.1450954 , 0.1607556 ],\n",
       "         [0.13173147, 0.15917505, 0.13395226, 0.13770014, 0.14265053,\n",
       "          0.1654794 , 0.12931111]]], dtype=float32)>)"
      ]
     },
     "execution_count": 22,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q = tf.cast(np.random.uniform(size=(1,2,512)), dtype=tf.float32)\n",
    "k = tf.cast(np.random.uniform(size=(1,7,512)), dtype=tf.float32)\n",
    "v = tf.cast(np.random.uniform(size=(1,7,512)), dtype=tf.float32)\n",
    "scaled_dot_product_attention(q,k,v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9SBCCD7ixP_u"
   },
   "source": [
    "# 멀티 헤드 어텐션 정의\n",
    "멀티 헤드 어텐션은 전체 어텐션을 분리하여 병렬적으로 어텐션을 수행하는 기법.  \n",
    "즉 (batch_size, 50, 64*8) 의 텐서가 있다면 이것을 (batch_size, 50, 64) 의 8개의 텐서로 나눈다음에 개별적으로 어텐션을 수행하고, 다시 (batch_size, 50, 64*8)의 텐서로 concat(합치는) 하게 됨.  \n",
    "이렇게 하는 이유는, 깊은 차원을 한번에 어텐션을 수행하는 것보다, 병렬로 각각 수행하는 것이 더 심도있는 언어들간의 관계를 학습할 수 있기 때문."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sCnRYvoWGoj1"
   },
   "outputs": [],
   "source": [
    "class MultiHeadAttention(tf.keras.layers.Layer):\n",
    "  def __init__(self, d_model, num_heads):\n",
    "    super().__init__()\n",
    "    self.num_heads = num_heads\n",
    "    self.d_model = d_model\n",
    "\n",
    "    assert d_model % self.num_heads == 0\n",
    "\n",
    "    self.depth = d_model // self.num_heads\n",
    "\n",
    "    self.wq = tf.keras.layers.Dense(d_model)\n",
    "    self.wk = tf.keras.layers.Dense(d_model)\n",
    "    self.wv = tf.keras.layers.Dense(d_model)\n",
    "\n",
    "    self.dense = tf.keras.layers.Dense(d_model)\n",
    "\n",
    "  def split_heads(self, x, batch_size):\n",
    "    x = tf.reshape(x, (batch_size, -1, self.num_heads, self.depth))\n",
    "    return tf.transpose(x, perm=[0,2,1,3])\n",
    "\n",
    "  def call(self, v, k, q, mask):\n",
    "    batch_size = tf.shape(q)[0]\n",
    "\n",
    "    q = self.wq(q)\n",
    "    k = self.wk(k)\n",
    "    v = self.wv(v)\n",
    "\n",
    "    q = self.split_heads(q, batch_size)\n",
    "    k = self.split_heads(k, batch_size)\n",
    "    v = self.split_heads(v, batch_size)\n",
    "\n",
    "\n",
    "    attention_weights, softmax = scaled_dot_product_attention(q, k, v, mask)\n",
    "\n",
    "    scaled_attention = tf.transpose(attention_weights, perm=[0,2,1,3])\n",
    "\n",
    "    concat_attention = tf.reshape(scaled_attention, (batch_size, -1, self.d_model))\n",
    "\n",
    "    output = self.dense(concat_attention)\n",
    "\n",
    "    return output, softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 110
    },
    "id": "3OM-vtx-VJXw",
    "outputId": "7551fbe5-9949-4e48-a6cc-c08f967df0da"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[-0.31026363  0.85829777 -0.55492616 ... -0.06981528  0.47073826\n",
      "   -0.42894214]\n",
      "  [-0.30631518  0.8601597  -0.56767696 ... -0.06277549  0.45563567\n",
      "   -0.44153762]]], shape=(1, 2, 512), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "q = tf.cast(np.random.uniform(size=(1,2,512)), dtype=tf.float32)\n",
    "k = tf.cast(np.random.uniform(size=(1,7,512)), dtype=tf.float32)\n",
    "v = tf.cast(np.random.uniform(size=(1,7,512)), dtype=tf.float32)\n",
    "temp_mha = MultiHeadAttention(512, 8)\n",
    "encoder_output, _ = temp_mha(v,k,q, mask=None)\n",
    "print(encoder_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bsbTtqHi3vTN"
   },
   "source": [
    "# 포인트와이즈 피드 포워드 네트워크 정의\n",
    "Pointwise Feed Forward 네트워크에서는 인코더의 출력에서 512개의 차원이 2048차원까지 확장되고,  \n",
    "다시 512개의 차원으로 압축됨."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZeXomoz44N5s"
   },
   "outputs": [],
   "source": [
    "class Pointwise_FeedForward_Network(tf.keras.layers.Layer):\n",
    "  def __init__(self, d_model, dff):\n",
    "    super().__init__()\n",
    "    self.d_model = d_model\n",
    "    self.dff = dff\n",
    "\n",
    "    self.middle = tf.keras.layers.Dense(dff, activation='relu')\n",
    "    self.out = tf.keras.layers.Dense(d_model)\n",
    "\n",
    "  def call(self, x):\n",
    "    middle = self.middle(x) # middle shape : (batch_size, seq_len, dff)\n",
    "    out = self.out(middle) # out shape : (batch_size, seq_len, d_model)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 110
    },
    "id": "xqtcgn2x6YkB",
    "outputId": "358a3f24-6b0f-492b-af58-d6a51e54129b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 2, 512), dtype=float32, numpy=\n",
       "array([[[ 0.08143914,  0.21229027,  0.14004783, ..., -0.54702425,\n",
       "         -0.06841414, -0.2699497 ],\n",
       "        [ 0.09557277,  0.21649924,  0.13990189, ..., -0.5435008 ,\n",
       "         -0.07319072, -0.27843332]]], dtype=float32)>"
      ]
     },
     "execution_count": 26,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_PFFN = Pointwise_FeedForward_Network(512, 2048)\n",
    "sample_PFFN(encoder_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jbkyN8bq7EYT"
   },
   "source": [
    "# 인코더, 디코더 정의\n",
    "지금까지 임베딩 -> 멀티 헤드 어텐션 -> 포인트와이즈 피드 포워드 네트워크까지 살펴봄.  \n",
    "트랜스포머에서의 인코딩은 (멀티헤드어텐션 + 포인트와이즈 피드 포워드 네트워크)를 층층이 쌓은 것. 따라서 방금 공부했던 멀티헤드 어텐션과 포인트와이즈 피드 포워드 네트워크를 겹겹이 쌓아서, 인코더층을 쌓는 것.  \n",
    "\n",
    "인코더 레이어를 정의해서 멀티헤드 어텐션과 포인트와이즈 피드 포워드 네트워크를 합쳐 보기. \n",
    "\n",
    "단어 임베딩 벡터(단어 임베딩+위치 임베딩)가 -> 1. 멀티헤드어텐션  -> 2. Residual Network를 거쳐 원래 input과 멀티헤드어텐션의 합이 출력 -> 3. 포인트와이즈 피드포워드 네트워크 를 거치고, -> 4. Residual Network를 거쳐서 원래의 인풋과 포인트와이즈 피드포워드 네트워크의 합이 출력됨  \n",
    "![Imgur](https://i.imgur.com/w4n19Rs.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SAf18XXu6kB3"
   },
   "outputs": [],
   "source": [
    "class EncoderLayer(tf.keras.layers.Layer):\n",
    "  def __init__(self, d_model, num_heads, dff, rate=0.1):\n",
    "    super().__init__()\n",
    "    self.mha = MultiHeadAttention(d_model, num_heads)\n",
    "    self.ffn = Pointwise_FeedForward_Network(d_model, dff)\n",
    "\n",
    "    self.dropout1 = tf.keras.layers.Dropout(rate)\n",
    "    self.dropout2 = tf.keras.layers.Dropout(rate)\n",
    "    \n",
    "    self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "    self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "\n",
    "  def call(self, x, training, mask=None):\n",
    "    # x : 위치 임베딩 + 단어 임베딩 된 인코딩의 인풋\n",
    "    attn_output, _ = self.mha(x, x, x, mask) \n",
    "    # 멀티헤드 어텐션\n",
    "    # attn_output shape : (batch_size, input_seq_len, d_model)\n",
    "\n",
    "    attn_output = self.dropout1(attn_output, training=training)\n",
    "\n",
    "    out1 = self.layernorm1(x + attn_output) # Residual Network 거침, 레이어 노멀레이제이션을 통한 값 평준화\n",
    "\n",
    "    ffn_output = self.ffn(out1) # ffn_output_shape : (batch_size, input_seq_len, d_model), 포인트와이즈 피드포워드 네트워크\n",
    "    ffn_output = self.dropout2(ffn_output, training=training)\n",
    "\n",
    "    out2 = self.layernorm2(out1 + ffn_output)   # Residual Network 거침\n",
    "                                                # out2 shape : (batch_size, input_seq_len, d_model)\n",
    "\n",
    "    return out2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 555
    },
    "id": "O7omwGh--4fv",
    "outputId": "cd77a398-6c1e-42af-c1e2-026675829ede"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[-1.062428    1.848176    0.29866648 ... -0.10534775  0.01475797\n",
      "    1.3331335 ]\n",
      "  [-0.22095704  1.3884783   1.1205227  ... -0.10534775  0.01486163\n",
      "    1.3331335 ]\n",
      "  [-0.15313059  0.43202922  1.2350812  ... -0.10534775  0.0149653\n",
      "    1.3331335 ]\n",
      "  ...\n",
      "  [-1.7059661   1.6135901  -0.60785115 ... -0.10535568  0.0185935\n",
      "    1.3331262 ]\n",
      "  [-0.7660594   1.8032497  -0.56473345 ... -0.1053561   0.01869717\n",
      "    1.3331257 ]\n",
      "  [-0.09863263  1.114819    0.2214348  ... -0.10535651  0.01880083\n",
      "    1.3331254 ]]], shape=(1, 40, 512), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[[-0.89588743  2.5474074   0.41721514 ... -1.5990319   0.62943566\n",
      "    0.7460321 ]\n",
      "  [-0.32145768  2.294458    0.9872557  ... -1.6359459   0.647713\n",
      "    0.6469191 ]\n",
      "  [-0.17449485  1.5995928   1.0862168  ... -1.5915033   0.6544112\n",
      "    0.5807754 ]\n",
      "  ...\n",
      "  [-0.85940653  2.473055    0.17831305 ... -1.5553817   0.7807983\n",
      "    0.8528498 ]\n",
      "  [-0.19838409  2.550714    0.22447349 ... -1.419519    0.75573003\n",
      "    0.8477317 ]\n",
      "  [ 0.30394316  2.014494    0.7383778  ... -1.3022925   0.7012485\n",
      "    0.8249162 ]]], shape=(1, 40, 512), dtype=float32)\n",
      "Encoded 차원 : (1, 40, 512)\n"
     ]
    }
   ],
   "source": [
    "# 임베딩\n",
    "x = np.float32(np.random.uniform(size=(1,40))) # 문장 길이 40\n",
    "Embedder = TransformerEmbedding(512, tokenizer_en.vocab_size+2, 10000)\n",
    "embedded = Embedder(x, False)\n",
    "print(embedded) # 문장이 위치 임베딩 + 포지션 임베딩\n",
    "#인코더\n",
    "sample_encoder = EncoderLayer(d_model=512, num_heads=8, dff=2048, rate=0.1)\n",
    "sample_encoding = sample_encoder(embedded, training=None, mask=None)\n",
    "print(sample_encoding)\n",
    "#최종출력\n",
    "print(\"Encoded 차원 :\", sample_encoding.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F76815Y-BDZ8"
   },
   "source": [
    "디코더를 정의.  \n",
    "![Imgur](https://i.imgur.com/kGTfPr8.png)\n",
    "\n",
    "디코더는 인코더랑 유사하지만, 구조가 약간 다름. \n",
    "이번 Seq2Seq는 포르투갈어를 영어로 바꾸는 문제.  디코더에서는 \n",
    "두단계의 멀티 헤드 어텐션 구조를 거치는데, **첫번째 멀티 헤드 어텐션은**, **영어문장과 영어문장의 셀프 어텐션을 하여**, 영어 문장간의 관계를 배우게 됨.  \n",
    "두번째 멀티 헤드 어텐션은 **포르투갈어가 인코딩 된 것과**, **영어 문장간의 셀프** **어텐션된 결과를 다시 어텐션 해서 포르투갈 어와 영어의 관계를 학습하게 됨.**  \n",
    "\n",
    "포르투갈어가 암호화된 것과, 영어 문장 한단어 한단어를 보면서 다음 단어를 예측하게 되기 때문에, look_ahead_mask를 사용하게 됨.  \n",
    "만약 영어 문장이 (I love you) 로 이루어져 있다면, look_ahead_mask를 사용하면,  \n",
    "(I, 0, 0) -> Love 예측, (I love, 0) -> You 예측, (I love you) -> 단어의 끝인 [SEP] 예측을 함.   \n",
    "**즉 look_ahead_mask는 다음 단어를 예측할 때, 전에 있던 단어만으로 예측할수 있도록 앞에 있는 단어는 가리는 것.**\n",
    "  \n",
    "  이러한 역할을 가능하게 하는 mask가 look_ahead_mask."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TxwEGGzZ30eh"
   },
   "source": [
    "look_ahead_mask 알아보기.**(매우 중요)**  \n",
    "참고로 패딩은 1로 함. 왜냐하면 어텐션 부분에서 mask * (-1e9)를 하는데, 패딩이 1이어야 -1e9가 곱해져서 상당히 음수로 큰 수가 되는 것이고, 이게 소프트 맥스에 들어가면 0이 되기 때문.(지수함수라 지수함수에 -음수는 0으로 수렴)  \n",
    "![Imgur](https://i.imgur.com/eLAlzji.png)  \n",
    "![Imgur](https://i.imgur.com/gAVenk0.png)  \n",
    "![Imgur](https://i.imgur.com/hsZ6dGs.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 221
    },
    "id": "PGtYNoL23oIR",
    "outputId": "338b869c-9ab5-4e33-c6ee-a027e7d10a5e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10, 10), dtype=float32, numpy=\n",
       "array([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [1., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [1., 1., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [1., 1., 1., 1., 0., 0., 0., 0., 0., 0.],\n",
       "       [1., 1., 1., 1., 1., 0., 0., 0., 0., 0.],\n",
       "       [1., 1., 1., 1., 1., 1., 0., 0., 0., 0.],\n",
       "       [1., 1., 1., 1., 1., 1., 1., 0., 0., 0.],\n",
       "       [1., 1., 1., 1., 1., 1., 1., 1., 0., 0.],\n",
       "       [1., 1., 1., 1., 1., 1., 1., 1., 1., 0.],\n",
       "       [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]], dtype=float32)>"
      ]
     },
     "execution_count": 40,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 상삼각행렬 만들기\n",
    "tf.linalg.band_part(tf.ones((10, 10)), -1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 166
    },
    "id": "Gs3HDOex3rnK",
    "outputId": "1b3e609a-3891-4f7e-e7fd-072c66e4045b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[0. 1. 1. ... 1. 1. 1.]\n",
      " [0. 0. 1. ... 1. 1. 1.]\n",
      " [0. 0. 0. ... 1. 1. 1.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 1. 1.]\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 0. 0.]], shape=(40, 40), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "temp_mask = 1 - tf.linalg.band_part(tf.ones((40, 40)), -1, 0)\n",
    "print(temp_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 333
    },
    "id": "vhYWwxQo373G",
    "outputId": "0c50bc1b-c4d9-4fa3-e36c-76266a5535d8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[15.  9.  5. 15. 16. 14. 15.  8. 13. 12.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.]]\n",
      "tf.Tensor(\n",
      "[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      "  1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]], shape=(1, 40), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      "    1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]]]], shape=(1, 1, 1, 40), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[[[0. 1. 1. ... 1. 1. 1.]\n",
      "   [0. 0. 1. ... 1. 1. 1.]\n",
      "   [0. 0. 0. ... 1. 1. 1.]\n",
      "   ...\n",
      "   [0. 0. 0. ... 1. 1. 1.]\n",
      "   [0. 0. 0. ... 1. 1. 1.]\n",
      "   [0. 0. 0. ... 1. 1. 1.]]]], shape=(1, 1, 40, 40), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# 예제 문장 (1, 40) 즉, 1문장, 40개의 단어를 가짐\n",
    "example_sentence = np.hstack([np.random.randint(20, size=10), np.zeros(30)])[np.newaxis, :]\n",
    "print(example_sentence) # 예제 문장\n",
    "example_sentence = tf.cast(tf.math.equal(example_sentence, 0), dtype=tf.float32)\n",
    "print(example_sentence) # 패딩 된 것(문장에서 0이 아닌 부분은 0으로, 0인 부분은 1로)\n",
    "example_sentence = example_sentence[:, tf.newaxis, tf.newaxis, :] # 차원 변경\n",
    "print(example_sentence)\n",
    "\n",
    "look_ahead_mask = tf.maximum(temp_mask, example_sentence) # 상삼각행렬과 example sentence를 비교해가며 최대값만 취해서 패딩을 1로 처리함\n",
    "# look ahead mask\n",
    "print(look_ahead_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Uy3HuPbQ2_wJ"
   },
   "outputs": [],
   "source": [
    "# look_ahead_mask 알아보기\n",
    "def create_look_ahead_mask(size):\n",
    "  mask = 1 - tf.linalg.band_part(tf.ones((size, size)), -1, 0)\n",
    "  return mask\n",
    "  \n",
    "def create_masks(tar):\n",
    "  temp_mask = create_look_ahead_mask(tf.shape(tar)[1])\n",
    "  \n",
    "  \n",
    "  reverse_tar = tf.cast(tf.math.equal(tar, 0), dtype=tf.float32)\n",
    "  reverse_tar = reverse_tar[:,tf.newaxis,tf.newaxis,:]\n",
    "  look_ahead_mask = tf.maximum(reverse_tar, temp_mask)\n",
    "\n",
    "\n",
    "  return look_ahead_mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FZYtaJVW6Q4K"
   },
   "source": [
    "또한 패딩 마스크를 두어서, 패딩인 부분은 1으로 처리하겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "N47qF-CZ6m26"
   },
   "outputs": [],
   "source": [
    "def create_padding_mask(seq):\n",
    "  seq = tf.cast(tf.math.equal(seq, 0), tf.float32)\n",
    "  return seq[:, tf.newaxis, tf.newaxis, :]  # (batch_size, 1, 1, seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 128
    },
    "id": "T6c7E0716uUj",
    "outputId": "973a0eed-7683-4f41-b52a-adcc307995d7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[10.  1.  4. 16.  3.  9. 18.  6. 17. 13.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.]]\n",
      "tf.Tensor(\n",
      "[[[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      "    1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]]]], shape=(1, 1, 1, 40), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "example_sentence = np.hstack([np.random.randint(20, size=10), np.zeros(30)])[np.newaxis, :]\n",
    "# 패딩 되기 전\n",
    "print(example_sentence)\n",
    "# 패딩 된 후\n",
    "print(create_padding_mask(example_sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Vr-x36BB_ekk"
   },
   "outputs": [],
   "source": [
    "class DecoderLayer(tf.keras.layers.Layer):\n",
    "  def __init__(self, d_model, num_heads, dff, rate=0.1):\n",
    "    super().__init__()\n",
    "\n",
    "    self.mha1 = MultiHeadAttention(d_model, num_heads)\n",
    "    self.mha2 = MultiHeadAttention(d_model, num_heads)\n",
    "    \n",
    "    self.ffn = Pointwise_FeedForward_Network(d_model, dff)\n",
    "\n",
    "    self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "    self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "    self.layernorm3 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "\n",
    "    self.dropout1 = tf.keras.layers.Dropout(rate)\n",
    "    self.dropout2 = tf.keras.layers.Dropout(rate)\n",
    "    self.dropout3 = tf.keras.layers.Dropout(rate)\n",
    "\n",
    "\n",
    "  def call(self, x, enc_output, training, padding_mask, look_ahead_mask):\n",
    "    # x : 훈련 과정에서는 Seq2Seq에서 번역이 될 문장이 입력됨,\n",
    "    # x : 추론 과정에서는 과거의 단어가 입력됨\n",
    "    # enc_output : 인코더의 출력\n",
    "    # padding_mask : 멀티 헤드 어텐션에 필요한 정보만 남기고 나머지는 패딩 처리\n",
    "    # look_ahead_mask : 위에 설명\n",
    "    # enc_output_shape == (batch_size, input_seq_len, d_model)\n",
    "\n",
    "    #### 첫번째 멀티 헤드 어텐션 파트임 ####\n",
    "    #### 첫번째 멀티 헤드 어텐션은, 인코더와의 결합 없이 번역이 될 문장끼리만 어텐션을 함 ####\n",
    "    attn1, attn_weights_block1 = self.mha1(x, x, x, look_ahead_mask)\n",
    "    out1 = self.dropout1(attn1, training=training)\n",
    "    out1 = self.layernorm1(out1 + x)\n",
    "    \n",
    "    #### 두번째 멀티 헤드 어텐션 파트임 ####\n",
    "    #### 두번째 멀티 헤드 어텐션 파트는 enc_output에서 인코더와(포르투갈어), out1(영어문장으로만 셀프어텐션을 한 것)\n",
    "    #### 이 다시 멀티 헤드 어텐션 과정을 거치게 됨\n",
    "    #### 다시 상기하자면, 이번 과제는 포르투갈 어를 영어로 번역하는 것임\n",
    "    attn2, attn_weights_block2 = self.mha2(\n",
    "        enc_output, enc_output, out1, padding_mask)\n",
    "    out2 = self.dropout2(attn2, training=training)\n",
    "    out2 = self.layernorm2(out2 + out1) # (batch_size, target_seq_len, d_model)\n",
    "    \n",
    "\n",
    "    ffn_output = self.ffn(out2)\n",
    "    ffn_output = self.dropout3(ffn_output, training=training)\n",
    "    out3 = self.layernorm3(ffn_output + out2) # (batch_size, target_seq_len, d_model)\n",
    "    \n",
    "\n",
    "    return out3, attn_weights_block1, attn_weights_block2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 296
    },
    "id": "kk9I7NdJNMN0",
    "outputId": "5082fd8d-6bb8-40b9-95a7-d33826563859"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[-1.861443    0.27191493  2.616368   ... -0.06494223  0.37421167\n",
      "   -0.33387262]\n",
      "  [-1.4556838   0.02654802  2.9826684  ... -0.11393957  0.32178423\n",
      "   -0.3594063 ]\n",
      "  [-1.4244808  -0.52545476  2.9944925  ... -0.17711166  0.2963217\n",
      "   -0.42363918]\n",
      "  ...\n",
      "  [-1.869552    0.39455086  2.1463938  ...  0.01799125  0.5466902\n",
      "   -0.32442454]\n",
      "  [-1.417133    0.5532684   2.2169363  ... -0.02880318  0.5430099\n",
      "   -0.24101742]\n",
      "  [-1.0640508   0.19279505  2.6072536  ... -0.03333719  0.5305211\n",
      "   -0.1643059 ]]], shape=(1, 40, 512), dtype=float32)\n",
      "(1, 40, 512)\n"
     ]
    }
   ],
   "source": [
    "sample_decoder_layer = DecoderLayer(d_model=512, num_heads=8, dff=2048)\n",
    "sample_decoder_layer_output, _, _ = sample_decoder_layer(embedded, sample_encoding, False, None, None)\n",
    "print(sample_decoder_layer_output)\n",
    "print(sample_decoder_layer_output.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JwKQPfQiQc_r"
   },
   "source": [
    "이제 여러 층의 인코더를 쌓는 Encoder Class를 정의해보도록 하겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "c7WJs-lXOXtS"
   },
   "outputs": [],
   "source": [
    "class Encoder(tf.keras.layers.Layer):\n",
    "  def __init__(self, num_layers, d_model, num_heads, dff, rate=0.1):\n",
    "    super().__init__()\n",
    "\n",
    "    self.d_model = d_model\n",
    "    self.num_layers = num_layers\n",
    "\n",
    "    self.enc_layers = [EncoderLayer(d_model, num_heads, dff, rate) for _ in range(num_layers)] # 인코더를 쌓아서 층을 만듦\n",
    "\n",
    "\n",
    "  def call(self, x, training, mask):\n",
    "    # 인풋은 타겟 임베딩 + 포지셔닝 임베딩\n",
    "    for i in range(self.num_layers):\n",
    "      x = self.enc_layers[i](x, training, mask)\n",
    "\n",
    "    return x # 출력 모양 : (batch_size, input_seq_len, d_model), 인코더의 층을 출력으로 내보냄"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 277
    },
    "id": "UfRtgnkuy578",
    "outputId": "aaca8a9f-c7cd-423b-b7b2-92bd2d2f431f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[-0.47727606  1.6010028   0.16539513 ... -0.7333455  -0.87375486\n",
      "   -0.6986873 ]\n",
      "  [-0.44379246  1.5546945   0.24726509 ... -0.7487673  -0.84782803\n",
      "   -0.72768575]\n",
      "  [-0.42934194  1.4639065   0.29219803 ... -0.7357335  -0.8191331\n",
      "   -0.7450143 ]\n",
      "  ...\n",
      "  [-0.55059993  1.5710609   0.2833891  ... -0.7724647  -0.718376\n",
      "   -0.85729116]\n",
      "  [-0.47772884  1.5554613   0.27527115 ... -0.783389   -0.6973587\n",
      "   -0.8585827 ]\n",
      "  [-0.4197512   1.4693106   0.30762646 ... -0.77654094 -0.6887383\n",
      "   -0.8284968 ]]], shape=(1, 40, 512), dtype=float32) (1, 40, 512)\n"
     ]
    }
   ],
   "source": [
    "Encoder_layer = Encoder(6, 512, 8, 2048) #6층, 512차원의 단어 임베딩, 8개의 병렬 멀티 헤드 어텐션의 인코더\n",
    "# embedded : 위치 임베딩 + 단어 임베딩\n",
    "Encoded = Encoder_layer(embedded, False, None)\n",
    "print(Encoded, Encoded.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DQnvGLCzRmZ7"
   },
   "outputs": [],
   "source": [
    "class Decoder(tf.keras.layers.Layer):\n",
    "  def __init__(self, num_layers, d_model, num_heads, dff, rate=0.1):\n",
    "    super().__init__()\n",
    "\n",
    "    self.d_model = d_model\n",
    "    self.num_layers = num_layers\n",
    "\n",
    "    self.dec_layers = [DecoderLayer(d_model, num_heads, dff, rate) for _ in range(num_layers)]\n",
    "\n",
    "\n",
    "  def call(self, x, enc_output, training, padding_mask, look_ahead_mask):\n",
    "    attention_weights = {}\n",
    "\n",
    "    for i in range(self.num_layers):\n",
    "      x, block1, block2 = self.dec_layers[i](x, enc_output, training, padding_mask, look_ahead_mask)\n",
    "\n",
    "      attention_weights['decoder_layer{}_block1'.format(i+1)] = block1\n",
    "      attention_weights['decoder_layer{}_block2'.format(i+1)] = block2\n",
    "\n",
    "    return x, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 296
    },
    "id": "ovF60mjeTnfu",
    "outputId": "57e33d4f-4e88-41ef-c8cf-49cada08ccbc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[-0.3431721  -0.3290148   1.5598023  ...  2.303232    1.371545\n",
      "    0.11695281]\n",
      "  [-0.33767134 -0.33899462  1.5710102  ...  2.3005219   1.3617636\n",
      "    0.11278047]\n",
      "  [-0.3494037  -0.3352064   1.5691497  ...  2.297593    1.3669722\n",
      "    0.11108976]\n",
      "  ...\n",
      "  [-0.35400254 -0.33930886  1.5467725  ...  2.3000638   1.3758032\n",
      "    0.1186213 ]\n",
      "  [-0.3487999  -0.33877504  1.543845   ...  2.3040543   1.3668836\n",
      "    0.12298044]\n",
      "  [-0.33305132 -0.34201398  1.5553851  ...  2.310325    1.3722295\n",
      "    0.11848406]]], shape=(1, 40, 512), dtype=float32) (1, 40, 512)\n",
      "6층 Decoder 출력 : (1, 40, 512)\n"
     ]
    }
   ],
   "source": [
    "# 위치 임베딩 + 포지셔널 임베딩\n",
    "embedded\n",
    "#인코더 아웃풋 \n",
    "Encoded\n",
    "\n",
    "# 디코더의 위치+포지셔널 임베딩(Teaching Force 과정이라 디코더 부분에 타겟(영어)도 넣어줌)\n",
    "target_embedder = TransformerEmbedding(d_model=512, input_vocab_size=tokenizer_en.vocab_size, maximum_position_encoding=512, dropout_rate=0.1)\n",
    "target_embedding = target_embedder(tf.cast(np.random.uniform(size=(1,40)), dtype=tf.float32), True)\n",
    "\n",
    "# 6층 디코더\n",
    "Decoder_layer = Decoder(num_layers=6, d_model=512, num_heads=8, dff=2048)\n",
    "\n",
    "Decoded, _ = Decoder_layer(target_embedding, Encoded, False, None, None) # Decoded에서 인코더와 디코더의 정보 결합\n",
    "print(Decoded, Decoded.shape)\n",
    "#최종출력\n",
    "print(\"6층 Decoder 출력 :\", sample_encoding.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "03BBwaxOUPbJ"
   },
   "source": [
    "# 임베딩 + 인코딩 + 디코딩을 결합하는 Transformer Class 정의  \n",
    "최종적으로 지금까지 배웠던 임베딩, 인코딩, 디코딩을 결합하는 Transformer Class를 정의."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cgoRro-QUE3G"
   },
   "outputs": [],
   "source": [
    "class Transformer(tf.keras.Model):\n",
    "  def __init__(self, num_layers, d_model, num_heads, dff, input_vocab_size, target_vocab_size, pe_input, pe_target, rate=0.1):\n",
    "    \n",
    "    # num_layers : 인코딩, 디코딩을 몇 층으로 할 지\n",
    "    # d_model : 임베딩의 차원\n",
    "    # num_heads : 병렬로 어텐션을 수행할 멀티 헤드 어텐션의 개수\n",
    "    # dff : 포인트와이즈 피드포워드 네트워크에서 몇 차원의 연산이 이루어 질 지\n",
    "    # input_vocab_size : 본 문제는 포르투갈어를 영어로 번역하는 문제이며, 포르투갈어 토크나이저의 총 단어수를 뜻함(처음 도입부에서 만들었음)\n",
    "    # target_vocab_size : 영어 토크나이저의 총 단어수를 뜻함(위와 마찬가지)\n",
    "    # pe_input : 별로 중요한 것은 아니지만, 위치 임베딩 할 때 위치 임베딩의 길이의 상한을 뜻함(포르투갈어)\n",
    "    # pe_target : 위치 임베딩의 상한(영어)\n",
    "    super().__init__()\n",
    "    \n",
    "    self.input_embedder = TransformerEmbedding(d_model, input_vocab_size, pe_input, rate) # 포르투갈어 임베딩\n",
    "    self.encoder = Encoder(num_layers, d_model, num_heads, dff, rate) # x층 인코더\n",
    "\n",
    "    self.target_embedder = TransformerEmbedding(d_model, target_vocab_size, pe_target, rate) # 영어 임베딩\n",
    "    self.decoder = Decoder(num_layers, d_model, num_heads, dff, rate) # x층 디코더\n",
    "\n",
    "    self.final_layer = tf.keras.layers.Dense(target_vocab_size) # 최종 출력 decoder (영어 단어의 수), 우리가 맞추려는 것은 영어 단어의 인덱스이므로..\n",
    "\n",
    "  def call(self, inp, tar, training):\n",
    "    # inp : 포르투갈어\n",
    "    # tar : 영어\n",
    "\n",
    "    \n",
    "    enc_mask = create_padding_mask(inp) # 인코더 패딩\n",
    "    dec_mask = create_padding_mask(inp) # 디코더 패딩\n",
    "    look_ahead_mask = create_masks(tar) # 디코더에 들어갈 look_ahead_mask 정의\n",
    "\n",
    "    inp_embedding = self.input_embedder(inp) # 인코더 임베딩 정의\n",
    "    enc_output = self.encoder(inp_embedding, training, enc_mask) # 인코더 아웃풋(디코더와 결합되게 됨)\n",
    "\n",
    "    tar_embedding = self.target_embedder(tar) # 디코더 임베딩 정의\n",
    "   \n",
    "    dec_output, attention_weights = self.decoder(tar_embedding, enc_output, training, dec_mask, look_ahead_mask)\n",
    "    \n",
    "    final_output = self.final_layer(dec_output) # 최종 영어 단어를 예측하는 아웃풋 정의\n",
    "\n",
    "    return final_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 277
    },
    "id": "4hwFuX2H-df4",
    "outputId": "36fb6b50-b015-41a3-daad-fe403000bfdd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[-0.3345034  -0.01396056  0.5463812  ... -0.05968201  0.3116074\n",
      "   -0.4603326 ]\n",
      "  [-0.33054727 -0.03038269  0.5541858  ... -0.04792291  0.3003717\n",
      "   -0.46931484]\n",
      "  [-0.3331985  -0.02435888  0.55642915 ... -0.04478735  0.3014708\n",
      "   -0.4855488 ]\n",
      "  ...\n",
      "  [-0.3428004  -0.04054517  0.5622994  ... -0.05635282  0.2901105\n",
      "   -0.49792284]\n",
      "  [-0.34195268 -0.04063866  0.5711767  ... -0.06332943  0.2811991\n",
      "   -0.49841833]\n",
      "  [-0.34157473 -0.0376301   0.5684389  ... -0.06148854  0.28651989\n",
      "   -0.50064284]]], shape=(1, 40, 8089), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# 트랜스포머 테스트하기\n",
    "sample_transformer = Transformer(6, 512, 8, 2048, tokenizer_pt.vocab_size + 2, tokenizer_en.vocab_size + 2, 10000, 10000)\n",
    "inp = tf.cast(np.random.randint(100,size=40)[np.newaxis, :], dtype=tf.int32)\n",
    "tar = tf.cast(np.random.randint(100,size=40)[np.newaxis, :], dtype=tf.int32)\n",
    "transformer = sample_transformer(inp, tar, False)\n",
    "print(transformer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0LuW2OLQ_LC3"
   },
   "source": [
    "#하이퍼파라미터 설정하기\n",
    "테스트를 위해서 층을 가볍게 쌓아보도록 하겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3IBl1m3T_KdU"
   },
   "outputs": [],
   "source": [
    "num_layers = 4    # 4층 인코더, 디코더 쌓기\n",
    "d_model = 128   # 단어의 임베딩 차원을 128로\n",
    "dff = 512  # 포인트와이즈 피드포워드 네트워크의 일시적인 차원을 512\n",
    "num_heads = 8 # 멀티 헤드 어텐션을 8개로 병렬 처리\n",
    "SEQ_LEN = 40\n",
    "\n",
    "input_vocab_size = tokenizer_pt.vocab_size + 2\n",
    "target_vocab_size = tokenizer_en.vocab_size + 2\n",
    "dropout_rate = 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oJlCBwNE_Sex"
   },
   "source": [
    "# 옵티마이저 설정하기\n",
    "옵티마이저는 논문에 따라서 성능이 좋았다는 옵티마이저를 복사 붙여넣기 함."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wH6O3Gvs_R0O"
   },
   "outputs": [],
   "source": [
    "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
    "  def __init__(self, d_model, warmup_steps=4000):\n",
    "    super(CustomSchedule, self).__init__()\n",
    "    \n",
    "    self.d_model = d_model\n",
    "    self.d_model = tf.cast(self.d_model, tf.float32)\n",
    "\n",
    "    self.warmup_steps = warmup_steps\n",
    "    \n",
    "  def __call__(self, step):\n",
    "    arg1 = tf.math.rsqrt(step)\n",
    "    arg2 = step * (self.warmup_steps ** -1.5)\n",
    "    \n",
    "    return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)\n",
    "\n",
    "learning_rate = CustomSchedule(d_model)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate, beta_1=0.9, beta_2=0.98, \n",
    "                                     epsilon=1e-9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZemqrgPw_bPe"
   },
   "source": [
    "# Loss 함수 설정하기\n",
    "loss 함수 또한 중요한 부분인데, transformer에서는 패딩되는 부분을 Loss를 계산할 때 연산하지 않음."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vl-ogg3D_eru"
   },
   "outputs": [],
   "source": [
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True, reduction='none') #from_logits=True로 하면 Dense 이후 softmax layer 값 출력\n",
    "\n",
    "def loss_function(real, pred):\n",
    "  mask = tf.math.logical_not(tf.math.equal(real, 0)) # 예를 들어서 실제 자료(0은 패딩)가 [1,2,3,4,5,0,0,0,0,0] 이라면 [0,0,0,0,0,1,1,1,1,1]로 바꿔 줌\n",
    "                                                     # 이후 tf.math.logical_not을 활용해서 [True,True,True,True,True,False,False,False,False,False]으로 바꿔 줌\n",
    "  loss_ = loss_object(real, pred) # loss_는 패딩을 고려하지 않은 loss 값\n",
    "\n",
    "  mask = tf.cast(mask, dtype=loss_.dtype) # [True,True,True,True,True,False,False,False,False,False]를 [1,1,1,1,1,0,0,0,0,0] 으로 바꿔 줌\n",
    "  loss_ *= mask # loss에 mask를 곱해서, 패딩인 부분은 0처리 해줌\n",
    "\n",
    "  return tf.reduce_sum(loss_)/tf.reduce_sum(mask)\n",
    "\n",
    "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
    "train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='train_accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6zZ0hEBSD5ka"
   },
   "source": [
    "# 모델 훈련"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Z2GySrPlEx2l"
   },
   "outputs": [],
   "source": [
    "transformer = Transformer(num_layers, d_model, num_heads, dff,\n",
    "                          input_vocab_size, target_vocab_size, \n",
    "                          pe_input=10000, \n",
    "                          pe_target=10000,\n",
    "                          rate=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "k07jNkQIw9N6"
   },
   "outputs": [],
   "source": [
    "# 인풋, 아웃풋의 텐셔 shape 정의\n",
    "train_step_signature = [\n",
    "    tf.TensorSpec(shape=(None, None), dtype=tf.int64),\n",
    "    tf.TensorSpec(shape=(None, None), dtype=tf.int64),\n",
    "]\n",
    "\n",
    "# tf.function을 사용하면 그래프를 미리 컴파일 하기 때문에 속도가 상당히 빠름\n",
    "# 같은 GPU여도 케라스에 비해서 체감상 7~8배 정도의 차이가 나는 것 같음\n",
    "@tf.function(input_signature=train_step_signature)\n",
    "def train_step(inp, tar):\n",
    "  tar_inp = tar[:, :-1]\n",
    "  tar_real = tar[:, 1:]\n",
    "  \n",
    "  with tf.GradientTape() as tape:\n",
    "    predictions = transformer(inp, tar_inp, True)\n",
    "    loss = loss_function(tar_real, predictions)\n",
    "\n",
    "  gradients = tape.gradient(loss, transformer.trainable_variables)    \n",
    "  optimizer.apply_gradients(zip(gradients, transformer.trainable_variables))\n",
    "  \n",
    "  train_loss(loss)\n",
    "  train_accuracy(tar_real, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1Iq2uReVFS1J"
   },
   "outputs": [],
   "source": [
    "# 저장할 체크포인트 지정\n",
    "checkpoint_path = \"./\"\n",
    "\n",
    "ckpt = tf.train.Checkpoint(transformer=transformer,\n",
    "                           optimizer=optimizer)\n",
    "\n",
    "ckpt_manager = tf.train.CheckpointManager(ckpt, checkpoint_path, max_to_keep=5)\n",
    "\n",
    "# if a checkpoint exists, restore the latest checkpoint.\n",
    "if ckpt_manager.latest_checkpoint:\n",
    "  ckpt.restore(ckpt_manager.latest_checkpoint)\n",
    "  print ('Latest checkpoint restored!!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "xHAeCJP-xZCu",
    "outputId": "36a8fe30-f744-4a6c-bf73-4a5e74e96bc7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Batch 0 Loss 8.9987 Accuracy 0.0000\n",
      "Epoch 1 Batch 50 Loss 8.9453 Accuracy 0.0034\n",
      "Epoch 1 Batch 100 Loss 8.8529 Accuracy 0.0134\n",
      "Epoch 1 Batch 150 Loss 8.7466 Accuracy 0.0168\n",
      "Epoch 1 Batch 200 Loss 8.6171 Accuracy 0.0184\n",
      "Epoch 1 Batch 250 Loss 8.4618 Accuracy 0.0195\n",
      "Epoch 1 Batch 300 Loss 8.2848 Accuracy 0.0236\n",
      "Epoch 1 Batch 350 Loss 8.1004 Accuracy 0.0273\n",
      "Epoch 1 Batch 400 Loss 7.9196 Accuracy 0.0301\n",
      "Epoch 1 Batch 450 Loss 7.7574 Accuracy 0.0326\n",
      "Epoch 1 Batch 500 Loss 7.6136 Accuracy 0.0355\n",
      "Epoch 1 Batch 550 Loss 7.4792 Accuracy 0.0388\n",
      "Epoch 1 Batch 600 Loss 7.3546 Accuracy 0.0427\n",
      "Epoch 1 Batch 650 Loss 7.2348 Accuracy 0.0465\n",
      "Epoch 1 Batch 700 Loss 7.1196 Accuracy 0.0503\n",
      "Epoch 1 Loss 7.1152 Accuracy 0.0504\n",
      "Time taken for 1 epoch: 79.08091878890991 secs\n",
      "\n",
      "Epoch 2 Batch 0 Loss 5.7278 Accuracy 0.0938\n",
      "Epoch 2 Batch 50 Loss 5.4732 Accuracy 0.1046\n",
      "Epoch 2 Batch 100 Loss 5.4041 Accuracy 0.1061\n",
      "Epoch 2 Batch 150 Loss 5.3532 Accuracy 0.1085\n",
      "Epoch 2 Batch 200 Loss 5.3088 Accuracy 0.1099\n",
      "Epoch 2 Batch 250 Loss 5.2682 Accuracy 0.1124\n",
      "Epoch 2 Batch 300 Loss 5.2265 Accuracy 0.1145\n",
      "Epoch 2 Batch 350 Loss 5.1899 Accuracy 0.1161\n",
      "Epoch 2 Batch 400 Loss 5.1555 Accuracy 0.1177\n",
      "Epoch 2 Batch 450 Loss 5.1229 Accuracy 0.1194\n",
      "Epoch 2 Batch 500 Loss 5.0927 Accuracy 0.1209\n",
      "Epoch 2 Batch 550 Loss 5.0652 Accuracy 0.1222\n",
      "Epoch 2 Batch 600 Loss 5.0397 Accuracy 0.1234\n",
      "Epoch 2 Batch 650 Loss 5.0119 Accuracy 0.1247\n",
      "Epoch 2 Batch 700 Loss 4.9883 Accuracy 0.1259\n",
      "Epoch 2 Loss 4.9868 Accuracy 0.1259\n",
      "Time taken for 1 epoch: 44.30380201339722 secs\n",
      "\n",
      "Epoch 3 Batch 0 Loss 4.6232 Accuracy 0.1753\n",
      "Epoch 3 Batch 50 Loss 4.5817 Accuracy 0.1450\n",
      "Epoch 3 Batch 100 Loss 4.5632 Accuracy 0.1459\n",
      "Epoch 3 Batch 150 Loss 4.5604 Accuracy 0.1459\n",
      "Epoch 3 Batch 200 Loss 4.5491 Accuracy 0.1465\n",
      "Epoch 3 Batch 250 Loss 4.5413 Accuracy 0.1470\n",
      "Epoch 3 Batch 300 Loss 4.5299 Accuracy 0.1475\n",
      "Epoch 3 Batch 350 Loss 4.5184 Accuracy 0.1482\n",
      "Epoch 3 Batch 400 Loss 4.5085 Accuracy 0.1485\n",
      "Epoch 3 Batch 450 Loss 4.5005 Accuracy 0.1490\n",
      "Epoch 3 Batch 500 Loss 4.4873 Accuracy 0.1495\n",
      "Epoch 3 Batch 550 Loss 4.4756 Accuracy 0.1498\n",
      "Epoch 3 Batch 600 Loss 4.4677 Accuracy 0.1501\n",
      "Epoch 3 Batch 650 Loss 4.4568 Accuracy 0.1505\n",
      "Epoch 3 Batch 700 Loss 4.4470 Accuracy 0.1510\n",
      "Epoch 3 Loss 4.4468 Accuracy 0.1510\n",
      "Time taken for 1 epoch: 44.45479679107666 secs\n",
      "\n",
      "Epoch 4 Batch 0 Loss 4.2324 Accuracy 0.1636\n",
      "Epoch 4 Batch 50 Loss 4.1740 Accuracy 0.1633\n",
      "Epoch 4 Batch 100 Loss 4.1639 Accuracy 0.1627\n",
      "Epoch 4 Batch 150 Loss 4.1519 Accuracy 0.1631\n",
      "Epoch 4 Batch 200 Loss 4.1324 Accuracy 0.1641\n",
      "Epoch 4 Batch 250 Loss 4.1250 Accuracy 0.1651\n",
      "Epoch 4 Batch 300 Loss 4.1188 Accuracy 0.1660\n",
      "Epoch 4 Batch 350 Loss 4.1145 Accuracy 0.1666\n",
      "Epoch 4 Batch 400 Loss 4.1005 Accuracy 0.1673\n",
      "Epoch 4 Batch 450 Loss 4.0890 Accuracy 0.1679\n",
      "Epoch 4 Batch 500 Loss 4.0780 Accuracy 0.1688\n",
      "Epoch 4 Batch 550 Loss 4.0656 Accuracy 0.1697\n",
      "Epoch 4 Batch 600 Loss 4.0532 Accuracy 0.1705\n",
      "Epoch 4 Batch 650 Loss 4.0402 Accuracy 0.1714\n",
      "Epoch 4 Batch 700 Loss 4.0248 Accuracy 0.1724\n",
      "Epoch 4 Loss 4.0242 Accuracy 0.1725\n",
      "Time taken for 1 epoch: 44.30045199394226 secs\n",
      "\n",
      "Epoch 5 Batch 0 Loss 3.4033 Accuracy 0.2066\n",
      "Epoch 5 Batch 50 Loss 3.6744 Accuracy 0.1919\n",
      "Epoch 5 Batch 100 Loss 3.6507 Accuracy 0.1927\n",
      "Epoch 5 Batch 150 Loss 3.6447 Accuracy 0.1930\n",
      "Epoch 5 Batch 200 Loss 3.6315 Accuracy 0.1935\n",
      "Epoch 5 Batch 250 Loss 3.6214 Accuracy 0.1949\n",
      "Epoch 5 Batch 300 Loss 3.6175 Accuracy 0.1955\n",
      "Epoch 5 Batch 350 Loss 3.6045 Accuracy 0.1963\n",
      "Epoch 5 Batch 400 Loss 3.5996 Accuracy 0.1968\n",
      "Epoch 5 Batch 450 Loss 3.5912 Accuracy 0.1975\n",
      "Epoch 5 Batch 500 Loss 3.5839 Accuracy 0.1977\n",
      "Epoch 5 Batch 550 Loss 3.5748 Accuracy 0.1985\n",
      "Epoch 5 Batch 600 Loss 3.5650 Accuracy 0.1990\n",
      "Epoch 5 Batch 650 Loss 3.5589 Accuracy 0.1998\n",
      "Epoch 5 Batch 700 Loss 3.5506 Accuracy 0.2004\n",
      "Saving checkpoint for epoch 5 at ./ckpt-1\n",
      "Epoch 5 Loss 3.5497 Accuracy 0.2004\n",
      "Time taken for 1 epoch: 44.612069606781006 secs\n",
      "\n",
      "Epoch 6 Batch 0 Loss 3.0750 Accuracy 0.2216\n",
      "Epoch 6 Batch 50 Loss 3.1687 Accuracy 0.2194\n",
      "Epoch 6 Batch 100 Loss 3.1730 Accuracy 0.2190\n",
      "Epoch 6 Batch 150 Loss 3.1820 Accuracy 0.2170\n",
      "Epoch 6 Batch 200 Loss 3.1866 Accuracy 0.2174\n",
      "Epoch 6 Batch 250 Loss 3.1848 Accuracy 0.2187\n",
      "Epoch 6 Batch 300 Loss 3.1812 Accuracy 0.2195\n",
      "Epoch 6 Batch 350 Loss 3.1806 Accuracy 0.2197\n",
      "Epoch 6 Batch 400 Loss 3.1767 Accuracy 0.2200\n",
      "Epoch 6 Batch 450 Loss 3.1744 Accuracy 0.2203\n",
      "Epoch 6 Batch 500 Loss 3.1683 Accuracy 0.2205\n",
      "Epoch 6 Batch 550 Loss 3.1619 Accuracy 0.2211\n",
      "Epoch 6 Batch 600 Loss 3.1561 Accuracy 0.2215\n",
      "Epoch 6 Batch 650 Loss 3.1484 Accuracy 0.2222\n",
      "Epoch 6 Batch 700 Loss 3.1421 Accuracy 0.2229\n",
      "Epoch 6 Loss 3.1415 Accuracy 0.2229\n",
      "Time taken for 1 epoch: 44.359644174575806 secs\n",
      "\n",
      "Epoch 7 Batch 0 Loss 2.6573 Accuracy 0.2393\n",
      "Epoch 7 Batch 50 Loss 2.7642 Accuracy 0.2404\n",
      "Epoch 7 Batch 100 Loss 2.7670 Accuracy 0.2407\n",
      "Epoch 7 Batch 150 Loss 2.7668 Accuracy 0.2406\n",
      "Epoch 7 Batch 200 Loss 2.7715 Accuracy 0.2397\n",
      "Epoch 7 Batch 250 Loss 2.7681 Accuracy 0.2396\n",
      "Epoch 7 Batch 300 Loss 2.7650 Accuracy 0.2407\n",
      "Epoch 7 Batch 350 Loss 2.7639 Accuracy 0.2420\n",
      "Epoch 7 Batch 400 Loss 2.7613 Accuracy 0.2425\n",
      "Epoch 7 Batch 450 Loss 2.7583 Accuracy 0.2431\n",
      "Epoch 7 Batch 500 Loss 2.7541 Accuracy 0.2433\n",
      "Epoch 7 Batch 550 Loss 2.7502 Accuracy 0.2437\n",
      "Epoch 7 Batch 600 Loss 2.7465 Accuracy 0.2442\n",
      "Epoch 7 Batch 650 Loss 2.7427 Accuracy 0.2445\n",
      "Epoch 7 Batch 700 Loss 2.7391 Accuracy 0.2447\n",
      "Epoch 7 Loss 2.7391 Accuracy 0.2447\n",
      "Time taken for 1 epoch: 44.38622713088989 secs\n",
      "\n",
      "Epoch 8 Batch 0 Loss 2.3553 Accuracy 0.2520\n",
      "Epoch 8 Batch 50 Loss 2.3678 Accuracy 0.2643\n",
      "Epoch 8 Batch 100 Loss 2.3673 Accuracy 0.2646\n",
      "Epoch 8 Batch 150 Loss 2.3807 Accuracy 0.2658\n",
      "Epoch 8 Batch 200 Loss 2.3894 Accuracy 0.2654\n",
      "Epoch 8 Batch 250 Loss 2.3896 Accuracy 0.2648\n",
      "Epoch 8 Batch 300 Loss 2.3910 Accuracy 0.2652\n",
      "Epoch 8 Batch 350 Loss 2.3955 Accuracy 0.2654\n",
      "Epoch 8 Batch 400 Loss 2.4008 Accuracy 0.2655\n",
      "Epoch 8 Batch 450 Loss 2.4007 Accuracy 0.2655\n",
      "Epoch 8 Batch 500 Loss 2.4016 Accuracy 0.2658\n",
      "Epoch 8 Batch 550 Loss 2.4038 Accuracy 0.2654\n",
      "Epoch 8 Batch 600 Loss 2.4054 Accuracy 0.2653\n",
      "Epoch 8 Batch 650 Loss 2.4071 Accuracy 0.2652\n",
      "Epoch 8 Batch 700 Loss 2.4059 Accuracy 0.2651\n",
      "Epoch 8 Loss 2.4056 Accuracy 0.2651\n",
      "Time taken for 1 epoch: 44.65272235870361 secs\n",
      "\n",
      "Epoch 9 Batch 0 Loss 2.1085 Accuracy 0.3173\n",
      "Epoch 9 Batch 50 Loss 2.0877 Accuracy 0.2828\n",
      "Epoch 9 Batch 100 Loss 2.0966 Accuracy 0.2807\n",
      "Epoch 9 Batch 150 Loss 2.1006 Accuracy 0.2810\n",
      "Epoch 9 Batch 200 Loss 2.1152 Accuracy 0.2807\n",
      "Epoch 9 Batch 250 Loss 2.1257 Accuracy 0.2805\n",
      "Epoch 9 Batch 300 Loss 2.1357 Accuracy 0.2800\n",
      "Epoch 9 Batch 350 Loss 2.1423 Accuracy 0.2795\n",
      "Epoch 9 Batch 400 Loss 2.1448 Accuracy 0.2790\n",
      "Epoch 9 Batch 450 Loss 2.1508 Accuracy 0.2790\n",
      "Epoch 9 Batch 500 Loss 2.1557 Accuracy 0.2791\n",
      "Epoch 9 Batch 550 Loss 2.1559 Accuracy 0.2793\n",
      "Epoch 9 Batch 600 Loss 2.1574 Accuracy 0.2793\n",
      "Epoch 9 Batch 650 Loss 2.1622 Accuracy 0.2790\n",
      "Epoch 9 Batch 700 Loss 2.1654 Accuracy 0.2789\n",
      "Epoch 9 Loss 2.1653 Accuracy 0.2789\n",
      "Time taken for 1 epoch: 44.233455419540405 secs\n",
      "\n",
      "Epoch 10 Batch 0 Loss 1.8756 Accuracy 0.2834\n",
      "Epoch 10 Batch 50 Loss 1.8793 Accuracy 0.2984\n",
      "Epoch 10 Batch 100 Loss 1.8912 Accuracy 0.2946\n",
      "Epoch 10 Batch 150 Loss 1.9065 Accuracy 0.2933\n",
      "Epoch 10 Batch 200 Loss 1.9212 Accuracy 0.2928\n",
      "Epoch 10 Batch 250 Loss 1.9342 Accuracy 0.2919\n",
      "Epoch 10 Batch 300 Loss 1.9413 Accuracy 0.2912\n",
      "Epoch 10 Batch 350 Loss 1.9483 Accuracy 0.2908\n",
      "Epoch 10 Batch 400 Loss 1.9546 Accuracy 0.2905\n",
      "Epoch 10 Batch 450 Loss 1.9630 Accuracy 0.2906\n",
      "Epoch 10 Batch 500 Loss 1.9661 Accuracy 0.2902\n",
      "Epoch 10 Batch 550 Loss 1.9707 Accuracy 0.2896\n",
      "Epoch 10 Batch 600 Loss 1.9729 Accuracy 0.2896\n",
      "Epoch 10 Batch 650 Loss 1.9780 Accuracy 0.2896\n",
      "Epoch 10 Batch 700 Loss 1.9842 Accuracy 0.2895\n",
      "Saving checkpoint for epoch 10 at ./ckpt-2\n",
      "Epoch 10 Loss 1.9850 Accuracy 0.2896\n",
      "Time taken for 1 epoch: 44.6807496547699 secs\n",
      "\n",
      "Epoch 11 Batch 0 Loss 1.6583 Accuracy 0.2910\n",
      "Epoch 11 Batch 50 Loss 1.7554 Accuracy 0.3036\n",
      "Epoch 11 Batch 100 Loss 1.7630 Accuracy 0.3031\n",
      "Epoch 11 Batch 150 Loss 1.7672 Accuracy 0.3026\n",
      "Epoch 11 Batch 200 Loss 1.7777 Accuracy 0.3023\n",
      "Epoch 11 Batch 250 Loss 1.7821 Accuracy 0.3023\n",
      "Epoch 11 Batch 300 Loss 1.7942 Accuracy 0.3016\n",
      "Epoch 11 Batch 350 Loss 1.7979 Accuracy 0.3009\n",
      "Epoch 11 Batch 400 Loss 1.8074 Accuracy 0.3001\n",
      "Epoch 11 Batch 450 Loss 1.8148 Accuracy 0.2999\n",
      "Epoch 11 Batch 500 Loss 1.8219 Accuracy 0.2997\n",
      "Epoch 11 Batch 550 Loss 1.8271 Accuracy 0.2987\n",
      "Epoch 11 Batch 600 Loss 1.8334 Accuracy 0.2987\n",
      "Epoch 11 Batch 650 Loss 1.8386 Accuracy 0.2983\n",
      "Epoch 11 Batch 700 Loss 1.8418 Accuracy 0.2979\n",
      "Epoch 11 Loss 1.8421 Accuracy 0.2979\n",
      "Time taken for 1 epoch: 44.32446074485779 secs\n",
      "\n",
      "Epoch 12 Batch 0 Loss 1.7401 Accuracy 0.3160\n",
      "Epoch 12 Batch 50 Loss 1.6039 Accuracy 0.3171\n",
      "Epoch 12 Batch 100 Loss 1.6199 Accuracy 0.3134\n",
      "Epoch 12 Batch 150 Loss 1.6305 Accuracy 0.3125\n",
      "Epoch 12 Batch 200 Loss 1.6466 Accuracy 0.3117\n",
      "Epoch 12 Batch 250 Loss 1.6590 Accuracy 0.3104\n",
      "Epoch 12 Batch 300 Loss 1.6704 Accuracy 0.3096\n",
      "Epoch 12 Batch 350 Loss 1.6805 Accuracy 0.3088\n",
      "Epoch 12 Batch 400 Loss 1.6886 Accuracy 0.3078\n",
      "Epoch 12 Batch 450 Loss 1.6941 Accuracy 0.3072\n",
      "Epoch 12 Batch 500 Loss 1.6983 Accuracy 0.3066\n",
      "Epoch 12 Batch 550 Loss 1.7061 Accuracy 0.3061\n",
      "Epoch 12 Batch 600 Loss 1.7130 Accuracy 0.3058\n",
      "Epoch 12 Batch 650 Loss 1.7191 Accuracy 0.3056\n",
      "Epoch 12 Batch 700 Loss 1.7226 Accuracy 0.3050\n",
      "Epoch 12 Loss 1.7227 Accuracy 0.3050\n",
      "Time taken for 1 epoch: 44.53757357597351 secs\n",
      "\n",
      "Epoch 13 Batch 0 Loss 1.4844 Accuracy 0.3349\n",
      "Epoch 13 Batch 50 Loss 1.5040 Accuracy 0.3219\n",
      "Epoch 13 Batch 100 Loss 1.5169 Accuracy 0.3208\n",
      "Epoch 13 Batch 150 Loss 1.5308 Accuracy 0.3187\n",
      "Epoch 13 Batch 200 Loss 1.5406 Accuracy 0.3179\n",
      "Epoch 13 Batch 250 Loss 1.5506 Accuracy 0.3169\n",
      "Epoch 13 Batch 300 Loss 1.5573 Accuracy 0.3166\n",
      "Epoch 13 Batch 350 Loss 1.5668 Accuracy 0.3159\n",
      "Epoch 13 Batch 400 Loss 1.5764 Accuracy 0.3147\n",
      "Epoch 13 Batch 450 Loss 1.5884 Accuracy 0.3145\n",
      "Epoch 13 Batch 500 Loss 1.5955 Accuracy 0.3139\n",
      "Epoch 13 Batch 550 Loss 1.6034 Accuracy 0.3135\n",
      "Epoch 13 Batch 600 Loss 1.6101 Accuracy 0.3130\n",
      "Epoch 13 Batch 650 Loss 1.6177 Accuracy 0.3126\n",
      "Epoch 13 Batch 700 Loss 1.6227 Accuracy 0.3121\n",
      "Epoch 13 Loss 1.6229 Accuracy 0.3121\n",
      "Time taken for 1 epoch: 45.53956842422485 secs\n",
      "\n",
      "Epoch 14 Batch 0 Loss 1.3664 Accuracy 0.3628\n",
      "Epoch 14 Batch 50 Loss 1.4419 Accuracy 0.3263\n",
      "Epoch 14 Batch 100 Loss 1.4345 Accuracy 0.3253\n",
      "Epoch 14 Batch 150 Loss 1.4512 Accuracy 0.3228\n",
      "Epoch 14 Batch 200 Loss 1.4614 Accuracy 0.3228\n",
      "Epoch 14 Batch 250 Loss 1.4696 Accuracy 0.3227\n",
      "Epoch 14 Batch 300 Loss 1.4805 Accuracy 0.3218\n",
      "Epoch 14 Batch 350 Loss 1.4866 Accuracy 0.3217\n",
      "Epoch 14 Batch 400 Loss 1.4968 Accuracy 0.3206\n",
      "Epoch 14 Batch 450 Loss 1.5069 Accuracy 0.3201\n",
      "Epoch 14 Batch 500 Loss 1.5126 Accuracy 0.3195\n",
      "Epoch 14 Batch 550 Loss 1.5201 Accuracy 0.3186\n",
      "Epoch 14 Batch 600 Loss 1.5266 Accuracy 0.3184\n",
      "Epoch 14 Batch 650 Loss 1.5326 Accuracy 0.3179\n",
      "Epoch 14 Batch 700 Loss 1.5357 Accuracy 0.3175\n",
      "Epoch 14 Loss 1.5363 Accuracy 0.3175\n",
      "Time taken for 1 epoch: 45.02189350128174 secs\n",
      "\n",
      "Epoch 15 Batch 0 Loss 1.3980 Accuracy 0.3264\n",
      "Epoch 15 Batch 50 Loss 1.3330 Accuracy 0.3386\n",
      "Epoch 15 Batch 100 Loss 1.3475 Accuracy 0.3332\n",
      "Epoch 15 Batch 150 Loss 1.3621 Accuracy 0.3320\n",
      "Epoch 15 Batch 200 Loss 1.3744 Accuracy 0.3307\n",
      "Epoch 15 Batch 250 Loss 1.3803 Accuracy 0.3291\n",
      "Epoch 15 Batch 300 Loss 1.3911 Accuracy 0.3281\n",
      "Epoch 15 Batch 350 Loss 1.4005 Accuracy 0.3274\n",
      "Epoch 15 Batch 400 Loss 1.4124 Accuracy 0.3264\n",
      "Epoch 15 Batch 450 Loss 1.4211 Accuracy 0.3254\n",
      "Epoch 15 Batch 500 Loss 1.4297 Accuracy 0.3247\n",
      "Epoch 15 Batch 550 Loss 1.4350 Accuracy 0.3240\n",
      "Epoch 15 Batch 600 Loss 1.4447 Accuracy 0.3236\n",
      "Epoch 15 Batch 650 Loss 1.4527 Accuracy 0.3234\n",
      "Epoch 15 Batch 700 Loss 1.4604 Accuracy 0.3227\n",
      "Saving checkpoint for epoch 15 at ./ckpt-3\n",
      "Epoch 15 Loss 1.4602 Accuracy 0.3228\n",
      "Time taken for 1 epoch: 45.342923402786255 secs\n",
      "\n",
      "Epoch 16 Batch 0 Loss 1.0781 Accuracy 0.3229\n",
      "Epoch 16 Batch 50 Loss 1.2595 Accuracy 0.3371\n",
      "Epoch 16 Batch 100 Loss 1.2736 Accuracy 0.3376\n",
      "Epoch 16 Batch 150 Loss 1.2938 Accuracy 0.3356\n",
      "Epoch 16 Batch 200 Loss 1.3076 Accuracy 0.3345\n",
      "Epoch 16 Batch 250 Loss 1.3196 Accuracy 0.3338\n",
      "Epoch 16 Batch 300 Loss 1.3290 Accuracy 0.3327\n",
      "Epoch 16 Batch 350 Loss 1.3344 Accuracy 0.3319\n",
      "Epoch 16 Batch 400 Loss 1.3451 Accuracy 0.3305\n",
      "Epoch 16 Batch 450 Loss 1.3558 Accuracy 0.3295\n",
      "Epoch 16 Batch 500 Loss 1.3615 Accuracy 0.3293\n",
      "Epoch 16 Batch 550 Loss 1.3697 Accuracy 0.3291\n",
      "Epoch 16 Batch 600 Loss 1.3796 Accuracy 0.3286\n",
      "Epoch 16 Batch 650 Loss 1.3871 Accuracy 0.3282\n",
      "Epoch 16 Batch 700 Loss 1.3930 Accuracy 0.3280\n",
      "Epoch 16 Loss 1.3932 Accuracy 0.3281\n",
      "Time taken for 1 epoch: 44.752070903778076 secs\n",
      "\n",
      "Epoch 17 Batch 0 Loss 1.2447 Accuracy 0.3290\n",
      "Epoch 17 Batch 50 Loss 1.1962 Accuracy 0.3427\n",
      "Epoch 17 Batch 100 Loss 1.2119 Accuracy 0.3427\n",
      "Epoch 17 Batch 150 Loss 1.2303 Accuracy 0.3413\n",
      "Epoch 17 Batch 200 Loss 1.2430 Accuracy 0.3406\n",
      "Epoch 17 Batch 250 Loss 1.2576 Accuracy 0.3384\n",
      "Epoch 17 Batch 300 Loss 1.2662 Accuracy 0.3378\n",
      "Epoch 17 Batch 350 Loss 1.2733 Accuracy 0.3369\n",
      "Epoch 17 Batch 400 Loss 1.2822 Accuracy 0.3366\n",
      "Epoch 17 Batch 450 Loss 1.2910 Accuracy 0.3361\n",
      "Epoch 17 Batch 500 Loss 1.3018 Accuracy 0.3349\n",
      "Epoch 17 Batch 550 Loss 1.3092 Accuracy 0.3344\n",
      "Epoch 17 Batch 600 Loss 1.3173 Accuracy 0.3343\n",
      "Epoch 17 Batch 650 Loss 1.3250 Accuracy 0.3332\n",
      "Epoch 17 Batch 700 Loss 1.3319 Accuracy 0.3330\n",
      "Epoch 17 Loss 1.3320 Accuracy 0.3329\n",
      "Time taken for 1 epoch: 44.743831634521484 secs\n",
      "\n",
      "Epoch 18 Batch 0 Loss 0.9768 Accuracy 0.3506\n",
      "Epoch 18 Batch 50 Loss 1.1597 Accuracy 0.3449\n",
      "Epoch 18 Batch 100 Loss 1.1689 Accuracy 0.3432\n",
      "Epoch 18 Batch 150 Loss 1.1853 Accuracy 0.3427\n",
      "Epoch 18 Batch 200 Loss 1.1996 Accuracy 0.3417\n",
      "Epoch 18 Batch 250 Loss 1.2107 Accuracy 0.3412\n",
      "Epoch 18 Batch 300 Loss 1.2179 Accuracy 0.3406\n",
      "Epoch 18 Batch 350 Loss 1.2236 Accuracy 0.3400\n",
      "Epoch 18 Batch 400 Loss 1.2332 Accuracy 0.3391\n",
      "Epoch 18 Batch 450 Loss 1.2427 Accuracy 0.3387\n",
      "Epoch 18 Batch 500 Loss 1.2513 Accuracy 0.3382\n",
      "Epoch 18 Batch 550 Loss 1.2566 Accuracy 0.3379\n",
      "Epoch 18 Batch 600 Loss 1.2634 Accuracy 0.3374\n",
      "Epoch 18 Batch 650 Loss 1.2710 Accuracy 0.3370\n",
      "Epoch 18 Batch 700 Loss 1.2777 Accuracy 0.3366\n",
      "Epoch 18 Loss 1.2774 Accuracy 0.3367\n",
      "Time taken for 1 epoch: 44.47447395324707 secs\n",
      "\n",
      "Epoch 19 Batch 0 Loss 1.0398 Accuracy 0.3698\n",
      "Epoch 19 Batch 50 Loss 1.1146 Accuracy 0.3477\n",
      "Epoch 19 Batch 100 Loss 1.1219 Accuracy 0.3496\n",
      "Epoch 19 Batch 150 Loss 1.1362 Accuracy 0.3464\n",
      "Epoch 19 Batch 200 Loss 1.1474 Accuracy 0.3457\n",
      "Epoch 19 Batch 250 Loss 1.1572 Accuracy 0.3451\n",
      "Epoch 19 Batch 300 Loss 1.1672 Accuracy 0.3435\n",
      "Epoch 19 Batch 350 Loss 1.1768 Accuracy 0.3431\n",
      "Epoch 19 Batch 400 Loss 1.1841 Accuracy 0.3427\n",
      "Epoch 19 Batch 450 Loss 1.1887 Accuracy 0.3424\n",
      "Epoch 19 Batch 500 Loss 1.1962 Accuracy 0.3417\n",
      "Epoch 19 Batch 550 Loss 1.2048 Accuracy 0.3415\n",
      "Epoch 19 Batch 600 Loss 1.2142 Accuracy 0.3406\n",
      "Epoch 19 Batch 650 Loss 1.2215 Accuracy 0.3404\n",
      "Epoch 19 Batch 700 Loss 1.2298 Accuracy 0.3393\n",
      "Epoch 19 Loss 1.2299 Accuracy 0.3394\n",
      "Time taken for 1 epoch: 44.57541823387146 secs\n",
      "\n",
      "Epoch 20 Batch 0 Loss 1.0221 Accuracy 0.3498\n",
      "Epoch 20 Batch 50 Loss 1.0534 Accuracy 0.3617\n",
      "Epoch 20 Batch 100 Loss 1.0729 Accuracy 0.3588\n",
      "Epoch 20 Batch 150 Loss 1.0862 Accuracy 0.3541\n",
      "Epoch 20 Batch 200 Loss 1.0935 Accuracy 0.3535\n",
      "Epoch 20 Batch 250 Loss 1.1069 Accuracy 0.3523\n",
      "Epoch 20 Batch 300 Loss 1.1191 Accuracy 0.3519\n",
      "Epoch 20 Batch 350 Loss 1.1304 Accuracy 0.3501\n",
      "Epoch 20 Batch 400 Loss 1.1404 Accuracy 0.3491\n",
      "Epoch 20 Batch 450 Loss 1.1501 Accuracy 0.3484\n",
      "Epoch 20 Batch 500 Loss 1.1566 Accuracy 0.3472\n",
      "Epoch 20 Batch 550 Loss 1.1619 Accuracy 0.3463\n",
      "Epoch 20 Batch 600 Loss 1.1689 Accuracy 0.3454\n",
      "Epoch 20 Batch 650 Loss 1.1756 Accuracy 0.3445\n",
      "Epoch 20 Batch 700 Loss 1.1817 Accuracy 0.3442\n",
      "Saving checkpoint for epoch 20 at ./ckpt-4\n",
      "Epoch 20 Loss 1.1820 Accuracy 0.3441\n",
      "Time taken for 1 epoch: 44.694963693618774 secs\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "# 20 에포크 훈련\n",
    "for epoch in range(20):\n",
    "  start = time.time()\n",
    "  \n",
    "  train_loss.reset_states()\n",
    "  train_accuracy.reset_states()\n",
    "  \n",
    "  # input : 포루투갈어, tar : 영어\n",
    "  for (batch, (inp, tar)) in enumerate(train_dataset):\n",
    "    train_step(inp, tar)\n",
    "    \n",
    "    if batch % 50 == 0:\n",
    "      print ('Epoch {} Batch {} Loss {:.4f} Accuracy {:.4f}'.format(\n",
    "          epoch + 1, batch, train_loss.result(), train_accuracy.result()))\n",
    "      \n",
    "  if (epoch + 1) % 5 == 0:\n",
    "    ckpt_save_path = ckpt_manager.save()\n",
    "    print ('Saving checkpoint for epoch {} at {}'.format(epoch+1,\n",
    "                                                         ckpt_save_path))\n",
    "    \n",
    "  print ('Epoch {} Loss {:.4f} Accuracy {:.4f}'.format(epoch + 1, \n",
    "                                                train_loss.result(), \n",
    "                                                train_accuracy.result()))\n",
    "\n",
    "  print ('Time taken for 1 epoch: {} secs\\n'.format(time.time() - start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "45sJJKmdL8u-"
   },
   "source": [
    "# 평가  \n",
    "![Imgur](https://i.imgur.com/cUjg18g.png)  \n",
    "\n",
    "\n",
    "평가는 훈련과는 다르게 진행됨.  \n",
    "번역할 포르투갈어는 인코더 레이어를 거쳐 인코딩이 되고,  \n",
    "디코더에는 영어 문장을 넣지 않고, 영어 문장의 시작 토큰만 디코더의 인풋으로 들어가게 됨.  \n",
    "그러면 인코딩 된 것과 + 시작 토큰을 활용해서 다음 단어를 예측하고,  \n",
    "인코딩 된 것 + 시작 토큰 + 전에 예측된 단어를 활용해서 다음 단어를 예측하는 방식. \n",
    "  \n",
    "그림에서는 bos가 시작 토큰.\n",
    "![Imgur](https://i.imgur.com/F6QseH6.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fdaL7LLfGzaQ"
   },
   "outputs": [],
   "source": [
    "def evaluate(inp_sentence):\n",
    "  # inp_sentence : 문자 (string)\n",
    "  start_token = [tokenizer_pt.vocab_size] # 포르투갈어의 시작 토큰\n",
    "  end_token = [tokenizer_pt.vocab_size + 1] # 포르투갈어의 끝 토큰\n",
    "  \n",
    "  # 시작 토큰 + 포르투갈 어 + 끝 토큰\n",
    "  inp_sentence = start_token + tokenizer_pt.encode(inp_sentence) + end_token\n",
    "  encoder_input = tf.expand_dims(inp_sentence, 0)\n",
    "  \n",
    "  # 디코더의 인풋은 영어 문장의 시작 토큰만 들어감\n",
    "  decoder_input = [tokenizer_en.vocab_size]\n",
    "  output = tf.expand_dims(decoder_input, 0)\n",
    "  \n",
    "  for i in range(MAX_LENGTH):\n",
    "    # predictions.shape == (batch_size, seq_len, vocab_size)\n",
    "    predictions = transformer(encoder_input, output, False)\n",
    "    \n",
    "    # 예측 결과에서 마지막 부분만 추출\n",
    "    predictions = predictions[: ,-1:, :]  # (batch_size, 1, vocab_size)\n",
    "\n",
    "    predicted_id = tf.cast(tf.argmax(predictions, axis=-1), tf.int32)\n",
    "\n",
    "    # 만약에 예측된 영어 단어가 영어의 끝 토큰에 해당한다면 예측을 끝냄\n",
    "    if predicted_id == tokenizer_en.vocab_size+1:\n",
    "      return tf.squeeze(output, axis=0)\n",
    "    \n",
    "    # 예측된 단어를 전 단어와 결합하여 다음 예측에 써먹음\n",
    "    output = tf.concat([output, predicted_id], axis=-1)\n",
    "\n",
    "  return tf.squeeze(output, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ECK0XFzCHBxv"
   },
   "outputs": [],
   "source": [
    "def translate(sentence):\n",
    "  result= evaluate(sentence)\n",
    "  \n",
    "  predicted_sentence = tokenizer_en.decode([i for i in result \n",
    "                                            if i < tokenizer_en.vocab_size])  \n",
    "\n",
    "  print('Input: {}'.format(sentence))\n",
    "  print('Predicted translation: {}'.format(predicted_sentence))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Fe6y5oDePZOI"
   },
   "source": [
    "실제로 번역해보기  \n",
    "제법 포르투갈 어를 영어 문법에 맞게 번역하는 것을 알 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 73
    },
    "id": "czjSk64HHCq5",
    "outputId": "88cdd289-4a37-4537-c101-5d9d5a81c7d2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: este é um problema que temos que resolver.\n",
      "Predicted translation: this is a problem we have to solve the united states .\n",
      "Real translation: this is a problem we have to solve .\n"
     ]
    }
   ],
   "source": [
    "translate(\"este é um problema que temos que resolver.\")\n",
    "print (\"Real translation: this is a problem we have to solve .\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 73
    },
    "id": "WkQuQyvjHcbJ",
    "outputId": "fae2b14c-acf1-46ca-ed26-ede08c782d42"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: os meus vizinhos ouviram sobre esta ideia.\n",
      "Predicted translation: my neighbors heard about this idea .\n",
      "Real translation: and my neighboring homes heard about this idea .\n"
     ]
    }
   ],
   "source": [
    "translate(\"os meus vizinhos ouviram sobre esta ideia.\")\n",
    "print (\"Real translation: and my neighboring homes heard about this idea .\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 93
    },
    "id": "76ZizBuyPbd8",
    "outputId": "898b2073-8a09-4b22-9218-25cc434df106"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: vou então muito rapidamente partilhar convosco algumas histórias de algumas coisas mágicas que aconteceram.\n",
      "Predicted translation: so i 'm going to quickly share with you some stories of a few magic things that happened .\n",
      "Real translation: so i 'll just share with you some stories very quickly of some magical things that have happened .\n"
     ]
    }
   ],
   "source": [
    "translate(\"vou então muito rapidamente partilhar convosco algumas histórias de algumas coisas mágicas que aconteceram.\")\n",
    "print (\"Real translation: so i 'll just share with you some stories very quickly of some magical things that have happened .\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 73
    },
    "id": "29vxXk81PlbE",
    "outputId": "af846b13-dbba-4d83-e267-f9fb68c8417b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: este é o primeiro livro que eu fiz.\n",
      "Predicted translation: this is the first book that i did n't .\n",
      "Real translation: this is the first book i've ever done.\n"
     ]
    }
   ],
   "source": [
    "translate(\"este é o primeiro livro que eu fiz.\")\n",
    "print (\"Real translation: this is the first book i've ever done.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xn44IonrZhnV"
   },
   "source": [
    "출처  \n",
    "http://jalammar.github.io/illustrated-gpt2/  \n",
    "https://d2l.ai/chapter_recurrent-modern/seq2seq.html  \n",
    "https://www.tensorflow.org/tutorials/text/transformer\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "machine_shape": "hm",
   "name": "Transformer(NMT).ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
